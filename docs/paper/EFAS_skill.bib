@article{Alfieri2014,
   abstract = {In operational hydrological forecasting systems, improvements are directly related to the continuous monitoring of the forecast performance. An efficient evaluation framework must be able to spot issues and limitations and provide feedback to the system developers. In regional systems, the expertise of analysts on duty is a major component of the daily evaluation. On the other hand, large scale systems need to be complemented with semi-automated tools to evaluate the quality of forecasts equitably in every part of their domain.This article presents the current status of the monitoring and evaluation framework of the European Flood Awareness System (EFAS). For each grid point of the European river network, 10-day ensemble streamflow predictions are evaluated against a reference simulation which uses observed meteorological fields as input to a calibrated hydrological model. Performance scores are displayed over different regions, forecast lead times, basin sizes, as well as in time, considering average scores for moving 12-month windows of forecasts. Skilful predictions are found in medium to large rivers over the whole 10-day range. On average, performance drops significantly in river basins with upstream area smaller than 300km2, partly due to underestimation of the runoff in mountain areas. Model limitations and recommendations to improve the evaluation framework are discussed in the final section.},
   author = {Lorenzo Alfieri and Florian Pappenberger and Fredrik Wetterhall and Thomas Haiden and David Richardson and Peter Salamon},
   doi = {10.1016/j.jhydrol.2014.06.035},
   issn = {00221694},
   journal = {Journal of Hydrology},
   keywords = {CRPS,Distributed hydrological modelling,Ensemble streamflow predictions,Flood early warning,Skill scores},
   month = {6},
   pages = {913-922},
   publisher = {Elsevier B.V.},
   title = {Evaluation of ensemble streamflow predictions in Europe},
   volume = {517},
   year = {2014},
}
@article{Alfieri2017,
	abstract = {Rising global temperature has put increasing pressure on understanding the linkage between atmospheric warming and the occurrence of natural hazards. While the Paris Agreement has set the ambitious target to limiting global warming to 1.5°C compared to preindustrial levels, scientists are urged to explore scenarios for different warming thresholds and quantify ranges of socioeconomic impact. In this work, we present a framework to estimate the economic damage and population affected by river floods at global scale. It is based on a modeling cascade involving hydrological, hydraulic and socioeconomic impact simulations, and makes use of state-of-the-art global layers of hazard, exposure and vulnerability at 1-km grid resolution. An ensemble of seven high-resolution global climate projections based on Representative Concentration Pathways 8.5 is used to derive streamflow simulations in the present and in the future climate. Those were analyzed to assess the frequency and magnitude of river floods and their impacts under scenarios corresponding to 1.5°C, 2°C, and 4°C global warming. Results indicate a clear positive correlation between atmospheric warming and future flood risk at global scale. At 4°C global warming, countries representing more than 70{\%} of the global population and global gross domestic product will face increases in flood risk in excess of 500{\%}. Changes in flood risk are unevenly distributed, with the largest increases in Asia, U.S., and Europe. In contrast, changes are statistically not significant in most countries in Africa and Oceania for all considered warming levels.},
	author = {Alfieri, Lorenzo and Bisselink, Berny and Dottori, Francesco and Naumann, Gustavo and de Roo, Ad and Salamon, Peter and Wyser, Klaus and Feyen, Luc},
	doi = {10.1002/2016EF000485},
	file = {:C$\backslash$:/Users/casadje/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Alfieri et al. - 2017 - Global projections of river flood risk in a warmer world.pdf:pdf},
	issn = {23284277},
	journal = {Earth's Future},
	keywords = {climate change,flood frequency,flood risk,floods,model agreement,projections,rcp 8.5,risk,specific warming levels},
	mendeley-tags = {floods,projections,risk},
	month = {feb},
	number = {2},
	pages = {171--182},
	publisher = {John Wiley and Sons Inc},
	title = {{Global projections of river flood risk in a warmer world}},
	volume = {5},
	year = {2017}
}
@article{Bartholmes2009,
   abstract = {Since 2005 the European Flood Alert System (EFAS) has been producing probabilistic hydrological forecasts in pre-operational mode at the Joint Research Centre (JRC) of the European Commission. EFAS aims at increasing preparedness for floods in trans-national European river basins by providing medium-range deterministic and proba-bilistic flood forecasting information, from 3 to 10 days in advance, to national hydro-meteorological services. This paper is Part 2 of a study presenting the development and skill assessment of EFAS. In Part 1, the scientific approach adopted in the development of the system has been presented, as well as its basic principles and forecast products. In the present article, two years of existing operational EFAS forecasts are statistically assessed and the skill of EFAS forecasts is analysed with several skill scores. The analysis is based on the comparison of threshold exceedances between proxy-observed and forecasted discharges. Skill is assessed both with and without taking into account the persistence of the forecasted signal during consecutive forecasts. Skill assessment approaches are mostly adopted from meteorology and the analysis also compares probabilistic and deterministic aspects of EFAS. Furthermore, the utility of different skill scores is discussed and their strengths and shortcomings illustrated. The analysis shows the benefit of incorporating past forecasts in the probability analysis, for medium-range forecasts, which effectively increases the skill of the forecasts.},
   author = {J C Bartholmes and J Thielen and M H Ramos and S Gentilini},
   doi = {10.5194/hess-13-141-2009},
   journal = {Hydrol. Earth Syst. Sci},
   pages = {141-153},
   title = {The european flood alert system EFAS – Part 2: Statistical skill assessment of probabilistic and deterministic operational forecasts},
   volume = {13},
   url = {www.hydrol-earth-syst-sci.net/13/141/2009/},
   year = {2009},
}
@article{Bauer2015,
	abstract = {Advances in numerical weather prediction represent a quiet revolution because they have resulted from a steady accumulation of scientific knowledge and technological advances over many years that, with only a few exceptions, have not been associated with the aura of fundamental physics breakthroughs. Nonetheless, the impact of numerical weather prediction is among the greatest of any area of physical science. As a computational problem, global weather prediction is comparable to the simulation of the human brain and of the evolution of the early Universe, and it is performed every day at major operational centres across the world.},
	author = {Bauer, Peter and Thorpe, Alan and Brunet, Gilbert},
	doi = {10.1038/nature14956},
	file = {:C$\backslash$:/Users/casadje/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bauer, Thorpe, Brunet - 2015 - The quiet revolution of numerical weather prediction.pdf:pdf},
	issn = {14764687},
	journal = {Nature},
	keywords = {NWP},
	mendeley-tags = {NWP},
	month = {sep},
	number = {7567},
	pages = {47--55},
	publisher = {Nature Publishing Group},
	title = {{The quiet revolution of numerical weather prediction}},
	volume = {525},
	year = {2015}
}
@unpublished{Bouttier2023,
	abstract = {Translation of ensemble predictions into high precipitation warnings is assessed using user oriented metrics. Short range probabilistic forecasts are derived from an operational ensemble prediction system using neighbourhood post-processing and conversion into categorical predictions by decision threshold optimization. Forecast skill is modelled for two different types of users. We investigate the balance between false alarms and missed events and the implications of the scales at which forecast information is communicated. 5 Results show that ensemble predictions objectively outperform the corresponding deterministic control forecasts at low precipitation intensities when an optimal probability threshold is used. Thresholds estimated from a short forecast archive are robust with respect to forecast range and season and can be extrapolated towards extreme values to estimate severe weather guidance. Numerical weather forecast value is found to be limited: the highest usable precipitation intensities have return periods of 10 a few years only, with resolution limited to several tens of kilometres. Implied precipitation warnings fall short of common skill requirements for high impact weather, confirming the importance of human expertise, nowcasting information and the potential of machine learning approaches. The verification methodology presented here provides a benchmark for high precipitation forecasts, based on metrics that are relatively easy to compute and explain to non-experts.},
	annote = {Summary
	The paper presents a methodology to optimize high-intensity precipitation warnings using an ensemble numerical weather prediction (NWP) model. They define two types of user and optimize the probability threshold that renders higher warning skill.
	It is interesting that they use the f-score as a target metric, but they use a beta coefficient of 2, i.e., they try to minimize the missed events claiming that the cost of a false alarm is smaller than the cost of a missed event. It is also interesting how they compute the total probability, because they apply a triangular kernel to smooth the continuous probability distribution (in their case is needed because AROME has only 17 members).
	Since they deal with precipitation data, instead of discharge, they have to preprocess both the observed and forecasted precipitation fields to deal with the spatial locations of the storms. They have also analysed the sensitivity of their method to the ensemble dressing, the spatial buffering (both in observations and forecasts), the precipitation intensity, the time dimension (diurnal cycle, season, accumulation timescale).},
	author = {Bouttier, Fran{\c{c}}ois and Marchal, Hugo},
	doi = {10.5194/egusphere-2023-3111},
	file = {:C$\backslash$:/Users/casadje/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bouttier, Marchal - Unknown - Probabilistic short-range forecasts of high precipitation events optimal decision thresholds and predicta.pdf:pdf},
	keywords = {ensemble forecast,high precipitation,warning},
	mendeley-tags = {ensemble forecast,high precipitation,warning},
	title = {{Probabilistic short-range forecasts of high precipitation events : optimal decision thresholds and predictability limits}},
	url = {https://doi.org/10.5194/egusphere-2023-3111},
	year = {2023}
}
@article{Brier1950,
   abstract = {Verification of weather forecasts has been a controversial subject for more than a half century. There are a number of reasons why this problem has been so perplexing to meteorologists and others but one of the most important difficulties seems to be in reaching an agreement on the specification of a scale of goodness for weather forecasts. Numerous systems have been proposed but one of the greatest arguments raised against forecast verification is that forecasts which may be the “best” according to the accepted system of arbitrary scores may not be the most useful forecasts. In attempting to resolve this difficulty the forecaster may often find himself in the position of choosing to ignore the verification system or to let it, do the forecasting for him by “hedging” or “playing the system.” This may lead the forecaster to forecast something other than what he thinks will occur, for it is often easier to analyze the effect of different possible forecasts on the verification score than it is to analyze the weather situation. It is generally agreed that this state of affairs is unsatisfactory, as one essential criterion for satisfactory verification is that the verification scheme should influence the forecaster in no undesirable way. Unfortunately, the criterion is difficult, if not impossible to satisfy, although some schemes will be much worse than others in this respect.
It is the purpose of this paper to discuss one situation where it appears to be possible to devise a verification scheme that cannot influence the forecaster in any undesirable way. This is the case when forecasts are expressed in terms of probability statements. The advantages of expressing the degree of assumed reliability of a forecast numerically have been discussed previously [1, 2, 3, 4] so that the purpose here will not be to emphasize the enhanced usefulness of such forecasts but rather to point out how some aspects of the verification problem are simplified or solved.},
   author = {Glenn W. Brier},
   issue = {1},
   journal = {Monthly Weather Review},
   title = {Verification of forecasts expressed in terms of probability},
   volume = {78},
   year = {1950},
}
@article{Buizza2008,
	abstract = {Probabilistic forecasts designed to estimate the probability density function of forecast states are potentially more valuable than single forecasts because (1) they can predict not only the most likely outcome but also the probability of occurrence of extreme and rare events and (2) probabilistic forecasts issued on consecutive days are usually more consistent than corresponding single forecasts. In this communication, the potential economic value of probabilistic and single forecasts are compared, and single and probabilistic forecasts of precipitation for a flooding event are analyzed to illustrate the potential value of consistency between successive forecasts. Copyright {\textcopyright} 2008 Royal Meteorological Society},
	author = {Buizza, Roberto},
	doi = {10.1002/asl.170},
	file = {:C$\backslash$:/Users/casadje/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Buizza - 2008 - The value of probabilistic prediction.pdf:pdf},
	issn = {1530-261X},
	journal = {Atmospheric Science Letters},
	keywords = {ensemble prediction,forecast value,probabilistic prediction},
	mendeley-tags = {ensemble prediction,forecast value,probabilistic prediction},
	month = {apr},
	number = {2},
	pages = {36--42},
	publisher = {Wiley},
	title = {{The value of probabilistic prediction}},
	volume = {9},
	year = {2008}
}
@misc{Burek2013a,
   author = {Peter Burek and Johan van der Knijff and Ad de Roo},
   city = {Luxembourg},
   doi = {10.2788/24719},
   isbn = {879-92-79-33190-9},
   issn = {1831-9424},
   institution = {European Commission - Joint Research Centre},
   title = {LISFLOOD. Distributed Water Balance and Flood Simulation Model},
   year = {2013},
}
@article{Cloke2009,
   abstract = {Operational medium range flood forecasting systems are increasingly moving towards the adoption of ensembles of numerical weather predictions (NWP), known as ensemble prediction systems (EPS), to drive their predictions. We review the scientific drivers of this shift towards such 'ensemble flood forecasting' and discuss several of the questions surrounding best practice in using EPS in flood forecasting systems. We also review the literature evidence of the 'added value' of flood forecasts based on EPS and point to remaining key challenges in using EPS successfully. © 2009 Elsevier B.V. All rights reserved.},
   author = {H. L. Cloke and F. Pappenberger},
   doi = {10.1016/j.jhydrol.2009.06.005},
   issn = {00221694},
   issue = {3-4},
   journal = {Journal of Hydrology},
   keywords = {Ensemble prediction system,Flood prediction,Numerical weather prediction,Streamflow,Uncertainty},
   month = {9},
   pages = {613-626},
   title = {Ensemble flood forecasting: A review},
   volume = {375},
   year = {2009},
}
@article{Cloke2017,
   abstract = {Flood early warning systems mitigate damages and loss of life and are an economically efficient way of enhancing disaster resilience. The use of continental scale flood early warning systems is rapidly growing. The European Flood Awareness System (EFAS) is a pan-European flood early warning system forced by a multi-model ensemble of numerical weather predictions. Responses to scientific and technical changes can be complex in these computationally expensive continental scale systems, and improvements need to be tested by evaluating runs of the whole system. It is demonstrated here that forecast skill is not correlated with the value of warnings. In order to tell if the system has been improved an evaluation strategy is required that considers both forecast skill and warning value. The combination of a multi-forcing ensemble of EFAS flood forecasts is evaluated with a new skill-value strategy. The full multi-forcing ensemble is recommended for operational forecasting, but, there are spatial variations in the optimal forecast combination. Results indicate that optimizing forecasts based on value rather than skill alters the optimal forcing combination and the forecast performance. Also indicated is that model diversity and ensemble size are both important in achieving best overall performance. The use of several evaluation measures that consider both skill and value is strongly recommended when considering improvements to early warning systems.},
   author = {Hannah L. Cloke and Florian Pappenberger and Paul J. Smith and Fredrik Wetterhall},
   doi = {10.1088/1748-9326/aa625a},
   issn = {17489326},
   issue = {4},
   journal = {Environmental Research Letters},
   keywords = {Copernicus,european flood awareness system,flood early warning systems,flood resilience,forecast skill,monetary value,multi-forcing ensemble},
   month = {3},
   note = {<b>Objective</b><br/><br/>* To prove whether there is a  correlation between forecast skill and value.<br/>* To analyze the skill and value of several combinations of forecasts (both probabilistic and deterministic) in the EFAS framework. The<b> hypothesis</b> is that full multi-model forcing will provide the highest skill and highest warning value.<br/><br/><b>Data</b><br/><br/><u>Observed</u><br/><br/>Discharge proxy obtained by simulation of observed meteorology with the same hydrological model setup.<br/><br/><u>Forecast</u><br/><br/>2 years (January 2012, December 2013) of EFAS reforecast data. It includes 4 NWP models: deterministic DWD, deterministic ECMWF, probabilistic ECMWF-ENS, probabilistic COSMO-LEPS. Forecasts are issued daily with 10 d lead time, but the study focuses only from day 3 onwards.<br/><br/><b>Methods</b><br/><br/><u>Forecast combination and optimization</u><br/><br/>To combine forecasts, weights are given to each individual forecast for each of the 768 river catchments. They use <b>nonhomogeneous Gaussian regression (NGR)</b>; this is a methodology that corrects the raw forecast including the uncertainty derived from a linear regression between past forecasts and observations, and the spread in the current forecast.<br/><br/>Where <i>a</i> and <i>bi</i> are bias correction parameters (related to the forecast mean <i>Mi</i>), <i>c </i>and <i>di</i> are spread correction parameters (related to the forecast standard deviation Si). The parameters are estimated with the las 90 d of forecasts. 5 optimization methods are applied:<br/><br/>* Continuous rank probability      score (CRPS)<br/>* CRPS lagged with forecasts      from 3-10 days before.<br/>* Symmetric extreme dependency      index (SEDI). It is built out of the hit rate and false alarm rate from      the contingency table.<br/>* Hit rate<br/>* Value, which the authors      measure simply as the number of hits. I don't understand why.<br/><br/><u>Sensitivity analysis</u><br/><br/>They apply two approaches:<br/><br/>* Leave one out comparison      (LOOC): comparison between combinations that apply a forcing with those      that do not apply it.<br/>* Add one in comparison (AOIC):      an individual forcing is added to each combinations and compared to the      combination without it.<br/><br/>Skill scores are derived from the previous metrics used in the optimization. It means that they are normalized by dividing it by a reference score.<br/><br/><b>Results</b><br/><br/><u>Is an optimization method looking at both skill and value required?</u><br/><br/>* Spearman rank correlation      coefficients prove a week correlation between skill and value.<br/>* The full multi-model approach      ranks higher both for CRPS and value.<br/><br/><u>Which NWP forcings have the greatest relative contribution to improved forecast performance?</u><br/><br/>* DWD, ECMWF-HRES and ECMWF-ENS      have a positive contribution.<br/>* COSMO-LEPS does not add value      in general, but it is interesting in certain areas like the Alps.<br/>* There are strong spatial      dependencies that suggest that using forcings specifically for each      catchment will improve performance.<br/><br/><u>Which NWP forcing most improves forecast performance when added to an existing configuration?</u><br/><br/>* The value of multi-forcing      ensembles is proved, with increasing skill and value for larger      configurations.<br/>*Model diversity is important      (ECMWF deterministic and probabilistic are too similar) in order to      improve the hit rate, but ensemble size is more important for improving      CRPS},
   publisher = {Institute of Physics Publishing},
   title = {How do i know if I've improved my continental scale flood early warning system?},
   volume = {12},
   year = {2017},
}
@article{Demeritt2013,
   abstract = {Although ensemble prediction systems (EPS) are increasingly promoted as the scientific state-of-the-art for operational flood forecasting, the communication, perception, and use of the resulting alerts have received much less attention. Using a variety of qualitative research methods, including direct user feedback at training workshops, participant observation during site visits to 25 forecasting centres across Europe, and in-depth interviews with 69 forecasters, civil protection officials, and policy makers involved in operational flood risk management in 17 European countries, this article discusses the perception, communication, and use of European Flood Alert System (EFAS) alerts in operational flood management. In particular, this article describes how the design of EFAS alerts has evolved in response to user feedback and desires for a hydrographic-like way of visualizing EFAS outputs. It also documents a variety of forecaster perceptions about the value and skill of EFAS forecasts and the best way of using them to inform operational decision making. EFAS flood alerts were generally welcomed by flood forecasters as a sort of 'pre-alert' to spur greater internal vigilance. In most cases, however, they did not lead, by themselves, to further preparatory action or to earlier warnings to the public or emergency services. Their hesitancy to act in response to medium-term, probabilistic alerts highlights some wider institutional obstacles to the hopes in the research community that EPS will be readily embraced by operational forecasters and lead to immediate improvements in flood incident management. The EFAS experience offers lessons for other hydrological services seeking to implement EPS operationally for flood forecasting and warning. © 2012 John Wiley & Sons, Ltd.},
   author = {David Demeritt and Sebastien Nobert and Hannah L. Cloke and Florian Pappenberger},
   doi = {10.1002/hyp.9419},
   issn = {08856087},
   issue = {1},
   journal = {Hydrological Processes},
   keywords = {EFAS,EPS,Flood warnings,Risk communication},
   pages = {147-157},
   title = {The European Flood Alert System and the communication, perception, and use of ensemble predictions for operational flood risk management},
   volume = {27},
   year = {2013},
}
@article{DeRoo2000,
   abstract = {Although many geographical information systems (GISs) are very advanced in data processing and display, current GIS are not capable of physically based modelling. Especially, simulating transport of water and pollutants through landscapes is a problem in a GIS environment. A number of specific routing methods are needed in a GIS for hydrologic modelling, amongst these are the numerical solutions of the Saint-Venant equations, such as the kinematic wave approximation for transport of surface water in a landscape. The PCRaster Spatial Modelling language is a GIS capable of dynamic modelling. It has been extended recently with a kinematic wave approximation simulation tool to allow for physically based water flow modelling. The LISFLOOD model is an example of a physically based model written using the PCRaster GIS environment. The LISFLOOD model simulates river discharge in a drainage basin as a function of spatial data on topography, soils and land cover. Although hydrological modelling capabilities have largely increased, there is still a need for development of other routing methods, such a diffusion wave. Copyright (C) 2000 John Wiley and Sons, Ltd.},
   author = {A. P.J. De Roo and C. G. Wesseling and W. P.A. Van Deursen},
   doi = {10.1002/1099-1085(20000815/30)14:11/12<1981::aid-hyp49>3.0.co;2-f},
   issn = {08856087},
   issue = {11-12},
   journal = {Hydrological Processes},
   keywords = {Catchment,Floods,GIS,Hydrological modelling,Kinematic wave,LISFLOOD,PCRaster},
   pages = {1981-1992},
   publisher = {John Wiley & Sons Ltd},
   title = {Physically based river basin modelling within a GIS: The LISFLOOD model},
   volume = {14},
   year = {2000},
}
@article{Diomede2008,
	abstract = {In the field of hydrological prediction for medium-sized watersheds, characterized by complex orography and short response times, forecasts cannot rely only upon observed precipitation: predicted rainfall is in this case an essential input for hydrological models. However, the quality and reliability of deterministic numerical precipitation forecasts driving a hydrological model are often unsatisfactory, because uncertainty in Quantitative Precipitation Forecasts (QPFs) is considerable at the scales of interest for hydrological purposes. The uncertainty inherent in precipitation forecast can be accounted for better estimating the uncertainty associated with the flood forecast, in order to provide a more informative hydrological prediction. The methodology proposed and adopted in this work is based on a hydrological ensemble forecasting approach that uses multiple precipitation scenarios provided by different high-resolution numerical weather prediction models, driving the same hydrological model. In this way, the uncertainty associated with the meteorological forecasts can propagate into the hydrological models and be used in warnings and decision making procedures relying upon a probabilistic approach. In the framework of RISK AWARE, an INTERREG III B EU project, a detailed analysis of two cases of intense precipitation affecting the Reno river basin, a medium-sized catchment in northern Italy, has been performed. One case study has been performed using lateral boundary values derived from analysed fields, the other simulating a real time forecast, i.e., using forecasted boundary conditions. Four different meteorological models (Lokal Modell, RAMS, BOLAM and MOLOCH), operating at different horizontal resolutions, provide QPFs which are used to force the hydrological model. The discharge predictions are obtained by means of the physically based rainfall-runoff model TOPKAPI. The results provide examples of the uncertainties inherent in the QPF and show that the hydrological response of the Reno river basin, as simulated by the TOPKAPI model, is highly sensitive to the correct space-time localization of precipitation, even if the total amount of rainfall is, on average, well forecasted. The system seems able to provide useful information concerning the discharge peaks (amount and timing) for warning purposes. {\textcopyright} Springer-Verlag 2008.},
	author = {Diomede, Tommaso and Davolio, S. and Marsigli, C. and Miglietta, M. M. and Moscatello, A. and Papetti, P. and Paccagnella, T. and Buzzi, A. and Malguzzi, P.},
	doi = {10.1007/s00703-007-0285-0},
	file = {:C$\backslash$:/Users/casadje/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Diomede et al. - 2008 - Discharge prediction based on multi-model precipitation forecasts.pdf:pdf},
	issn = {01777971},
	journal = {Meteorology and Atmospheric Physics},
	number = {3-4},
	pages = {245--265},
	title = {{Discharge prediction based on multi-model precipitation forecasts}},
	volume = {101},
	year = {2008}
}
@techreport{EEA2023,
	author = {EEA},
	institution = {European Environmental Agency},
	keywords = {Europe,floods,losses},
	mendeley-tags = {Europe,floods,losses},
	month = {oct},
	title = {{Economic losses from weather- and climate-related extremes in Europe}},
	url = {https://www.eea.europa.eu/en/analysis/indicators/economic-losses-from-climate-related?activeAccordion=ecdb3bcf-bbe9-4978-b5cf-0b136399d9f8},
	year = {2023}
}
@misc{EFASv4.0,
	author = {{Joint Research Centre - European Commission}},
	keywords = {EFAS},
	mendeley-tags = {EFAS},
	month = {jun},
	title = {{European Flood Awareness System v4.0}},
	url = {https://confluence.ecmwf.int/display/CEMS/EFAS+v4.0},
	urldate = {2024-01-10},
	year = {2020}
}
@misc{EFASv5.0,
	author = {{Joint Research Centre - European Commission}},
	keywords = {EFAS},
	mendeley-tags = {EFAS},
	title = {{European Flood Awareness System v5.0}},
	url = {https://confluence.ecmwf.int/display/CEMS/Latest+operational+EFAS+release},
	urldate = {2024-01-19},
	year = {2023}
}
@article{Gupta2009,
   abstract = {The mean squared error (MSE) and the related normalization, the Nash–Sutcliffe efficiency (NSE), are the two criteria most widely used for calibration and evaluation of hydrological models with observed data. Here, we present a diagnostically interesting decomposition of NSE (and hence MSE), which facilitates analysis of the relative importance of its different components in the context of hydrological modelling, and show how model calibration problems can arise due to interactions among these components. The analysis is illustrated by calibrating a simple conceptual precipitation-runoff model to daily data for a number of Austrian basins having a broad range of hydro-meteorological characteristics. Evaluation of the results clearly demonstrates the problems that can be associated with any calibration based on the NSE (or MSE) criterion. While we propose and test an alternative criterion that can help to reduce model calibration problems, the primary purpose of this study is not to present an improved measure of model performance. Instead, we seek to show that there are systematic problems inherent with any optimization based on formulations related to the MSE. The analysis and results have implications to the manner in which we calibrate and evaluate environmental models; we discuss these and suggest possible ways forward that may move us towards an improved and diagnostically meaningful approach to model performance evaluation and identification.},
   author = {Hoshin V. Gupta and Harald Kling and Koray K. Yilmaz and Guillermo F. Martinez},
   doi = {10.1016/J.JHYDROL.2009.08.003},
   issn = {0022-1694},
   issue = {1-2},
   journal = {Journal of Hydrology},
   month = {10},
   note = {<b>Objetivo:</b><br/>Hacer un diagnóstico del NSE como función objetivo en la calibración de modelos hidrológicos a partir de su descomposición. A partir de ese diagnóstico se propone un nuevo criterio de optimización.<br/><br/><b>Metodología:</b><br/>Primeramente se hace un desarrollo teórico sobre la descomposición del NSE, sus limitaciones y se plantea el KGE como nuevo criterio de optimización.<br/><br/>La aplicabilidad de estos dos criterios se estudio por medio de la simulación mediante HBV de 49 cuencas a mesoescala en Austria. El modelo se calibra de dos maneras, frente al NSE y el KGE, obteniéndose dos conjuntos de parámetros para cada subcuenca. Sobre estas simulaciones se analiza el rendimiento global, los componentes del NSE/KGE y los conjuntos de parámetros optimizados.<br/><br/><b>Teorías e hipótesis:<br/></b>Se descompone el NSE en tres componentes: la correlación, el sesgo normalizado (a través de la desv. típica) y la variabilidad relativa. De esta descomposición se extraen las siguientes limitaciones del NSE:<br/>- La normalización del sesgo limita el peso específico de éste sobre el global del NSE, especialmente en cuencas con régimen muy variable.<br/>- La variabilidad aparece dos veces en el NSE y se demuestra que el máximo se obtiene cuando la variabilidad es igual a la raíz del coeficiente de correlación. NSE nunca será superior, por tanto, al coeficiente de correlación.<br/>- Se tiende a subestimar la pendiente de las regresiones observado-simulado y viceversa, por lo que se subestiman los caudales altos y sobreestiman los caudales bajos.<br/><br/>Frente al NSE, se propone un nuevo criterio de optimización, el Kling-Gupta efficiency (KGE). Es la distancia euclídea entre los tres componentes (correlación, sesgo relativo y variabilidad relativa) y sus valores óptimos (1, 0 , 1).<br/><br/><b>Resultados:</b><br/>- Fuenrte correlación entre los resultados de NSE y KGE cuando se calibra a éste último. No es así en sentido contrario.<br/>- La correlación es claramente el componente con más peso de los tres tanto para NSE como para KGE. Sin embargo, en el caso de KGE, no se debe a una menor ponderación (los tres componentes tienen el mismo peso), sino a que se consiguen valores de los otros dos componentes muy próximos al óptimo.<br/>- Mientras que ambos métodos obtienen calibraciones de la correlación similares, KGE es muy superior a NSE en la calibración del sesgo y la variabilidad relativos. La pérdida en la validación es menor con KGE, aunque aumenta mucho la variabilidad de los dos componentes.<br/>- NSE obtiene una recta de regresión casi ideal para la regresión de simulados sobre observados, pero muy mala al contrario. KGE obtiene valores similares para ambas regresiones, pero siempre ligeramente inferiores al óptimo.<br/>- Muy fuerte correlación entre los valores de los parámetros optimizados por ambos métodos (0.8). Sin embargo, pequeños cambios en los parámetros conllevan mayores cambios en el rendimiento.<br/>- Dos valores iguales de NSE (o KGE) no tienen por qué significar un mismo rendimiento. Mirando a los tres componentes del criterio, se puede discernir qué conjunto es mejor/peor que otro incluyo para un mismo NSE (KGE).<br/><br/><b>Limitaciones:</b><br/><br/><b>Preguntas sin respuesta:<br/><br/>Futura investigación:<br/></b>},
   pages = {80-91},
   publisher = {Elsevier},
   title = {Decomposition of the mean squared error and NSE performance criteria: Implications for improving hydrological modelling},
   volume = {377},
   url = {https://www.sciencedirect.com/science/article/pii/S0022169409004843},
   year = {2009},
}
@article{Hall2021,
   author = {Liam Hall},
   note = {<b>Objectives</b><br/><br/>To analyse whether including model performance or forecast skill metrics in the EFAS' notification criteria would improve its accuracy (in terms of hit rate):<br/><br/>* To find the most interesting      metrics to add value to notifications.<br/>* To determine how to include      those metrics in the notification.<br/>* To study spatial      variations.<br/><br/><b>Data</b><br/><br/>EFAS v4.0 data for its first 5 months operating (oct-2020 to april-2021).<br/><br/>* Lists of formal (72) and      informal (48) flood notifications.<br/>* Feedback received from users      on formal notifications (8).<br/><br/><b>Methods</b><br/><br/>The selected model performance metric is the modified Kling-Gupta Efficiency (KGE). Not all notifications have KGE available, since there are areas where there aren't stations available.<br/>The forecast skill is measured by the Continuous ranked Probabilistic Skill Score (CRPSS). The benchmark is the model's climatology calculated over 30 years. Skill is analysed for lead times from 1 to 10 days.<br/>In both cases, notifications are clustered in 4 groups according to the 3 quartiles.<br/><br/><b>Results</b><br/><br/><u>Model performace:</u><br/><br/>* Formal notifications. KGE and      correlation are useful as discriminatory tool.<br/>* Informal notifications. Bias      produces the most useful results.<br/>* Formal+informal notifications.      None of the metrics (KGE or its constituents) show a clear trend.<br/><br/>The spatial analysis doesn't cast any interesting results, apart from a lower performance in Southern Europe related with lack of stations and highly regulated rivers.<br/><br/><u>Forecast skill:</u><br/><br/>* Increasing CRPSS at issued lead time is not useful for improving the hit rate.<br/><br/>The spatial analysis doesn't provide clear results either.<br/><br/><b>Conclusions</b><br/><br/>* KGE can't be used a notification criteria since it is not available in some areas (Italy and Greece).<br/>* CRPSS avoids this problem, but, since it's only based on modelled data, it doesn't take into      consideration reality.<br/>* It is suggested to add performance (KGE) and skill (CRPSS) labelling, rather than criteria. In the case of CRPSS it should show the skill for the same lead time as the      notification.<br/><br/><b>Further research</b><br/><br/>* Collect more feedback.<br/>* Repeat the analysis with larger amount of data. Now there is 2 years data.<br/>* Missed events haven't been analyzed. To do so, it would be necessary to spot flood events that weren't notified by EFAS (floodlist, etc.). Increasing the heat rate should not come at the expense of a higher miss rate.<br/>* To consider the possibility of removing the deterministic requirement for EFAS formal flood notifications (is it still applicable?).<br/><br/><b>Comments</b><br/><br/>He only analyses <b>precision</b>, i.e., the true positive rate: TP /      (TP + FP). Optimising precision means that when the system sends a flood notification, indeed a flood occurs. This may lead to underpredicting floods, since missed events are not taken into account in the optimization. To avoid missing flood events, other criteria such as <b>recall</b> should be applied: TP / (TP + FN). A compromise between these two criteria would be <b>F1</b> of <b>Fbeta</b> scores, which are a trade-off between them.},
   title = {Integrating Measures of Model Performance and Forecast Skill into European Flood Awareness System (EFAS) Notifications},
   year = {2021},
}
@book{Hanssen1965,
  title={On the Relationship Between the Frequency of Rain and Various Meteorological Parameters: (with Reference to the Problem Ob Objective Forecasting)},
  author={Hanssen, A.W. and Kuipers, W.J.A.},
  series={Koninkl. Nederlands Meterologisch Institut. Mededelingen en Verhandelingen},
  year={1965},
  publisher={Staatsdrukkerij- en Uitgeverijbedrijf}
}
@incollection{IPCC2023,
	author = {{Martina Angela Caretta} and {Aditi Mukherji} and {Md Arfanuzzaman} and {Richard A. Betts} and {Alexander Gelfan} and {Yukiko Hirabayashi} and {Tabea Katharina Lissner} and {Elena Lopez Gunn} and {Junguo Liu} and {Ruth Morgan} and {Sixbert Mwanga} and {Seree Supratid}},
	booktitle = {Climate Change 2022 – Impacts, Adaptation and Vulnerability},
	doi = {10.1017/9781009325844.006},
	file = {:C$\backslash$:/Users/casadje/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Martina Angela Caretta et al. - 2023 - Water.pdf:pdf},
	keywords = {climate change,water},
	mendeley-tags = {climate change,water},
	month = {jun},
	pages = {551--712},
	publisher = {Cambridge University Press},
	title = {{Water}},
	url = {https://www.cambridge.org/core/product/identifier/9781009325844{\%}23c4/type/book{\_}part},
	year = {2023}
}
@article{Knoben2019,
   abstract = {A traditional metric used in hydrology to summarize model performance is the Nash-Sutcliffe efficiency (NSE). Increasingly an alternative metric, the Kling-Gupta efficiency (KGE), is used instead. When NSE is used, NSE = 0 corresponds to using the mean flow as a benchmark predictor. The same reasoning is applied in various studies that use KGE as a metric: negative KGE values are viewed as bad model performance, and only positive values are seen as good model performance. Here we show that using the mean flow as a predictor does not result in KGE=0, but instead KGE = 1- √ 2 ∼ -0:41. Thus, KGE values greater than -0:41 indicate that a model improves upon the mean flow benchmark - even if the model's KGE value is negative. NSE and KGE values cannot be directly compared, because their relationship is non-unique and depends in part on the coefficient of variation of the observed time series. Therefore, modellers who use the KGE metric should not let their understanding of NSE values guide them in interpreting KGE values and instead develop new understanding based on the constitutive parts of the KGE metric and the explicit use of benchmark values to compare KGE scores against. More generally, a strong case can be made for moving away from ad hoc use of aggregated efficiency metrics and towards a framework based on purpose-dependent evaluation metrics and benchmarks that allows for more robust model adequacy assessment.},
   author = {Wouter J.M. Knoben and Jim E. Freer and Ross A. Woods},
   doi = {10.5194/hess-23-4323-2019},
   issn = {16077938},
   issue = {10},
   journal = {Hydrology and Earth System Sciences},
   month = {10},
   pages = {4323-4331},
   publisher = {Copernicus GmbH},
   title = {Technical note: Inherent benchmark or not? Comparing Nash-Sutcliffe and Kling-Gupta efficiency scores},
   volume = {23},
   year = {2019},
}
@article{LeClerc2015,
	abstract = {Despite improvements in forecasting extreme weather events, noncompliance with weather warnings among the public remains a problem. Although there are likely many reasons for noncompliance with weather warnings, one important factor might be people's past experiences with false alarms. The research presented here explores the role of false alarms in weather-related decision making. Over a series of trials, participants used an overnight low temperature forecast and advice from a decision aid to decide whether to apply salt treatment to a town's roads to prevent icy conditions or take the risk of withholding treatment, which resulted in a large penalty when freezing temperatures occurred. The decision aid gave treatment recommendations, some of which were false alarms, i.e., treatment was recommended but observed temperatures were above freezing. The rate at which the advice resulted in false alarms was manipulated between groups. Results suggest that very high and very low false alarm rates led to inferior decision making, but that lowering the false alarm rate slightly did not significantly affect compliance or decision quality. However, adding a probabilistic uncertainty estimate in the forecasts improved both compliance and decision quality. These findings carry implications about how weather warnings should be communicated to the public.},
	author = {LeClerc, Jared and Joslyn, Susan},
	doi = {10.1111/risa.12336},
	file = {:C$\backslash$:/Users/casadje/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/LeClerc, Joslyn - 2015 - The cry wolf effect and weather-related decision making.pdf:pdf},
	issn = {15396924},
	journal = {Risk Analysis},
	keywords = {Cognitive psychology,Decision making,False alarm effect,Risk communication,alarm,cognitive psychology,false alarm effect,risk communication},
	mendeley-tags = {alarm,cognitive psychology,false alarm effect,risk communication},
	month = {mar},
	number = {3},
	pages = {385--395},
	title = {{The cry wolf effect and weather-related decision making}},
	volume = {35},
	year = {2015}
}
@article{Molteni1996,
	author = {Molteni, F. and Buizza, R. and Palmer, T. N. and Petroliagis, T.},
	doi = {https://doi.org/10.1002/qj.49712252905},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	pages = {73--119},
	title = {{The ECMWF Ensemble Prediction System: Methodology and validation}},
	volume = {122},
	year = {1996}
}
@article{Nevo2022,
	archivePrefix = {arXiv},
	arxivId = {2111.02780},
	author = {Nevo, Sella and Morin, Efrat and {Gerzi Rosenthal}, Adi and Metzger, Asher and Barshai, Chen and Weitzner, Dana and Voloshin, Dafi and Kratzert, Frederik and Elidan, Gal and Dror, Gideon and Begelman, Gregory and Nearing, Grey and Shalev, Guy and Noga, Hila and Shavitt, Ira and Yuklea, Liora and Royz, Moriah and Giladi, Niv and {Peled Levi}, Nofar and Reich, Ofir and Gilon, Oren and Maor, Ronnie and Timnat, Shahar and Shechter, Tal and Anisimov, Vladimir and Gigi, Yotam and Levin, Yuval and Moshe, Zach and Ben-Haim, Zvika and Hassidim, Avinatan and Matias, Yossi},
	doi = {10.5194/hess-26-4013-2022},
	eprint = {2111.02780},
	file = {:C$\backslash$:/Users/casadje/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nevo et al. - 2022 - Flood forecasting with machine learning models in an operational framework.pdf:pdf},
	issn = {16077938},
	journal = {Hydrology and Earth System Sciences},
	keywords = {LSTM,flood forecasting,machine learning},
	mendeley-tags = {LSTM,flood forecasting,machine learning},
	month = {aug},
	number = {15},
	pages = {4013--4032},
	publisher = {Copernicus GmbH},
	title = {{Flood forecasting with machine learning models in an operational framework}},
	volume = {26},
	year = {2022}
}
@article{Legg2004,
	abstract = {A system has been developed to give probabilistic warnings of severe-weather events for the United Kingdom (UK) on a regional and national basis, based on forecast output from the European Centre for Medium-Range Weather Forecasts (ECMWF) Ensemble Prediction System (EPS). The First-Guess Early Warnings (FGEW) project aims to give guidance to operational forecasters, to help them give earlier warning of severe weather in support of the UK National Severe Weather Warning Service (NSWWS). Calibration was applied to the EPS model output to optimize the probabilistic early warnings over an initial training period of one winter season, and the resulting warnings were then verified over a 16-month period spanning two winter seasons. The skill of warnings from several versions of FGEW is assessed using a range of probabilistic skill scores, and is also compared with that of warnings issued by forecasters. Results show that the system is capable of providing useful warnings 3-4 days ahead with some probabilistic skill. Most of the skill is attributable to warnings issued at low probabilities, but when higher probabilities do occur, this provides a valuable signal that has been used by forecasters on a number of occasions to issue warnings earlier than was done previously. Maximum skill of the FGEW warnings is found at a lead time of 4 days, with virtually no skill at shorter lead times of 1 or 2 days. This behavior is found to also occur in equivalent deterministic forecasts and so is not attributable to the ensemble perturbation strategy. Nevertheless it is suggested that while the EPS perturbations work well for the medium range, alternative perturbation strategies may be required for successful short-range ensemble prediction.},
	author = {Legg, T P and Mylne, K R},
	journal = {Weather and Forecasting},
	number = {5},
	pages = {891--906},
	title = {{Early Warnings of Severe Weather from Ensemble Forecast Information}},
	volume = {19},
	year = {2004}
}
@article{Pagano2014,
   abstract = {Skillful and timely streamflow forecasts are critically important to water managers and emergency protection services. To provide these forecasts, hydrologists must predict the behavior of complex coupled human–natural systems using incomplete and uncertain information and imperfect models. Moreover, operational predictions often integrate anecdotal information and unmodeled factors. Forecasting agencies face four key challenges: 1) making the most of available data, 2) making accurate predictions using models, 3) turning hydrometeorological forecasts into effective warnings, and 4) administering an operational service. Each challenge presents a variety of research opportunities, including the development of automated quality-control algorithms for the myriad of data used in operational streamflow forecasts, data assimilation, and ensemble forecasting techniques that allow for forecaster input, methods for using human-generated weather forecasts quantitatively, and quantification of human interference in the hydrologic cycle. Furthermore, much can be done to improve the communication of probabilistic forecasts and to design a forecasting paradigm that effectively combines increasingly sophisticated forecasting technology with subjective forecaster expertise. These areas are described in detail to share a real-world perspective and focus for ongoing research endeavors.},
   author = {Thomas C. Pagano and Andrew W. Wood and Maria-Helena Ramos and Hannah L. Cloke and Florian Pappenberger and Martyn P. Clark and Michael Cranston and Dmitri Kavetski and Thibault Mathevet and Soroosh Sorooshian and Jan S. Verkade},
   doi = {10.1175/jhm-d-13-0188.1},
   issn = {1525-755X},
   issue = {4},
   journal = {Journal of Hydrometeorology},
   month = {8},
   pages = {1692-1707},
   publisher = {American Meteorological Society},
   title = {Challenges of Operational River Forecasting},
   volume = {15},
   year = {2014},
}
@article{Pappenberger2008,
   abstract = {All major weather forecast centres verify meteorological forecasts as a normal part of their operational duties, with verifications usually based on variables and methods of meteorological relevance. These forecasts are then often used to drive hydrological models, and this article demonstrates that a considerable gap exists between current meteorological practice and hydrological needs. This article discusses this gap in terms of the type of variables; the domain and resolution; the importance of choosing appropriate thresholds; and the smoothing and accumulation period. A list of recommendations for a user‐focused evaluation is given in the conclusions. We suggest that the meteorological community, and specifically the forecast centres, should consider making these adjustments and producing additional products suitable for hydrological applications. Copyright © 2008 Royal Meteorological Society},
   author = {F. Pappenberger and K. Scipal and R. Buizza},
   doi = {10.1002/asl.171},
   issn = {1530-261X},
   issue = {2},
   journal = {Atmospheric Science Letters},
   month = {4},
   pages = {43-52},
   publisher = {Wiley},
   title = {Hydrological aspects of meteorological verification},
   volume = {9},
   year = {2008},
}
@article{Pappenberger2015a,
	abstract = {The skill of a forecast can be assessed by comparing the relative proximity of both the forecast and a benchmark to the observations. Example benchmarks include climatology or a na{\"{i}}ve forecast. Hydrological ensemble prediction systems (HEPS) are currently transforming the hydrological forecasting environment but in this new field there is little information to guide researchers and operational forecasters on how benchmarks can be best used to evaluate their probabilistic forecasts. In this study, it is identified that the forecast skill calculated can vary depending on the benchmark selected and that the selection of a benchmark for determining forecasting system skill is sensitive to a number of hydrological and system factors. A benchmark intercomparison experiment is then undertaken using the continuous ranked probability score (CRPS), a reference forecasting system and a suite of 23 different methods to derive benchmarks. The benchmarks are assessed within the operational set-up of the European Flood Awareness System (EFAS) to determine those that are 'toughest to beat' and so give the most robust discrimination of forecast skill, particularly for the spatial average fields that EFAS relies upon.Evaluating against an observed discharge proxy the benchmark that has most utility for EFAS and avoids the most na{\"{i}}ve skill across different hydrological situations is found to be meteorological persistency. This benchmark uses the latest meteorological observations of precipitation and temperature to drive the hydrological model. Hydrological long term average benchmarks, which are currently used in EFAS, are very easily beaten by the forecasting system and the use of these produces much na{\"{i}}ve skill. When decomposed into seasons, the advanced meteorological benchmarks, which make use of meteorological observations from the past 20. years at the same calendar date, have the most skill discrimination. They are also good at discriminating skill in low flows and for all catchment sizes. Simpler meteorological benchmarks are particularly useful for high flows. Recommendations for EFAS are to move to routine use of meteorological persistency, an advanced meteorological benchmark and a simple meteorological benchmark in order to provide a robust evaluation of forecast skill. This work provides the first comprehensive evidence on how benchmarks can be used in evaluation of skill in probabilistic hydrological forecasts and which benchmarks are most useful for skill discrimination and avoidance of na{\"{i}}ve skill in a large scale HEPS. It is recommended that all HEPS use the evidence and methodology provided here to evaluate which benchmarks to employ; so forecasters can have trust in their skill evaluation and will have confidence that their forecasts are indeed better.},
	author = {Pappenberger, F. and Ramos, M. H. and Cloke, H. L. and Wetterhall, F. and Alfieri, L. and Bogner, K. and Mueller, A. and Salamon, P.},
	doi = {10.1016/j.jhydrol.2015.01.024},
	file = {:C$\backslash$:/Users/casadje/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pappenberger et al. - 2015 - How do I know if my forecasts are better Using benchmarks in hydrological ensemble prediction.pdf:pdf},
	issn = {00221694},
	journal = {Journal of Hydrology},
	keywords = {Benchmark,Evaluation,Forecast performance,Hydrological ensemble prediction,Probabilistic forecasts,Verification,benchmark,evaluation,forecast performance,hydrological ensemle prediction,probabilistic forecasts,verification},
	mendeley-tags = {benchmark,evaluation,forecast performance,hydrological ensemle prediction,probabilistic forecasts,verification},
	month = {mar},
	pages = {697--713},
	publisher = {Elsevier},
	title = {{How do I know if my forecasts are better? Using benchmarks in hydrological ensemble prediction}},
	volume = {522},
	year = {2015}
	}
	@misc{ValueKeepa,
	author = {{Value Keep}},
	title = {{Value Keep}},
	url = {https://valuekeep.com/},
	year = {2022}
}
@article{Pappenberger2015b,
	abstract = {Effective disaster risk management relies on science-based solutions to close the gap between prevention and preparedness measures. The consultation on the United Nations post-2015 framework for disaster risk reduction highlights the need for cross-border early warning systems to strengthen the preparedness phases of disaster risk management, in order to save lives and property and reduce the overall impact of severe events. Continental and global scale flood forecasting systems provide vital early flood warning information to national and international civil protection authorities, who can use this information to make decisions on how to prepare for upcoming floods. Here the potential monetary benefits of early flood warnings are estimated based on the forecasts of the continental-scale European Flood Awareness System (EFAS) using existing flood damage cost information and calculations of potential avoided flood damages. The benefits are of the order of 400 Euro for every 1 Euro invested. A sensitivity analysis is performed in order to test the uncertainty in the method and develop an envelope of potential monetary benefits of EFAS warnings. The results provide clear evidence that there is likely a substantial monetary benefit in this cross-border continental-scale flood early warning system. This supports the wider drive to implement early warning systems at the continental or global scale to improve our resilience to natural hazards.},
	author = {Pappenberger, Florian and Cloke, Hannah L. and Parker, Dennis J. and Wetterhall, Fredrik and Richardson, David S. and Thielen, Jutta},
	doi = {10.1016/j.envsci.2015.04.016},
	file = {:C$\backslash$:/Users/casadje/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pappenberger et al. - 2015 - The monetary benefit of early flood warnings in Europe.pdf:pdf},
	issn = {18736416},
	journal = {Environmental Science and Policy},
	keywords = {EFAS,Europe,European Flood Awareness System,HEPEX,Hydrological Ensemble Prediction Experiment (HEPEX),Monetary benefit,Probabilistic flood forecasting,hydrological ensemble prediction,monetary benefit,probabilistic flood forecasting},
	mendeley-tags = {EFAS,Europe,HEPEX,hydrological ensemble prediction,monetary benefit,probabilistic flood forecasting},
	month = {aug},
	pages = {278--291},
	publisher = {Elsevier Ltd},
	title = {{The monetary benefit of early flood warnings in Europe}},
	volume = {51},
	year = {2015}
}
@article{Paprotny2018,
	abstract = {Adverse consequences of floods change in time and are influenced by both natural and socio-economic trends and interactions. In Europe, previous studies of historical flood losses corrected for demographic and economic growth ('normalized') have been limited in temporal and spatial extent, leading to an incomplete representation of trends in losses over time. Here we utilize a gridded reconstruction of flood exposure in 37 European countries and a new database of damaging floods since 1870. Our results indicate that, after correcting for changes in flood exposure, there has been an increase in annually inundated area and number of persons affected since 1870, contrasted by a substantial decrease in flood fatalities. For more recent decades we also found a considerable decline in financial losses per year. We estimate, however, that there is large underreporting of smaller floods beyond most recent years, and show that underreporting has a substantial impact on observed trends.},
	author = {Paprotny, Dominik and Sebastian, Antonia and Morales-N{\'{a}}poles, Oswaldo and Jonkman, Sebastiaan N.},
	doi = {10.1038/s41467-018-04253-1},
	file = {:C$\backslash$:/Users/casadje/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Paprotny et al. - 2018 - Trends in flood losses in Europe over the past 150 years.pdf:pdf},
	issn = {20411723},
	journal = {Nature Communications},
	keywords = {floods,losses},
	mendeley-tags = {floods,losses},
	month = {dec},
	number = {1},
	pmid = {29844471},
	publisher = {Nature Publishing Group},
	title = {{Trends in flood losses in Europe over the past 150 years}},
	volume = {9},
	year = {2018}
}
@article{Ramos2007,
   abstract = {The study presents the development of flood warning decision support products based on ensemble forecasts in the European Flood Alert System (EFAS). EFAS aims to extend the lead time of flood forecasts to 3-10 days in transnational river basins and complement Member States' activities on flood forecasting. Weather forecasts are used as input to a hydrological model and simulated discharges are evaluated for exceedances of flood thresholds. Products were developed in collaboration with users for a concise and useful visualization of probabilistic results. Forecasts of flood events observed in the Danube river basin in 2005 illustrate the analysis. Copyright © 2007 Royal Meteorological Society.},
   author = {Maria Helena Ramos and Jens Bartholmes and Jutta Thielen-del Pozo},
   doi = {10.1002/asl.161},
   issn = {1530261X},
   issue = {4},
   journal = {Atmospheric Science Letters},
   keywords = {Ensemble prediction,Flood forecasting,Uncertainty,Warning},
   month = {10},
   note = {<b>Objective</b><br/><br/>To develop informative decision support products derived from the ensemble hydrological forecast made by EFAS.<br/>An example case study was conducted for the Danube 2005 floods to specifically analyze the influence of the probability threshold in the hit, miss and false rates.<br/><br/><b>Notes</b><br/>At that time, the persistence      threshold in order to issue an alert was 2 consecutive forecasts.},
   pages = {113-119},
   title = {Development of decision support products based on ensemble forecasts in the European flood alert system},
   volume = {8},
   year = {2007},
}
@article{Raynaud2015,
   abstract = {Flash floods are listed among the deadliest and costliest weather-driven hazard worldwide. Yet, only a few systems to predict flash floods run operationally in Europe. Recently, the European Precipitation Index based on Climatology (EPIC) was developed and then set up for daily flash flood early warning for an area covering most of the continent. EPIC is a purely rainfall-driven indicator based on the prediction of statistical threshold exceedence of the upstream precipitation to provide early warning up to 5days in advance. Its main assumption is that flash floods are directly and solely related to extreme accumulations of upstream precipitation. It does not take into account any geo-factors such as slope and land use or processes such as initial soil moisture, which can have a significant impact on the triggering of such events. This study proposes an enhanced version of EPIC through a dynamic and distributed runoff co-efficient which depends on the initial soil moisture. This co-efficient, namely the European Runoff Index based on Climatology (ERIC), is used to weigh each contribution of the upstream precipitation proportionally to the initial soil moisture. The evaluation based on 1year of daily runs proved that ERIC reaches a threat score of 0.5 if it forecasts a probability >35% of exceeding the 20year return period of upstream runoff. This result is 0.16 higher than for EPIC. A case study of the flash flooding affecting central Europe in June 2013 demonstrated the ability of ERIC to successfully detect and locate the affected areas.},
   author = {D. Raynaud and J. Thielen and P. Salamon and P. Burek and S. Anquetin and L. Alfieri},
   doi = {10.1002/met.1469},
   issn = {14698080},
   issue = {3},
   journal = {Meteorological Applications},
   keywords = {Early warning,Flash flood,Probabilistic forecast,Runoff co-efficient,Ungauged basins},
   month = {7},
   note = {<b>Summary</b><br/>The article presents the European Runoff Index based on Climatoloty (ERIC) methodology to predict flash floods. The methods builds on the previous European Precipitation Index based on Climatology (EPIC), but instead of being based only in precipitation, it is based on runoff (precipitation * runoff coefficient).<br/><br/>The notification criteria are tested on a complete year of data using a data set of observed flash floods as comparison. The selected criteria is the 35% probability of exceeding the 20 year return period in at least two cells within a 30 km radius. Persistence was tested but skill degraded.<br/><br/>The paper also shows the performance of ERIC in a flash flood in June 2013 in Germany, Austria, Cezch Republic.},
   pages = {410-418},
   publisher = {John Wiley and Sons Ltd},
   title = {A dynamic runoff co-efficient to improve flash flood early warning in Europe: Evaluation on the 2013 central European floods in Germany},
   volume = {22},
   year = {2015},
}
@article{Roebber2009,
   abstract = {A method for visually representing multiple measures of dichotomous (yes-no) forecast quality (probability of detection, false alarm ratio, bias, and critical success index) in a single diagram is presented. Illustration of the method is provided using performance statistics from two previously published forecast verification studies (snowfall density and convective initiation) and a verification of several new forecast datasets: Storm Prediction Center forecasts of severe storms (nontornadic and tornadic), Hydrometeorological Prediction Center forecasts of heavy precipitation (greater than 12.5 mm in a 6-h period), National Weather Service Forecast Office terminal aviation forecasts (ceiling and visibility), and medium-range ensemble forecasts of 500-hPa height anomalies. The use of such verification metrics in concert with more detailed investigations to advance forecasting is briefly discussed. © 2009 American Meteorological Society.},
   author = {Paul J. Roebber},
   doi = {10.1175/2008WAF2222159.1},
   issn = {08828156},
   issue = {2},
   journal = {Weather and Forecasting},
   month = {4},
   pages = {601-608},
   title = {Visualizing multiple measures of forecast quality},
   volume = {24},
   year = {2009},
}
@article{Skoien2021,
   abstract = {Different postprocessing techniques are frequently employed to improve the outcome of ensemble forecasting models. The main reason is to compensate for biases caused by errors in model structure or initial conditions, and as a correction for under-or overdispersed ensembles. Here we use the ensemble model output statistics method to postprocess the ensemble output from a continental-scale hydrological model, LISFLOOD, as used in the European Flood Awareness System (EFAS). We develop a method for local calibration and interpolation of the postprocessing parameters and compare it with a more traditional global calibration approach for 678 stations in Europe based on long-term observations of runoff and meteorological variables. For the global calibration we also test a reduced model with only a variance inflation factor. Whereas the postprocessing improved the results for the first 1–2 days lead time, the improvement was less for increasing lead times of the verification period. This was the case both for the local and global calibration methods. As the postprocessing is based on assumptions about the distribution of forecast errors, we also present an analysis of the ensemble output that provides some indications of what to expect from the postprocessing.},
   author = {Jon Olav Skøien and Konrad Bogner and Peter Salamon and Fredrik Wetterhall},
   doi = {10.1175/JHM-D-21-0008.1},
   issn = {15257541},
   issue = {10},
   journal = {Journal of Hydrometeorology},
   keywords = {Ensembles,Forecasting,Interpolation schemes,Operational forecasting,Probability forecasts/models/distribution,Statistical techniques},
   month = {10},
   note = {<b>Objectives</b><br/><br/>*To interpolate locally calibrated postprocessing parameters with the geostatistical method  top-kriging.<br/>* To analyse the  effect of transformation methods such as Box-Cox or GEV in the forecast      skill.<br/><br/><b>Data</b><br/><br/><u>Forecast</u><br/><br/>3 years discharge      (2015-2017) with up to 10 days lead time simulated with LISFLOOD. A total      of 69 simulations: 1 ECMWF deterministic, 51 ECMWF stochastic, 1 DWD, 16      COSMO-LEPS<br/><br/><u>Observations</u><br/><br/>discharge proxy      simulated with LISFLOOD using interpolated observed precipitation and      temperature.<br/><br/><b>Methods</b><br/><br/><u>Transformations</u><br/><br/>To apply postprocessing data must be normally distributed. Several transformation methods are tested (normal score transformation, versions of Box-Cox transformation, versions of GEV...) on the discharge data.<br/><br/><u>Ensemble model output statistics (EMOS) </u>(Gneiting et al., 2005)<br/>Its objective is to minimize the continuous ranked probability score (CRPS). The forecast will be calculated as a weighted mean of the ensembles. Optimizing that linear equation will render an unbiased mean forecast, but variance must also be optimize, for which another linear approximation is used. In that way, the CRPS can be analitically solved supposing that the predictive distribution functions is normal.<br/>Top-kriging to interpolate parameters<br/>It is applied to spatial variables (in this case specific discharge) to include in the interpolation the varying spatial support.<br/><br/><u>EMOS calibration</u><br/><br/>* Global calibration: one set      of EMOS parameters for the entire region<br/>* Local calibration:      individually for each location. To avoid equifinality, a spatial penalty      is tested, to induce the calibration into similar parameter sets in      neighboring catchments.<br/>* SCEUA<br/>* 1 year calibration      period<br/><br/><u>Validation</u><br/><br/>* Case 1:  difference in the calibration results between methods.<br/>* Case 2: cross-validation to identify sources of error.<br/>* Case 3: temporal verification.<br/>* Case 4: spatiotemporal cross-validation.<br/><br/>The score used is the continuous ranked probability skill score (CRPSS). The benchmark is the mean of the forecasts (ensembles are previously averaged) and the variance of a global ensemble. They also use probability integral transformation (PIT) as a visual indicator.<br/><br/><b>Conclusions:</b><br/><br/><u>Objective 1</u><br/><br/>the spatial      interpolation of parameters could be useful if there was stronger need for      postprocessing<br/><br/><u>Objective 2</u><br/><br/>none of the      transformations give substantially better results<br/>Since an operational service requires simplicity, only calibration the variance inflation factor would be the best option.},
   pages = {2731-2749},
   publisher = {American Meteorological Society},
   title = {On the Implementation of Postprocessing of Runoff Forecast Ensembles},
   volume = {22},
   year = {2021},
}
@article{Thielen2009a,
   abstract = {This paper presents the development of the Eu-ropean Flood Alert System (EFAS), which aims at increasing preparedness for floods in trans-national European river basins by providing local water authorities with medium-range and probabilistic flood forecasting information 3 to 10 days in advance. The EFAS research project started in 2003 with the development of a prototype at the European Commission Joint Research Centre (JRC), in close collaboration with the national hydrological and meteorological services. The prototype covers the whole of Europe on a 5 km grid. In parallel, different high-resolution data sets have been collected for the Elbe and Danube river basins, allowing the potential of the system under optimum conditions and on a higher resolution to be assessed. Flood warning lead-times of 3-10 days are achieved through the incorporation of medium-range weather forecasts from the Ger-man Weather Service (DWD) and the European Centre for Medium-Range Weather Forecasts (ECMWF), comprising a full set of 51 probabilistic forecasts from the Ensemble Prediction System (EPS) provided by ECMWF. The ensemble of different hydrographs is analysed and combined to produce early flood warning information, which is disseminated to the hydrological services that have agreed to participate in the development of the system. In Part 1 of this paper, the scientific approach adopted in the development of the system is presented. The rational of the project, the systems setup , its underlying components, basic principles and products are described. In Part 2, results of a detailed statistical analysis of the performance of the system are shown, with regard to both probabilistic and deterministic forecasts.},
   author = {J Thielen and J Bartholmes and M.-H Ramos and A De Roo},
   doi = {10.5194/hess-13-125-2009},
   journal = {Hydrol. Earth Syst. Sci},
   pages = {125-140},
   title = {The European Flood Alert System – Part 1: Concept and development},
   volume = {13},
   url = {www.hydrol-earth-syst-sci.net/13/125/2009/},
   year = {2009},
}
@article{Thielen2009b,
   abstract = {This paper describes a case study that explores the limits of the predictability of floods, by combining forecasts with multiple spatial and temporal resolutions. Monthly, medium- and short range numerical weather prediction (NWP) data are input to the European Flood Alert System for a flood event that affected rivers in Romania in October 2007. The NWP data comprise ensembles and deterministic forecasts of different spatial resolutions and lead times from different weather prediction models. Results are explored in terms of the individual NWP components as well as the ensemble. In this case study, ensembles of monthly weather forecasts contribute only marginally to the early warning, although some indication is given as early as 3 weeks before the event. The 15-day medium-range weather forecasts produce early flood warning information 9 to 11 days in advance. As the event draws nearer and is in range to be captured by the higher resolution ensemble forecasts, the spatial extent of the event is forecast with much more precision than with the medium-range. A novel post-processing method for the calculation of river discharge is applied to those stations where observations are available, and is able to correct for time-shifts and to improve the quantitative forecast. The study illustrates how a combination of forecasts and post-processing improves the lead time for early flood warnings by 2 to 3 days, while remaining reliable also in the short-range. © 2009 Royal Meteorological Society.},
   author = {J. Thielen and K. Bogner and F. Pappenberger and M. Kalas and M. del Medico and A. de Roo},
   doi = {10.1002/met.140},
   issn = {14698080},
   issue = {1},
   journal = {Meteorological Applications},
   keywords = {ARMAXSS,COSMO-LEPS,Discharge post-processing,ECMWF,EFAS,Early flood warning,Ensemble flood forecasting,Skill scores},
   note = {<b>Objective:</b><br/>To explore the predictability of floods using forecast of different nature (probabilistic or deterministic) and lead time (monthly, medium-range and short-range).<br/>To analyze the ability of post-processing to improve quantitatively forecasts.<br/><b>Data:</b><br/><br/>They analyze a flood event in the Danube river in Romania in October 2007.<br/><br/><b>Conclusions:</b><br/>Monthly forecasts can indicate potential flooding with 3-4 weeks in advance, but without a precise location in space and time.<br/>Medium-range forecasts show good results qualitative and quantitatively, being able to predict floods 7-9 days in advance.<br/>Deterministic forecasts are less coherent than probabilistic ones. This is applicable both at medium and short-range forecasts.<br/>Post-processing discharge ensembles can reduce uncertainty.},
   pages = {77-90},
   publisher = {John Wiley and Sons Ltd},
   title = {Monthly-, medium-, and short-range flood warning: Testing the limits of predictability},
   volume = {16},
   year = {2009},
}
@techreport{UN2023,
	author = {Egerton, Paul and Stander, Johan and Paterson, Laura and Devillier, Rose and Champagne-Fall, Annick and Honore, Cyrille and Allis, Erica and Love, Geoff and Nitu, Rodica and Stuart, Lauren and Kaya, Fatih and Santamaria, Lorena and Teruggi, Giacomo and Taalas, Petteri and Rea, Anthony and Lucio, Filipe and Harding, John and Repnik, Markus and Luterbacher, Juerg and Alexieva, Assia and Gonsior, Henriette and Uhlenbrook, Stefan and Cullmann, Johannes and Lombardi, Niccolo and Dunja, Dujanovic and Pfister, Daniel and Zommers, Zinta and {Escobar Rodriguez}, Hernani and Jacob, Arun and Keo, Kaylan},
	file = {:C$\backslash$:/Users/casadje/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Egerton et al. - 2023 - Eartly warnings for all. Executive action plan 2023-2027.pdf:pdf},
	institution = {Unitated Nations},
	keywords = {early warning systems},
	mendeley-tags = {early warning systems},
	title = {{Early warnings for all. Executive action plan 2023-2027}},
	url = {https://www.un.org/en/climatechange/early-warnings-for-all},
	year = {2023}
}
@article{Wetterhall2013,
   abstract = {Hydrological ensemble prediction systems (HEPS) have in recent years been increasingly used for the operational forecasting of floods by European hydrometeorological agencies. The most obvious advantage of HEPS is that more of the uncertainty in the modelling system can be assessed. In addition, ensemble prediction systems generally have better skill than deterministic systems both in the terms of the mean forecast performance and the potential forecasting of extreme events. Research efforts have so far mostly been devoted to the improvement of the physical and technical aspects of the model systems, such as increased resolution in time and space and better description of physical processes. Developments like these are certainly needed; however, in this paper we argue that there are other areas of HEPS that need urgent attention. This was also the result from a group exercise and a survey conducted to operational forecasters within the European Flood Awareness System (EFAS) to identify the top priorities of improvement regarding their own system. They turned out to span a range of areas, the most popular being to include verification of an assessment of past forecast performance, a multi-model approach for hydrological modelling, to increase the forecast skill on the medium range (>3 days) and more focus on education and training on the interpretation of forecasts. In light of limited resources, we suggest a simple model to classify the identified priorities in terms of their cost and complexity to decide in which order to tackle them. This model is then used to create an action plan of short-, medium- and long-term research priorities with the ultimate goal of an optimal improvement of EFAS in particular and to spur the development of operational HEPS in general. © 2013 Author(s).},
   author = {F. Wetterhall and F. Pappenberger and L. Alfieri and H. L. Cloke and J. Thielen-Del Pozo and S. Balabanova and J. Daňhelka and A. Vogelbacher and P. Salamon and I. Carrasco and A. J. Cabrera-Tordera and M. Corzo-Toscano and M. Garcia-Padilla and R. J. Garcia-Sanchez and C. Ardilouze and S. Jurela and B. Terek and A. Csik and J. Casey and G. Stankunavičius and V. Ceres and E. Sprokkereef and J. Stam and E. Anghel and D. Vladikovic and C. Alionte Eklund and N. Hjerdt and H. Djerv and F. Holmberg and J. Nilsson and K. Nyström and M. Sušnik and M. Hazlinger and M. Holubecka},
   doi = {10.5194/hess-17-4389-2013},
   issn = {16077938},
   issue = {11},
   journal = {Hydrology and Earth System Sciences},
   pages = {4389-4399},
   publisher = {European Geosciences Union},
   title = {HESS Opinions "forecaster priorities for improving probabilistic flood forecasts"},
   volume = {17},
   year = {2013},
}
@techreport{WMO2021,
	address = {Geneva},
	author = {WMO},
	file = {:C$\backslash$:/Users/casadje/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2021 - WMO Atlas of mortality and economic losses from weather, climate and water extremes (1970-2019).pdf:pdf},
	institution = {World Meteorological Organization},
	keywords = {extremes,losses,mortality},
	mendeley-tags = {extremes,losses,mortality},
	title = {{WMO Atlas of mortality and economic losses from weather, climate and water extremes (1970-2019)}},
	year = {2021}
}
@article{Yang2020,
	abstract = {Hydrological ensemble prediction systems (HEPSs) can provide decision makers with early warning information, such as peak stage and peak time, with enough lead time to take the necessary measures to mitigate disasters. This study develops a HEPS that integrates meteorological, hydrological, storm surge, and global tidal models. It is established to understand information about the uncertainty of numerical weather predictions and then to provide probabilistic flood forecasts instead of commonly adopted deterministic forecasts. The accuracy of flood forecasting is increased. However, the spatiotemporal uncertainty associated with these numerical models in the HEPS and the difficulty in interpreting the model results hinder effective decision-making during emergency response situations. As a result, the efficiency of decision-making is not always increased. Thus, this study also presents a visualization method to interpret the ensemble results to enhance the understanding of probabilistic runoff forecasts for operational purposes. A small watershed with area of 100 km2 and four historical typhoon events were selected to evaluate the performance of the method. The results showed that the proposed HEPS along with the visualization approach improved the intelligibility of forecasts of the peak stages and peak times compared to that of approaches previously described in the literature. The capture rate is greater than 50{\%}, which is considered practical for decision makers. The proposed HEPS with the visualization method has potential for both decreasing the uncertainty of numerical rainfall forecasts and improving the efficiency of decision-making for flood forecasts.},
	author = {Yang, Sheng Chi and Yang, Tsun Hua and Chang, Ya Chi and Chen, Cheng Hsin and Lin, Mei Ying and Ho, Jui Yi and Lee, Kwan Tun},
	doi = {10.3390/su12104258},
	file = {:C$\backslash$:/Users/casadje/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2020 - Development of a hydrological ensemble prediction system to assist with decision-making for floods during typhoons.pdf:pdf},
	issn = {20711050},
	journal = {Sustainability (Switzerland)},
	keywords = {Flood forecast,Hydrological ensemble prediction system,Numerical weather model,Peak flow,Visualization,flood forecast,hydrological ensemble prediction system,numerical weather model,peak flow,visualization},
	mendeley-tags = {flood forecast,hydrological ensemble prediction system,numerical weather model,peak flow,visualization},
	month = {may},
	number = {10},
	publisher = {MDPI},
	title = {{Development of a hydrological ensemble prediction system to assist with decision-making for floods during typhoons}},
	volume = {12},
	year = {2020}
}