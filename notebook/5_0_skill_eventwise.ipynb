{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fd5f453-13c1-47c1-ad27-8af80b47ee08",
   "metadata": {},
   "source": [
    "# Skill assessment - eventwise\n",
    "***\n",
    "\n",
    "**Author**: Chus Casado Rodr√≠guez<br>\n",
    "**Date**: 24-02-2023<br>\n",
    "\n",
    "\n",
    "**Introduction**:<br>\n",
    "\n",
    "\n",
    "**Questions**:<br>\n",
    "* [x] Weighting the model average by the Brier score?\n",
    "* [ ] Take into account the model spread?\n",
    "* [ ] Sort stations by catchment area (or other order)?\n",
    "* [ ] Persistence\n",
    "\n",
    "**Tasks to do**:<br>\n",
    "* What's `pred_event` for?\n",
    "\n",
    "**Interesting links**<br>\n",
    "[Evaluation metrics for imbalanced classification](https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/)<br>\n",
    "[Cross entropy for machine learning](https://machinelearningmastery.com/cross-entropy-for-machine-learning/)<br>\n",
    "[Probability metrics for imbalanced classification](https://machinelearningmastery.com/probability-metrics-for-imbalanced-classification/)<br>\n",
    "[ROC curves and precision-recall curves for imbalanced classification](https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4ee7a0f-f62b-4a8b-8147-c46a2e2471ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.patches import Rectangle\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "from datetime import datetime, timedelta\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix\n",
    "\n",
    "path_root = os.getcwd()\n",
    "path_forecast = '../data/CDS/forecast/'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas as gpd\n",
    "\n",
    "os.chdir('../py/')\n",
    "from notifications import *\n",
    "os.chdir(path_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ca1667-e5d2-45fb-83a1-647f9c9c4e7a",
   "metadata": {},
   "source": [
    "## 1 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6b62184-ec03-4b23-9797-ca274f1ab1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'EFAS'\n",
    "results_path = '../results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "819da3ad-ac4a-4f67-8c32-f4302d27bba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path where results will be saved\n",
    "path_out = f'{results_path}skill/{name}/'\n",
    "if os.path.exists(path_out) is False:\n",
    "    os.makedirs(path_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbf9fefe-8375-44af-b1c0-f1886b763c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coordinate reference system when plotting maps\n",
    "proj = ccrs.LambertAzimuthalEqualArea(central_longitude=10, central_latitude=52, false_easting=4321000, false_northing=3210000, globe=ccrs.Globe(ellipse='GRS80'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b284a86-2d64-4907-a259-e3c67b6de2d5",
   "metadata": {},
   "source": [
    "### 1.1 Stations\n",
    "\n",
    "I load all the stations that where selected in a previous [notebook](3_0_select_stations_loop.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad2ba6a-e095-4c1c-8f2c-3738dee497be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. stations:\t\t\t900\n"
     ]
    }
   ],
   "source": [
    "# load selected points for all the catchments\n",
    "stations = pd.DataFrame()\n",
    "catchments = []\n",
    "folders = os.listdir(f'{results_path}select_reporting_points/')\n",
    "for folder in folders:\n",
    "    try:\n",
    "        stn_cat = pd.read_csv(f'{results_path}select_reporting_points/{folder}/points_selected.csv', index_col='station_id')\n",
    "        stations = pd.concat((stations, stn_cat))\n",
    "        catchments.append(folder)\n",
    "    except:\n",
    "        continue\n",
    "print('no. stations:\\t\\t\\t{0}'.format(stations.shape[0]))\n",
    "\n",
    "# add columns where skill will be saved\n",
    "new_cols = [f'f1_{model}' for model in ['current', 'model_mean', 'member_weighted']]\n",
    "stations[new_cols] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23e20cb7-24f3-4aff-8c28-744b9485a1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # shapefile with rivers\n",
    "# rivers_shp = gpd.read_file(f'../data/GIS/RiversForWebPage_EU_ready.shp')\n",
    "# mask = rivers_shp.BASIN.isin(catchments)\n",
    "# rivers_shp = rivers_shp.loc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c23cc9-47d1-45a9-9387-66788d90aed1",
   "metadata": {},
   "source": [
    "### 1.2 Reanalysis: exceedance & events\n",
    "\n",
    "I load the preprocessed reanalysis data. In a previous [notebook](2_2_reanalysis_preprocessing.ipynb), the reanalysis discharge data was preprocessed to create timeseries of exceedance over the 5-year return period threshold.\n",
    "\n",
    "Out of the exceedance timeseries I calculate another timeseries of the onset of flood events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb5e7285-b789-4c55-b965-74c7d23c43fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_reanalysis = '../data/exceedance/reanalysis/'\n",
    "\n",
    "# load probability of exceeding the discharge threshold in the REANALYSIS data\n",
    "rean_exc = pd.read_parquet(f'{path_reanalysis}/exceedance_rl5.parquet')\n",
    "rean_exc.columns = rean_exc.columns.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f12e2cbf-4c0b-453b-acfa-02be936c5ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2274 in rean_exc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aab4f5f2-87f8-41ba-ab74-22f405a917f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   1,    2,    3,    4,    5,    9,   11,   12,   13,   14,\n",
       "            ...\n",
       "            5220, 5221, 5223, 5224, 5225, 5226, 5228, 5230, 5231, 5232],\n",
       "           dtype='int64', name='station_id', length=2219)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rean_exc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1fead8e-4571-48b3-9337-3e4f572197c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([2184, 2020, 1898, 3221, 3219, 2021, 2008, 2149, 3081, 1199,\n",
       "            ...\n",
       "            5145, 4416, 2159, 2158, 2024, 2160, 2163, 2012, 2587, 2490],\n",
       "           dtype='int64', name='station_id', length=900)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f8e3071-991d-4f8d-b16d-35a01864c7d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[2274, 2390, 795, 793, 229, 251, 255, 713, 700, 703, 291, 292, 665, 97, 278, 277, 155, 914, 223, 1716, 3018, 601, 599, 637, 2173, 10, 152, 2755, 593, 1016, 969, 988, 3011, 2862, 2131, 3007, 124, 2009, 2866, 2611, 1959, 535, 541, 2191, 426, 2597, 2022, 922, 2931, 359, 369, 2916, 1121, 2197, 2758, 2756, 2352, 2889, 2271] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#start, end = datetime(2021, 1, 1, 6), datetime(2022, 1, 1, 6) + timedelta(hours=39*6)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m start, end \u001b[38;5;241m=\u001b[39m datetime(\u001b[38;5;241m2021\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m6\u001b[39m), datetime(\u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m31\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m rean_exc \u001b[38;5;241m=\u001b[39m \u001b[43mrean_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\pandas\\core\\indexing.py:961\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m--> 961\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m    964\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\pandas\\core\\indexing.py:1149\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[0;32m   1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take(tup)\n\u001b[1;32m-> 1149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple_same_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\pandas\\core\\indexing.py:827\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_null_slice(key):\n\u001b[0;32m    825\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 827\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mretval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;66;03m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m retval\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\pandas\\core\\indexing.py:1132\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1132\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1134\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m )\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\pandas\\core\\indexing.py:1327\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1324\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1325\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1327\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5784\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5786\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5845\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5844\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 5845\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: '[2274, 2390, 795, 793, 229, 251, 255, 713, 700, 703, 291, 292, 665, 97, 278, 277, 155, 914, 223, 1716, 3018, 601, 599, 637, 2173, 10, 152, 2755, 593, 1016, 969, 988, 3011, 2862, 2131, 3007, 124, 2009, 2866, 2611, 1959, 535, 541, 2191, 426, 2597, 2022, 922, 2931, 359, 369, 2916, 1121, 2197, 2758, 2756, 2352, 2889, 2271] not in index'"
     ]
    }
   ],
   "source": [
    "#start, end = datetime(2021, 1, 1, 6), datetime(2022, 1, 1, 6) + timedelta(hours=39*6)\n",
    "start, end = datetime(2021, 1, 1, 6), datetime(2022, 12, 31)\n",
    "rean_exc = rean_exc.loc[start:end, stations.index.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6ed42e-9e46-4e3f-9a35-b139573b579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load probability of exceeding the discharge threshold in the REANALYSIS data\n",
    "# rean_onsets = pd.read_parquet(f'{path_reanalysis}/events_rl5.parquet')\n",
    "# rean_onsets.columns = rean_onsets.columns.astype(int)\n",
    "# rean_onsets = rean_onsets.loc[start:end, stations.index.tolist()]\n",
    "rean_onsets = rean_exc.astype(int).diff(axis=0) == 1\n",
    "rean_onsets.iloc[0,:] = rean_exc.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b61dee1-5fc9-40e0-a24d-d24ff611e24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataArray with the number of observed events per station\n",
    "n_events_obs = xr.DataArray(rean_onsets.sum(), dims=['id'], coords={'id': rean_onsets.columns.tolist()})\n",
    "print('no. events:\\t\\t\\t{0}'.format(n_events_obs.sum().data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ef83ff-1fa3-4fb4-899b-70a79c0c55d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select stations with events\n",
    "mask_stn = (n_events_obs > 0).to_pandas()\n",
    "print('no. stations with events:\\t{0}'.format(mask_stn.sum()))\n",
    "# stations = stations.loc[mask_stn,:]\n",
    "# rean_exc = rean_exc.loc[:,mask_stn]\n",
    "# rean_onsets = rean_onsets.loc[:,mask_stn]\n",
    "# print('no. stations with events:\\t{0}'.format(stations.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f0d09d-4409-4e98-a669-acc93be12255",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab4468e-041a-4216-9b82-7cd97a2ea63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rean_onsets.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71044fa7-6fc8-48f8-b355-c552222a91d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3784d69-489e-4e6a-8077-1561f0e5348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colormap used for the maps\n",
    "cmap = plt.cm.coolwarm\n",
    "cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "cmap = mpl.colors.LinearSegmentedColormap.from_list('no. events', cmaplist, cmap.N)\n",
    "bounds = np.arange(1, 7, 1)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7336fd1-3271-4b7d-971b-4c43576a0eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_map_stations(stations.X, stations.Y, rean_onsets.sum(), mask=~mask_stn,\n",
    "                  cmap=cmap, norm=norm, size=5, figsize=(8, 8))\n",
    "plt.colorbar(plot_map_stations.colorbar, shrink=.33, label='no. events');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73af3e62-38f7-4aab-8b03-7f13464140d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_map_f1(stations.X, stations.Y, rean_onsets.sum(), mask=mask_stn, s=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccda4dbe-2b16-46fd-b057-6d7dd431fae8",
   "metadata": {},
   "source": [
    "### 1.3 Exceedance forecast\n",
    "\n",
    "I load the preprocessed forecast data. In a previous [notebook](4_0_forecast_exceedance_review.ipynb), the forecasted discharge was converted to probability of exceeding the 5-year return period threshold. The ouput of that process is a NetCDF file per station with the forecasted probability of exceedance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f8870a-1354-474e-a119-0dc9876ed3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "models = {'COS': {'members': 20, 'leadtimes': 23},\n",
    "          'DWD': {'members': 1, 'leadtimes': 29},\n",
    "          'EUD': {'members': 1, 'leadtimes': 40},\n",
    "          'EUE': {'members': 51, 'leadtimes': 40},}\n",
    "\n",
    "min_leadtime = min([models[m]['leadtimes'] for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf58032a-a82c-41db-9a48-f86a3dc0a242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load probability of exceeding the discharge threshold in the FORECAST data\n",
    "path_forecast = '../data/exceedance/forecast/'\n",
    "\n",
    "fore_exc = {}\n",
    "for stn in stations.index:\n",
    "    da = xr.open_dataarray(f'{path_forecast}{stn:04d}.nc')\n",
    "    if 'id' in da.coords:\n",
    "        da = da.drop_vars('id')\n",
    "    fore_exc[stn] = da\n",
    "    da.close()\n",
    "\n",
    "# convert into a Dataset\n",
    "stn = stations.index[0]\n",
    "fore_exc = xr.Dataset(fore_exc, coords={'model': fore_exc[stn].model,\n",
    "                                        'forecast': fore_exc[stn].forecast,\n",
    "                                        'leadtime': fore_exc[stn].leadtime})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b14c06-ce43-4cda-8ba9-d3aab511f223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataArray with weights for each model and leadtime\n",
    "weights = np.zeros((len(fore_exc.model), len(fore_exc.leadtime)))\n",
    "for i, (key, value) in enumerate(models.items()):\n",
    "    leadtimes = value['leadtimes']\n",
    "    members = value['members']\n",
    "    weights[i,:leadtimes] = members\n",
    "weights = xr.DataArray(weights, coords={'model': list(models), 'leadtime': fore_exc.leadtime})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e91ac9-ff24-4cfd-aa65-3c98f8a27001",
   "metadata": {},
   "source": [
    "## 2 Compute events\n",
    "\n",
    "In this section I will create two boolean _DataArray_ with the onset of flood events, i.e., a matrix of zeros and ones where a one means the beginning of a flood.\n",
    "\n",
    "* `obs_onsets` is a _DataArray_ with three dimensions that contains the \"observed\" events: \n",
    "    * `id`: the stations ID\n",
    "    * `forecast`: the timestamp of the beginning of the forecast\n",
    "    * `leadtime`: the timedelta of the specific timestep. The addition of forecast and leadtime renders the actual date and time of the timestep\n",
    "* `pred_events` is a _DataArray_ with five dimensions that contains the forecasted events:\n",
    "    * `id`\n",
    "    * `forecast`\n",
    "    * `leadtime`\n",
    "    * `model` corresponds to the different procedures to compute the occcurrence of events.\n",
    "        * `current` is the current EFAS criteria, i.e., at least a deterministic model must predict the flood, and one of the probabilistic models must predict a probability of event higher than a probability threshold.\n",
    "        * `model_mean` computes total probability giving the same weight to every model, i.e., 25% weight to each of the 4 meteorological forcings.\n",
    "        * `member_weighted` computes total probability giving the same weight to each run, i.e., probabilistic models (with more than 1 run) have a higher weight.\n",
    "    * `probability` are different thresholds to consider a flood event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2151f526-0440-4c71-9f47-1c3df76f871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dprobability thresholds\n",
    "thresholds = np.arange(0.05, .96, .05).round(2)\n",
    "probabilities = xr.DataArray(thresholds, dims=['probability'], coords={'probability': thresholds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac0e628-5f66-4c52-9700-353bbfaff230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OBSERVED EVENTS & ONSETS\n",
    "# # ........................\n",
    "    \n",
    "# obs_onsets = {}\n",
    "# obs_events = {}\n",
    "# for i, stn in enumerate(stations.index): \n",
    "#     # find onsets\n",
    "#     mask = rean_onsets[stn]\n",
    "#     onsets = rean_onsets.index[mask].tolist()\n",
    "#     obs_onsets[stn] = dataarray_events(onsets, fore_exc.forecast, fore_exc.leadtime)\n",
    "    \n",
    "#     # find events\n",
    "#     mask = rean_exc[stn]\n",
    "#     exc = rean_exc.index[mask].tolist()\n",
    "#     # create DataArray of the occurrence of events\n",
    "#     obs_events[stn] = dataarray_events(exc, fore_exc.forecast, fore_exc.leadtime)\n",
    "    \n",
    "# obs_onsets = xr.Dataset(obs_onsets).to_array(dim='id', name='events')\n",
    "# obs_events = xr.Dataset(obs_events).to_array(dim='id', name='events')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9deffee-a2d2-4e6c-bbd9-8e8b7ea7ed12",
   "metadata": {},
   "source": [
    "```Python\n",
    "stn = 119\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, figsize=(16, 8), sharex=True, sharey=True)\n",
    "\n",
    "for ax, da in zip(axes, [obs_events.sel(id=stn), obs_onsets.sel(id=stn)]):\n",
    "    sns.heatmap(da.transpose(), ax=ax, cmap='Blues')\n",
    "    ax.tick_params(length=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a5bb7b-7816-4784-a474-b50fb3d3eab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PREDICTED EVENTS & ONSETS\n",
    "# # .........................\n",
    "\n",
    "# # CURRENT CRITERIA\n",
    "\n",
    "# # compute events for each probability threshold\n",
    "\n",
    "# # compute exceendace of probability thresholds\n",
    "# current = fore_exc.to_array(dim='id', name='current')\n",
    "# exceedance0 = current > probabilities\n",
    "# # find where the deterministic criteria was fulfilled\n",
    "# deterministic = exceedance0.sel(model=['DWD', 'EUD']).sum('model')\n",
    "# # find where the probabilistic criteria was fulfilled\n",
    "# probabilistic = exceedance0.sel(model=['COS', 'EUE']).sum('model')\n",
    "# # find where both the deterministic and the probabilistic criteria was fulfilled\n",
    "# events0 = ((deterministic >= 1) & (probabilistic >= 1))\n",
    "\n",
    "# # compute the onset of events for each probability threshold\n",
    "\n",
    "# steps0 = events0.astype(int).diff('leadtime') == 1\n",
    "# step0_0 = events0.isel(leadtime=0)\n",
    "# onsets0 = xr.concat((step0_0, steps0), 'leadtime')\n",
    "\n",
    "# # NEW CRITERIA\n",
    "\n",
    "# # compute events for each probability threshold and two new criteria: model mean, weighted mean\n",
    "# model_mean = fore_exc.mean('model').to_array(dim='id', name='model_mean')\n",
    "# member_weighted = fore_exc.weighted(weights).mean('model').to_array(dim='id', name='member_weighted')\n",
    "# exceedance12 = xr.merge([model_mean, member_weighted])\n",
    "# events12 = exceedance12 > probabilities\n",
    "\n",
    "# # compute the onset of events for each probability threshold\n",
    "# steps12 = events12.astype(int).diff('leadtime') == 1\n",
    "# step12_0 = events12.isel(leadtime=0)\n",
    "# onsets12 = xr.concat((step12_0, steps12), 'leadtime')\n",
    "\n",
    "# # join the three criteria\n",
    "# pred_events = xr.merge([events0.to_dataset(name='current'), events12]).to_array(dim='model', name='events')\n",
    "# pred_onsets = xr.merge([onsets0.to_dataset(name='current'), onsets12]).to_array(dim='model', name='onsets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c9a1f0-2e0d-475a-9b19-cc35c9ff5b6b",
   "metadata": {},
   "source": [
    "## 3 Assess skill\n",
    "\n",
    "In this section I will compute the skill of the EFAS predictions in different ways. In all the following sections I will work with three metrics: recall, precision and the f1-score. The three metrics are based in the contingency table of hits ($TP$ for true positives), false alarms ($FP$ for false positives) and misses ($FN$ for false negatives).\n",
    "\n",
    "$$recall = \\frac{TP}{TP + FN}$$\n",
    "$$precision = \\frac{TP}{TP + FP}$$\n",
    "$$f1 = \\frac{2 \\cdot TP}{2 \\cdot TP + FN + FP}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca24d60-b40f-4bb2-a7d9-a37bb9276514",
   "metadata": {},
   "source": [
    "### 3.1 Brier score: a probability assessment\n",
    "\n",
    "This score is specific for binary classification problems and, since it evaluates only positive cases, it is suited for imbalance datasets. The Brier score is the mean square error between predicted and expeted probabilities:\n",
    "\n",
    "$$BS = \\frac{\\sum (p_{pred} - p_{obs})^2}{N}$$ \n",
    "\n",
    "To compare several models, the **Brier skill score** computes the skill of a model relative to a benchmark model:\n",
    "\n",
    "$$BSS = 1 - \\frac{BS_i}{BS_{ref}}$$\n",
    "\n",
    "#### 3.1.1 Reformat data\n",
    "\n",
    "To be able to compute the Brier score in a simple manner, I need to reshape the exceedance forecast. Up until now, the exceedance forecast is saved in a matrix where the forecast time is one dimension and the leadtime is another dimension, in a way that there aren't missing values in the matrix. However, this shape is not easy to compare against the observed exceedances of the discharge threshold. Instead, I will reshape the original exceendance forecast into a new matrix in which a dimension named `datetime` represents actual date and time, and another dimension represents leadtime. In this way, a \"row\" in the matrix represents the same timeste and can be easily compared against observations. The drawback of this approach is that it will create missing values in the lower-left and upper-right corners of the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563ce24a-bac0-479a-acc1-1759afb27150",
   "metadata": {},
   "source": [
    "**Observed probability of exceendace**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1518df41-719d-4c4f-9d7b-e3b63af21aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataArray with observed threshold exceedance\n",
    "obs = df2da(rean_exc, dims=['id', 'datetime'], plot=False, figsize=(16, 20), title='observed exceendace')\n",
    "\n",
    "# expected probability of an exceedance\n",
    "obs = obs.astype(int)\n",
    "print(obs.dims)\n",
    "print(obs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fd2602-9f29-4fef-8876-da4735ec1e6b",
   "metadata": {},
   "source": [
    "**Predicted probability of exceedance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35177218-46f9-41bd-b15f-fc647db5445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataArray of predicted exceedance\n",
    "pred = fore_exc.to_array(dim='id')\n",
    "\n",
    "# reshape the previous DataArray\n",
    "coords = {'id': pred.id,\n",
    "          'model': pred.model,\n",
    "          'leadtime': (np.arange(0, int(len(pred.leadtime) / 2)) + 1) * 12, #[timedelta(hours=int(12 * h)) for h in np.arange(0, 20)],\n",
    "          'datetime': pd.date_range(start, end, freq='6h')}\n",
    "pred = reshape_DataArray(pred, coords, loop_dim='leadtime')\n",
    "print(pred.dims)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc24db9-d53a-4325-9360-463ce52cb737",
   "metadata": {},
   "source": [
    "The following plot is a graphical explanation of the new format in which forecast exceedance probability is stored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafb92b4-d53e-430e-8b71-1cc23e77056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the predicted probabilit for a station and NWP model\n",
    "stn = 4359\n",
    "stn = 2996\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize=(16, 10))\n",
    "leadtimes = [models[m]['leadtimes'] for m in models]\n",
    "gs = fig.add_gridspec(nrows=5, height_ratios=[1] + leadtimes)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0])\n",
    "plot_DataArray(obs.sel(id=stn), ax=ax1,\n",
    "        title=f'Observed events - station: {stn}')\n",
    "\n",
    "for i, (m, lt) in enumerate(zip(models, leadtimes)):\n",
    "    ax = fig.add_subplot(gs[i + 1], sharex=ax1)\n",
    "    da = pred.sel(id=stn, model=m).isel(leadtime=slice(0, lt))\n",
    "    plot_DataArray(da, ax=ax, title=f'{m} - station: {stn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a237f5-779f-4200-86ae-a0ac7dfe2049",
   "metadata": {},
   "source": [
    "#### 3.1.2 Skill\n",
    "\n",
    "With the previous matrixes we can easily compute the Brier score as the mean square error of probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d23625-3883-44e9-84aa-bcad9034fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# squared error\n",
    "se = (obs - pred)**2\n",
    "# se = se.isel(leadtime=slice(0, min_leadtime)) # keep only the leadtime that is available for all models\n",
    "\n",
    "# Brier skill of each model and station\n",
    "brier = se.mean(['leadtime', 'datetime']) #.isel(leadtime=slice(0, min_leadtime))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91ca1d0-27f8-4b74-81d7-1da516adf0b8",
   "metadata": {},
   "source": [
    "##### All stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0796f1c1-fab7-4956-8824-235067025ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Brier score according to model and forecast\n",
    "plot_DataArray(se.mean(['datetime', 'id']), xtick_step=1, ytick_step=1, cmap='magma_r', xlabel='leadtime (h)',\n",
    "        figsize=(7.5, 2), cbar_kws={'label': 'Brier (-)', 'shrink': .666})\n",
    "plt.savefig(f'{path_out}leadtime_Brier_all_stations.jpg', bbox_inches='tight', dpi=300)\n",
    "\n",
    "# plot Brier score according to model and station\n",
    "plot_DataArray(se.mean(['leadtime', 'datetime']).transpose(), yticklabels=se.model.data, ytick_step=1, xticklabels=se.id.data, xtick_step=30,\n",
    "        cmap='magma_r', cbar_kws={'label': 'Brier (-)', 'shrink': .666})\n",
    "\n",
    "# Brier skill score in terms of NWP model\n",
    "BSS = 1 - brier.mean('id') / brier.sel(model='EUD').mean('id')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "ax.scatter(range(0, 4), BSS.data, s=8)\n",
    "ax.hlines(0, -1, 5, 'k', ls='--', lw=1, zorder=0)\n",
    "ax.set_xticks(range(0, 4), BSS.model.data)\n",
    "ax.set(xlim=(-.5, 3.5), ylim=(-.5, .5), ylabel='Brier skill score (-)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06043f05-7f4b-4608-b260-0b9cf0f058a7",
   "metadata": {},
   "source": [
    "The previous plot shows The Brier skill score using as a benchmark the ECMWF deterministic EUD. Positive values represent models better than the reference, whereas negative values represent models worse than the reference. As seen previously, the two probabilistic models have a higher skill than the reference, with ECMWF ensemble as the best forcing. The DWD is the worst of all the forcings. As expected, skill degrades with increasing leadtimes.\n",
    "\n",
    "The second plot shows the Brier score by station and meteorological forcing. There are a lot of stations with Brier 0, but most of them represent stations with neither observed nor predicted events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac059f5f-dc01-4288-a79a-1698268be338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a map of the Brier score \n",
    "fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(8, 8), subplot_kw={'projection': proj}, constrained_layout=True)\n",
    "for ax, model in zip(axes.flatten(), brier.model.data):\n",
    "    plot_map_stations(stations.X, stations.Y, brier.sel(model=model).to_pandas(), ax=ax,\n",
    "                      rivers=None, size=5, cmap='magma_r', title=model)#, vmin=0, vmax=.022)\n",
    "fig.colorbar(plot_map_stations.colorbar, ax=axes[:,1], shrink=.333, label=f'Brier score (-)');\n",
    "\n",
    "plt.savefig(f'{path_out}eventwise_Brier_all_stations.jpg', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1a995a-4c5f-4e12-b346-26be0b6d398f",
   "metadata": {},
   "source": [
    "##### Stations with events\n",
    "\n",
    "Here I will repeat the previous plots but removing stations without observed flood events. The objective is to check if these stations are masking the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e106b74-4e6a-4ec2-af90-84c15c3088c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select stations with events\n",
    "se_ = se.sel(id=stations[mask_stn].index)\n",
    "\n",
    "# plot Brier score according to model and forecast\n",
    "plot_DataArray(se_.mean(['datetime', 'id']), xtick_step=1, ytick_step=1, cmap='magma_r', xlabel='leadtime (h)',\n",
    "        figsize=(7.5, 2), cbar_kws={'label': 'Brier (-)', 'shrink': .666})\n",
    "plt.savefig(f'{path_out}leadtime_Brier_stations_with_events.jpg', bbox_inches='tight', dpi=300)\n",
    "\n",
    "# plot Brier score according to model and station\n",
    "plot_DataArray(se_.mean(['leadtime', 'datetime']).transpose(), ytick_step=1, xtick_step=30, xlabel='station',\n",
    "        cmap='magma_r', cbar_kws={'label': 'Brier (-)', 'shrink': .666})\n",
    "\n",
    "# Brier skill score in terms of NWP model\n",
    "BSS = 1 - brier.sel(id=stations[mask_stn].index).mean('id') / brier.sel(model='EUD', id=stations[mask_stn].index).mean('id')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "ax.scatter(range(0, 4), BSS.data, s=8)\n",
    "ax.hlines(0, -1, 5, 'k', ls='--', lw=1, zorder=0)\n",
    "ax.set_xticks(range(0, 4), BSS.model.data)\n",
    "ax.set(xlim=(-.5, 3.5), ylim=(-.5, .5), ylabel='Brier skill score (-)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ce8ae0-0535-4400-b260-d90c10219b34",
   "metadata": {},
   "source": [
    "The results are very similar to those that take into account all the stations, not only those with observed flood events. The Brier values, though, are a bit lower.\n",
    "\n",
    "These two previous plots show that the probabilistic forcings (COS and EUE) have a better Brier score than the deterministic forcings (DWD and EUE). Between the two deterministic forcings, EUD seems to have a larger leadtime skill (up to the 5th forecast)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0016d18f-9448-48d2-8b9a-8f29b54b3f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a map of the Brier score \n",
    "fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(8, 8), subplot_kw={'projection': proj}, constrained_layout=True)\n",
    "for ax, model in zip(axes.flatten(), brier.model.data):\n",
    "    plot_map_stations(stations.X, stations.Y, brier.sel(model=model).to_pandas(), mask=~mask_stn, ax=ax,\n",
    "                      rivers=None, size=5, cmap='magma_r', title=model)#, vmin=0, vmax=.022)\n",
    "fig.colorbar(plot_map_stations.colorbar, ax=axes[:,1], shrink=.333, label=f'Brier score (-)');\n",
    "\n",
    "plt.savefig(f'{path_out}eventwise_Brier_stations_with_events.jpg', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa55160-c6a2-456f-950d-b3af15a8dac2",
   "metadata": {},
   "source": [
    "### 3.2 Where events predicted at any point in time?\n",
    "\n",
    "The objective of this section is to check if actual events where predicted at all, no matter leadtime.\n",
    "\n",
    "To convert exceedance probability for each meteo forcing against events we need to come up with a total exceedance probability, i.e., combine the probabilities of each model into a single probability value. This total probability will later be compared against a probability threshold to discern events. I will test four different approaches:\n",
    "\n",
    "* `current`:  the current notification criteria. At least a probabilistic and deterministic model must exceed the probability threshold.\n",
    "* `model_mean`\n",
    "* `member_weighted`\n",
    "* `brier_weighted`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28940917-a845-47be-a0a2-b3d288fe7842",
   "metadata": {},
   "source": [
    "#### 3.2.1 Exceedance over probability threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828fb1ba-1f4d-4c81-a385-e50bb904d0ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exceedance according to current criteria\n",
    "deterministic = (pred.sel(model=['EUD', 'DWD']) > probabilities).any('model')\n",
    "probabilistic = (pred.sel(model=['EUE', 'COS']) > probabilities).any('model')\n",
    "current = deterministic & probabilistic\n",
    "\n",
    "# exceedance according to mean over models\n",
    "model_mean = pred.mean('model', skipna=True) > probabilities\n",
    "\n",
    "# exceedance according to the mean over models weighted by the number of members\n",
    "weights_member = weights.isel(leadtime=slice(None, None, 2))\n",
    "weights_member['leadtime'] = pred.leadtime\n",
    "weights_member /= weights_member.sum('model')\n",
    "member_weighted = pred.weighted(weights_member).mean('model', skipna=True) > probabilities\n",
    "\n",
    "# exceedance according to the mean over models weighted by the inverse Brier score\n",
    "brier = se.mean(['id', 'datetime'])\n",
    "weights_brier = 1 / brier**2\n",
    "weights_brier /= weights_brier.sum('model')\n",
    "brier_weighted = pred.weighted(weights_brier.fillna(0)).mean('model', skipna=True) > probabilities\n",
    "\n",
    "# merge all in a single DataArray\n",
    "pred_reshape = xr.Dataset({'current': current,\n",
    "                           'model_mean': model_mean,\n",
    "                           'member_weighted': member_weighted,\n",
    "                           'brier_weighted': brier_weighted}).to_array(dim='model')\n",
    "\n",
    "# heatmap of weights\n",
    "fig, axes = plt.subplots(nrows=2, figsize=(6, 3), constrained_layout=True, sharex=True, sharey=True)\n",
    "Weights = xr.Dataset({'no. member': weights_member, 'Brier score': weights_brier})\n",
    "for i, (ax, (var, da)) in enumerate(zip(axes, Weights.items())):\n",
    "    htm = plot_DataArray(da, vmin=0, vmax=1, ax=ax, ytick_step=1, xtick_step=1, title=f'weighted by {var}', cbar_kws={'shrink': .66})\n",
    "    if i == len(axes) - 1:\n",
    "        ax.set_xlabel('leadtime (h)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d554ade9-494b-49ea-a746-c68e39cd3f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportar weights based on the Brier score\n",
    "weights_brier.to_netcdf('results/weights_brier.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ebc6c1-2470-4292-a97a-22c3eb0023c9",
   "metadata": {},
   "source": [
    "To create a weight based on the Brier score I need to invert the values, since lower Brier score values represent better models. Therefore, I compute the inverse of the squared Brier score. To normalize weights (values between 0 and 1) I divide the previous weight matrix by its sum over models.\n",
    "\n",
    "The previous plot shows the weighting factors for the mean weighted by the number of members of each model (top), and the mean weighted by the performace of the model measured in terms of Brier score (bottom). When taking into account the number of members, obviously COSMO-LEPS and EUE get the vast majority of the weight, rendering no importance to any of the deterministic models. Between the two probabilistic models, EUE prevails over COSMO-LEPS, even though we've seen that their performance is comparable. However, when weighting according to performance, COSMO-LEPS and EUE get a very similar value during the leadtime span for which COSMO-LEPS is available. The probabilistic models have lower weights, but not as insignificat as when weighting by the number of members. In this sense, this last weighting method is a mid ground point between the simple model mean and the mean weighted by the number of members."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d2be99-c00f-4d07-b43f-cf86250f81a5",
   "metadata": {},
   "source": [
    "**Graphical explanation of the procedure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1e2b7c-708e-413a-b7c0-89f13c7a2680",
   "metadata": {},
   "outputs": [],
   "source": [
    "stn = n_events_obs.idxmax().data\n",
    "stn = 119\n",
    "#stn = 4359\n",
    "stn = 2996\n",
    "# stn = 2753\n",
    "# stn = 2376\n",
    "print('Station {0} has {1} observed events'.format(stn, n_events_obs.sel(id=stn).data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b6d7b4-fb26-4b88-8f0a-5efcff9c9700",
   "metadata": {},
   "outputs": [],
   "source": [
    "das = {'obs': obs.sel(id=stn), \n",
    "       'pred': pred_reshape.sel(id=stn, probability=.3, model='member_weighted').any('leadtime').astype(int)}\n",
    "\n",
    "n_events_pred = (xr.concat([das['pred'].isel(datetime=[0]), das['pred'].diff('datetime')], dim='datetime') == 1).sum('datetime').data\n",
    "print('Station {0} has {1} predicted events'.format(stn, n_events_pred))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, figsize=(16, 1), sharex=True, sharey=True)\n",
    "for ax, (title, da) in zip(axes, das.items()):\n",
    "    plot_DataArray(da, ax=ax, xtick_step=60, cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de44b90-5e80-412a-9c24-21d0c9769476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling sum of observations and predictions\n",
    "w = 7\n",
    "mp = int(w / 2) + 1\n",
    "das_w = {key: das[key].rolling({'datetime': w}, center=True, min_periods=mp).sum() > 0 for key in das}\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, figsize=(16, 1), sharex=True, sharey=True)\n",
    "for ax, (title, da) in zip(axes, das_w.items()):\n",
    "    plot_DataArray(da, ax=ax, xtick_step=60, cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da18948f-4405-4116-9180-470010db3279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute true positives and false negatives\n",
    "aux1 = das_w['pred'].where(das['obs'] == 1)\n",
    "tp, fn = (aux1 == 1).astype(int), (aux1 == 0).astype(int)\n",
    "\n",
    "# compute false positives\n",
    "aux2 = das['pred'].where(das_w['obs'] == 0)\n",
    "fp = (aux2 == 1).astype(int)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, figsize=(16, 1.5), sharex=True, sharey=True)\n",
    "for ax, da in zip(axes, [tp, fn, fp]):\n",
    "    plot_DataArray(da, ax=ax, xtick_step=60, cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaac566-cae0-4a4e-b682-82966fb491a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = (tp.isel(datetime=0) + (tp.diff('datetime') == 1)).sum('datetime')\n",
    "TP = xr.ufuncs.minimum(TP, n_events_obs.sel(id=stn)).data\n",
    "FN = n_events_obs.sel(id=stn).data - TP\n",
    "FP = max(0, n_events_pred - TP)\n",
    "\n",
    "TP, FN, FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c105c933-707f-44ae-bc9d-5cc3b6c47890",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP / (TP + FN), TP / (TP + FP), 2 * TP / (2 * TP + FP + FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdeff38-cec2-4ac9-9ed2-9226614f5ded",
   "metadata": {},
   "source": [
    "**Compute for all the stations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc55aa7-aa38-46e9-ae99-b7cae85478d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataArrays of exceedance over threshold\n",
    "das = {'obs': obs, \n",
    "       'pred': pred_reshape.any('leadtime').astype(int)} #.sel(probability=.3)\n",
    "\n",
    "n_events_pred = (xr.concat([das['pred'].isel(datetime=[0]), das['pred'].diff('datetime')], dim='datetime') == 1).sum('datetime').data\n",
    "\n",
    "# rolling sum of observations and predictions\n",
    "w = 7\n",
    "mp = int(w / 2) + 1\n",
    "das_w = {key: das[key].rolling({'datetime': w}, center=True, min_periods=mp).sum() > 0 for key in das}\n",
    "\n",
    "# compute true positives\n",
    "tp = (das_w['pred'].where(das['obs']) == 1).astype(int)\n",
    "tp = (tp.isel(datetime=0) + (tp.diff('datetime') == 1)).sum('datetime')\n",
    "tp = xr.ufuncs.minimum(tp, n_events_obs)\n",
    "# compute false negatives and false positives\n",
    "fn = n_events_obs - tp\n",
    "fp = xr.ufuncs.maximum(0, n_events_pred - tp)\n",
    "\n",
    "# compute metrics\n",
    "skill = xr.Dataset({'recall': tp / (tp + fn),\n",
    "                   'precision': tp / (tp + fp),\n",
    "                   'f1': 2 * tp / (2 * tp + fp + fn)})#.to_array(dim='metric')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d4df85-1513-4c4a-90eb-036bcfa3811c",
   "metadata": {},
   "source": [
    "**All the stations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22998584-bc04-470a-919d-2e0c84b56ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot performace for individual stations\n",
    "filename = f'{path_out}eventwise_station_skill_(all_stations).jpg'\n",
    "plot_skill(skill, xtick_step=50, save=filename, figsize=(24, 14))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc75c307-4c48-4b0c-905e-3faade288ef2",
   "metadata": {},
   "source": [
    "* Most of the stations are in white, which means that they didn't have neither observed nor forecasted events. This specifically noticeable in the recall.\n",
    "* Lower probability threshols optimize recall.\n",
    "* Higher probability thresholds optimize precision.\n",
    "* Even f1 is the harmonic mean of recall and precision, its peak values are also for high probability thresholds. The highest value of all is obtained by the `brier_weighted` method and the 90% probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b224aa38-3c7a-40c4-b384-e65d11e0a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot average performance over stations\n",
    "fig, axes = plt.subplots(nrows=len(skill.model), figsize=(7.5, 6), constrained_layout=True, sharex=True, sharey=True)\n",
    "for i, (ax, model) in enumerate(zip(axes, skill.model.data)):\n",
    "    da = skill.sel(model=model).mean('id').to_array(dim='metric')\n",
    "    if i == 1:\n",
    "        cbar = True\n",
    "    else:\n",
    "        cbar = False\n",
    "    plot_DataArray(da, xtick_step=1, ytick_step=1, cmap='Blues', ax=ax, vmin=0, vmax=1, cbar=cbar, title=model,\n",
    "            cbar_kws={'shrink': 1.5, 'label': 'metric (-)'})\n",
    "    if i == len(skill.model) - 1:\n",
    "        ax.set_xlabel('probability (-)')\n",
    "        \n",
    "    print(model.upper().replace('_', ' '))\n",
    "    print('-' * len(model))\n",
    "    print('Best probability thresholds\\n{0}:\\t\\t{3:.3f}\\n{1}:\\t{4:.3f}\\n{2}:\\t\\t{5:.3f}\\n'.format(*da.metric.data, *da.idxmax('probability').data))\n",
    "    \n",
    "plt.savefig(f'{path_out}eventwise_average_skill_(all_stations).jpg', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab127a2-76ef-4706-b0c2-b8c54f90639c",
   "metadata": {},
   "source": [
    "> <font color='red'>Improve this figure to show the best performing option for each model and metric.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff21a55-b50c-4482-9891-4da98d68c184",
   "metadata": {},
   "source": [
    "The previous plot summarizes performance over stations. The general look of all models is similar, but there are slight differences:\n",
    "\n",
    "* `model_mean` and `brier_weighted` are very similar, with slightly higher values for `brier_weighted`. Their main difference compared with the other two models is a marked higher precision at larger probability thresholds.\n",
    "* `current` and `member_weighted` look very alike, with slightly higher performance for the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50a4cd4-b0fc-4e50-ab9a-c5952c4caa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find probability threshold that optimizes f1 for a given model\n",
    "metric = 'f1'\n",
    "model = 'brier_weighted'\n",
    "best_p = skill[metric].sel(model=model).mean('id').idxmax(dim='probability', skipna=True)\n",
    "\n",
    "# plot a map of the metrics\n",
    "proj = ccrs.LambertAzimuthalEqualArea(central_longitude=10, central_latitude=52, false_easting=4321000, false_northing=3210000, globe=ccrs.Globe(ellipse='GRS80'))\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(15, 5), subplot_kw={'projection': proj}, constrained_layout=True)\n",
    "for ax, metric in zip(axes, list(skill)):\n",
    "    # extract metric values for stations\n",
    "    metric_id = skill[metric].sel(model=model, probability=best_p).to_pandas()\n",
    "    # plot a map of the Brier score for the COS model\n",
    "    plot_map_stations(stations.X, stations.Y, metric_id, ax=ax,\n",
    "                      rivers=None, size=8, cmap='coolwarm_r', title=metric)\n",
    "fig.text(.475, 1.025, f'{model} | p = {best_p.data:.2f}', horizontalalignment='center', fontsize=13)\n",
    "fig.colorbar(plot_map_stations.colorbar, shrink=.5, label=f'(-)');\n",
    "\n",
    "plt.savefig(f'{path_out}eventwise_skill_map_(all_stations).jpg', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1033834-c278-4218-95ce-26c934898bba",
   "metadata": {},
   "source": [
    "Surprisingly, there's a larger amount of stations with poor recall (red dots in the left panel) than precision (red dots in the central panel). This means that there is a stronger tendency towards missing events than towards mistakenly producing events.\n",
    "\n",
    "A priori, there's no clear pattern in the geographical location of high or poor performing stations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c477c6e6-1750-4099-b4df-1e2b39354f56",
   "metadata": {},
   "source": [
    "**Stations with events**\n",
    "\n",
    "Let's repeat the previous plots but taking into account only stations with observed flood events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b165b9b0-b929-485e-96b0-7d0537b180ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot performace for individual stations\n",
    "stns = stations[mask_stn].index\n",
    "filename = f'{path_out}eventwise_station_skill_(stations_with_events).jpg'\n",
    "plot_skill(skill.sel(id=stns), xtick_step=50, save=filename, figsize=(24, 14))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686e0a2e-469c-47cc-9b5c-f6d488ca9cbf",
   "metadata": {},
   "source": [
    "Compared with the similar plot with all stations, there is barely no white in this one, where white means stations with neither observed nor predicted events.\n",
    "\n",
    "* Recall values seem higher in general (larger areas dark blue). Lower probability thresholds optimize recall.\n",
    "* As seen before, recall improves with larger probability thresholds. Specifically for the methods `model_mean` and `brier_weighted`, there is clear threshold above which some stations show high precision.\n",
    "* The highest f1 score is obtained by the `current` model at 30% probability, which is the actual curren probability threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de92dc09-540d-49b4-8839-16db8820c74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot average performance over stations\n",
    "stn = stations[mask_stn].index\n",
    "fig, axes = plt.subplots(nrows=len(skill.model), figsize=(7.5, 6), constrained_layout=True, sharex=True, sharey=True)\n",
    "for i, (ax, model) in enumerate(zip(axes, skill.model.data)):\n",
    "    da = skill.sel(model=model, id=stn).mean('id').to_array(dim='metric')\n",
    "    if i == 1:\n",
    "        cbar = True\n",
    "    else:\n",
    "        cbar = False\n",
    "    plot_DataArray(da, xtick_step=1, ytick_step=1, cmap='Blues', ax=ax, vmin=0, vmax=1, cbar=cbar, title=model,\n",
    "            cbar_kws={'shrink': 1.5, 'label': 'metric (-)'})\n",
    "    if i == len(skill.model) - 1:\n",
    "        ax.set_xlabel('probability (-)')\n",
    "        \n",
    "    print(model.upper().replace('_', ' '))\n",
    "    print('-' * len(model))\n",
    "    print('Best probability thresholds\\n{0}:\\t\\t{3:.3f}\\n{1}:\\t{4:.3f}\\n{2}:\\t\\t{5:.3f}\\n'.format(*da.metric.data, *da.idxmax('probability').data))\n",
    "    \n",
    "plt.savefig(f'{path_out}eventwise_average_skill_(stations_with_events).jpg', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f3828d-4908-41a8-8a3b-f5c57287742b",
   "metadata": {},
   "source": [
    "The conclusions are very similar to those commented on the similar plot with all stations. However, performace is higher in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5692a3-4909-4e5a-b35c-8c10e646fd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find probability threshold that optimizes f1 for a given model\n",
    "metric = 'f1'\n",
    "model = 'current'\n",
    "stn = stations[mask_stn].index\n",
    "best_p = skill[metric].sel(model=model, id=stn).mean('id').idxmax(dim='probability', skipna=True)\n",
    "\n",
    "# plot a map of the metrics\n",
    "proj = ccrs.LambertAzimuthalEqualArea(central_longitude=10, central_latitude=52, false_easting=4321000, false_northing=3210000, globe=ccrs.Globe(ellipse='GRS80'))\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(15, 5), subplot_kw={'projection': proj}, constrained_layout=True)\n",
    "for ax, metric in zip(axes, list(skill)):\n",
    "    # extract metric values for stations\n",
    "    metric_id = skill[metric].sel(model=model, probability=best_p).to_pandas()\n",
    "    # plot a map of the Brier score for the COS model\n",
    "    plot_map_stations(stations.X, stations.Y, metric_id, mask=~mask_stn, ax=ax,\n",
    "                      rivers=None, size=8, cmap='coolwarm_r', title=metric)\n",
    "fig.text(.475, 1.025, f'{model} | p = {best_p.data:.2f}', horizontalalignment='center', fontsize=13)\n",
    "fig.colorbar(plot_map_stations.colorbar, shrink=.5, label=f'(-)');\n",
    "\n",
    "plt.savefig(f'{path_out}eventwise_skill_map_(stations_with_events).jpg', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f9168f-ff91-45ef-831a-f7180f56c97f",
   "metadata": {},
   "source": [
    "As explained before, there are more stations with poor recall than precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0758177e-bd53-411c-b4ae-04c8b0c8ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'f1'\n",
    "attr = 'area'\n",
    "\n",
    "model = 'brier_weighted'\n",
    "p = .9\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(12, 4), sharex=True, sharey=True, constrained_layout=True)\n",
    "\n",
    "for i, (ax, metric) in enumerate(zip(axes, list(skill))):\n",
    "    ax.scatter(stations[attr], skill.sel(model=model, probability=p)[metric].to_pandas(), s=5, alpha=.33)\n",
    "    ax.set_title(metric)\n",
    "    ax.set_xlabel(attr)\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('metric (-)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676ba766-9ceb-46ef-b4f6-a655f92f192b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e035093-8e41-4bb3-9331-afe72adfbff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_skill_vs_attribute(skill, model, probability, attribute, id=None, **kwargs):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(ncols=3, figsize=(12, 4), sharex=True, sharey=True, constrained_layout=True)\n",
    "    \n",
    "    if id is None:\n",
    "        ds = skill.sel(model=model, probability=probability)\n",
    "        x = attribute\n",
    "    else:\n",
    "        ds = skill.sel(id=id, model=model, probability=probability)\n",
    "        x = attribute.loc[id]\n",
    "    for i, (ax, metric) in enumerate(zip(axes, list(ds))):\n",
    "        ax.scatter(x, ds[metric].to_pandas(), s=5, alpha=.33)\n",
    "        ax.set_title(metric)\n",
    "        if 'xlabel' in kwargs:\n",
    "            ax.set_xlabel(kwargs['xlabel'])\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('metric (-)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d9a2c5-e5a1-4518-bb0e-8280a190861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = 'area'\n",
    "plot_skill_vs_attribute(skill, 'brier_weighted', .3, stations[attr], xlabel=attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd774e6-247d-43d9-944c-9f5c7cb04922",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = 'area'\n",
    "plot_skill_vs_attribute(skill, 'brier_weighted', .3, stations[attr], id=stn, xlabel=attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5d31bb-a7c8-4daf-b002-ad67aa37410f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
