{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "654baf6d-f8eb-49dc-a90d-d8dd284d451d",
   "metadata": {},
   "source": [
    "# Summarize skill results\n",
    "***\n",
    "\n",
    "**Author**: Chus Casado Rodr√≠guez<br>\n",
    "**Date**: 27-06-2023<br>\n",
    "\n",
    "\n",
    "**Introduction**:<br>\n",
    "This notebook creates a table comparing the skill of the diverse notification criteria optimized for different f-scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f417aff7-e56d-4497-8e8e-727ea08402f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path_root = os.getcwd()\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from datetime import datetime, timedelta\n",
    "import pickle\n",
    "import yaml\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.chdir('../py/')\n",
    "from compute import hits2skill, limit_leadtime\n",
    "os.chdir(path_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a899f4-7f7b-4404-a63e-f1344fa1f331",
   "metadata": {},
   "source": [
    "## 1 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2febe9c2-a0e7-441a-9c19-0109c3bd6aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../conf/config.yml\", \"r\", encoding='utf8') as ymlfile:\n",
    "    cfg = yaml.load(ymlfile, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e915052-7b61-41cc-981c-1b135c8b2357",
   "metadata": {},
   "source": [
    "### 1.1 Reporting points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea338ed0-5ebe-4565-8f2c-e2398bc6c6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# area threshold\n",
    "area_threshold = cfg.get('reporting_points', {}).get('area', 500)\n",
    "\n",
    "# reporting points\n",
    "path_stations = cfg.get('reporting_points', {}).get('output', '../results/reporting_points/')\n",
    "file_stations = f'{path_stations}reporting_points_over_{area_threshold}km2.parquet'\n",
    "\n",
    "# catchments\n",
    "catchments = cfg.get('reporting_points', {}).get('catchments', None)\n",
    "\n",
    "# minimum performance required from the reporting points\n",
    "min_kge = cfg.get('reporting_points', {}).get('KGE', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59b30d3-d313-4db6-b0f7-f4aa5acbf8b4",
   "metadata": {},
   "source": [
    "### 1.2 Hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ce26e71-7110-466e-bcd2-b2343ecf72d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of the rolling window used to compute hits\n",
    "window = cfg.get('hits', {}).get('window', 1)\n",
    "\n",
    "# dissagregate the analysis by seasons?\n",
    "seasonality = cfg.get('hits', {}).get('seasonality', False)\n",
    "\n",
    "# path that contains the NetCDFs with hit, misses and false alarms pro\n",
    "path_in = cfg.get('hits', {}).get('output', '../results/hits/')\n",
    "path_in = f'{path_in}window_{window}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65389aa3-8726-45ee-adec-5930ce6c8fb9",
   "metadata": {},
   "source": [
    "### 1.3 Skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8b31a26-f636-4b02-a16f-0a1167e28a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current operationa criteria\n",
    "current_criteria = cfg.get('skill', {}).get('current_criteria', None)\n",
    "\n",
    "# fixed notification criteria\n",
    "min_leadtime = cfg.get('skill', {}).get('leadtime', 60) \n",
    "min_area = cfg.get('skill', {}).get('area', 2000) \n",
    "\n",
    "# path where results will be saved\n",
    "path_out = cfg.get('skill', {}).get('output', f'../results/skill/')\n",
    "if min_kge is not None:\n",
    "    path_out = f'{path_out}window_{window}/kge_{min_kge}/'\n",
    "else:\n",
    "    path_out = f'{path_out}window_{window}/no_kge/'\n",
    "    \n",
    "# coefficient of the fbeta-score\n",
    "betas = [float(item[1:]) for item in os.listdir(path_out) if os.path.isdir(f'{path_out}{item}') and item.startswith('f')]\n",
    "betas = [1 if beta == 1.0 else beta for beta in betas]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8827e1d7-7c0c-43de-b83f-4409dba98094",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2 Data\n",
    "\n",
    "### 2.1 Reporting points\n",
    "\n",
    "I load all the stations that where selected in a previous [notebook](3_0_select_stations.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7758ac43-6d08-465c-913f-f09d2adc33f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All points\n",
      "----------\n",
      "no. reporting points:\t\t1979\n",
      "no. stations with events:\t831\n",
      "no. observed events:\t\t1264\n",
      "\n",
      "Points selected for otimization\n",
      "-------------------------------\n",
      "no. reporting points:\t\t1239\n",
      "no. stations with events:\t480\n",
      "no. observed events:\t\t678\n"
     ]
    }
   ],
   "source": [
    "# load table of fixed reporting points\n",
    "stations = pd.read_parquet(file_stations)\n",
    "stations[['X', 'Y', 'area']] = stations[['X', 'Y', 'area']].astype(int)\n",
    "\n",
    "# select stations that belong to the selected catchments\n",
    "if catchments is not None:\n",
    "    if isinstance(catchments, list) is False:\n",
    "        catchments = [catchments]\n",
    "    stations = stations.loc[stations.catchment.isin(catchments),:]\n",
    "\n",
    "# remove points with a performance (KGE) lower than the established threshold\n",
    "if min_kge is not None:\n",
    "    mask_kge = ~(stations.KGE <= min_kge)\n",
    "    stations = stations.loc[mask_kge]\n",
    "else:\n",
    "    # remove station with erroneous behaviour\n",
    "    stations = stations.loc[~(stations.n_events_obs >= 6)]\n",
    "\n",
    "# mask stations with events\n",
    "stations_w_events = (stations.n_events_obs > 0)\n",
    "\n",
    "print('All points')\n",
    "print('----------')\n",
    "print(f'no. reporting points:\\t\\t{stations.shape[0]}')\n",
    "print('no. stations with events:\\t{0}'.format(stations_w_events.sum()))\n",
    "print('no. observed events:\\t\\t{0}'.format(stations.n_events_obs.sum()))\n",
    "\n",
    "# select stations according to catchment area\n",
    "if min_area > area_threshold:\n",
    "    stations_optimize = stations.loc[stations.area >= min_area].index\n",
    "else:\n",
    "    stations_optimize = stations.index\n",
    "\n",
    "print('\\nPoints selected for otimization')\n",
    "print('-------------------------------')\n",
    "print(f'no. reporting points:\\t\\t{len(stations_optimize)}')\n",
    "print('no. stations with events:\\t{0}'.format((stations.loc[stations_optimize, 'n_events_obs'] > 0).sum()))\n",
    "print('no. observed events:\\t\\t{0}'.format(stations.loc[stations_optimize, 'n_events_obs'].sum()))\n",
    "\n",
    "# suffix that will be used when saving plots\n",
    "suffix = f'{min_area}km2_{len(stations_optimize)}points'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c959c12-b037-40a9-aa8e-62cb4e4e2803",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2 Hits, misses and false alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6926cdde-578c-40b7-884d-e493da060be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hits for each station\n",
    "hits_stn = xr.open_mfdataset(f'{path_in}*.nc', combine='nested', concat_dim='id')\n",
    "\n",
    "# extract selected stations\n",
    "hits_stn = hits_stn.sel(id=stations.index.to_list()).compute()\n",
    "\n",
    "# convert to NaN lead times that can't be reached due to model limitations or persistence\n",
    "hits_stn = limit_leadtime(hits_stn)\n",
    "\n",
    "# subset of the 'hits' dataset with the stations selected for the optimization\n",
    "hits_opt = hits_stn.sel(id=stations_optimize).sum('id', skipna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53af8555-835c-4d54-a967-b530054a5cb2",
   "metadata": {},
   "source": [
    "## 3 Analysis\n",
    "\n",
    "In this section I will compute the skill of the EFAS predictions in different ways. In all the following sections I will work with three metrics: $recall$, $precision$ and the $f_{beta}$ score. The three metrics are based in the contingency table of hits ($TP$ for true positives), false alarms ($FP$ for false positives) and misses ($FN$ for false negatives).\n",
    "\n",
    "$$recall = \\frac{TP}{TP + FN}$$\n",
    "$$precision = \\frac{TP}{TP + FP}$$\n",
    "$$f_{beta} = \\frac{(1 + \\beta^2) \\cdot TP}{(1 + \\beta^2) \\cdot TP + \\beta^2 \\cdot FN + FP}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfdfc6d-19a1-4cdf-81e2-27dc2c7b3a24",
   "metadata": {},
   "source": [
    "### 3.2 Compare approaches\n",
    "#### 3.2.1 Import optimize criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0301c24-696f-4129-82e9-abc3b24c7223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'model' in hits_stn.dims:\n",
    "    criteria = {}\n",
    "else:\n",
    "    criteria = {'current': current_criteria}\n",
    "for beta in betas:\n",
    "    metric = f'f{beta}'\n",
    "    file = glob.glob(f'{path_out}{metric}/*{suffix}.pkl')[0]\n",
    "    opt_crit = pickle.load(open(file, 'rb'))\n",
    "    for key, crit in opt_crit.items():\n",
    "        if metric in crit:\n",
    "            del crit[metric]\n",
    "        criteria[f'{metric}_{key}'] = crit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcae12c-e390-4109-8f94-8b3d362faa82",
   "metadata": {},
   "source": [
    "#### 3.2.2 Compare approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4a438d1-cd3e-4bca-b531-3b999d013fce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [20], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m     summary_criteria\u001b[38;5;241m.\u001b[39mapproach \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([x[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mupper() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m app\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)]) \u001b[38;5;28;01mfor\u001b[39;00m app \u001b[38;5;129;01min\u001b[39;00m summary_criteria\u001b[38;5;241m.\u001b[39mapproach]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m hits_stn\u001b[38;5;241m.\u001b[39mdims:\n\u001b[1;32m----> 6\u001b[0m     summary_criteria\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m [model \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[43msummary_criteria\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m]\n\u001b[0;32m      7\u001b[0m summary_criteria[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwindow\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m window\n\u001b[0;32m      8\u001b[0m summary_criteria[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKGE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m min_kge\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\pandas\\core\\generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5569\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5570\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5571\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5572\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5573\u001b[0m ):\n\u001b[0;32m   5574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "# transform criteria into a DataFrame\n",
    "summary_criteria = pd.concat([pd.DataFrame(crtr, index=[i]) for i, crtr in criteria.items()], axis=0)\n",
    "if 'approach' in hits_stn.dims:\n",
    "    summary_criteria.approach = [''.join([x[0].upper() for x in app.split('_')]) for app in summary_criteria.approach]\n",
    "elif 'model' in hits_stn.dims:\n",
    "    summary_criteria.model = [model for model in summary_criteria.model]\n",
    "summary_criteria['window'] = window\n",
    "summary_criteria['KGE'] = min_kge\n",
    "summary_criteria['OF'] = [x.split('_')[0] if x != 'current' else '' for x in summary_criteria.index]\n",
    "if 'approach' in hits_stn.dims:\n",
    "    summary_criteria = summary_criteria[['window', 'KGE', 'approach', 'OF', 'probability', 'persistence']]\n",
    "elif 'model' in hits_stn.dims:\n",
    "    summary_criteria = summary_criteria[['window', 'KGE', 'model', 'OF', 'probability', 'persistence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5dc5be-5c40-4f1f-b589-69d5f05ca6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute hits, misses and false alarms\n",
    "summary_hits = pd.DataFrame({i: hits_opt.sel(leadtime=min_leadtime).sel(crtr).to_pandas() for i, crtr in criteria.items()}).transpose()\n",
    "summary_hits = summary_hits.astype(int)\n",
    "summary_hits['no_events'] = summary_hits.TP + summary_hits.FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e794a368-6906-45b4-b0e8-9e372d068ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute skill\n",
    "summary_hits['recall'] = summary_hits.TP / (summary_hits.TP + summary_hits.FN)\n",
    "summary_hits['precision'] = summary_hits.TP / (summary_hits.TP + summary_hits.FP)\n",
    "for beta in betas:\n",
    "    summary_hits[f'f{beta}'] = (1 + beta**2) * summary_hits.TP / ((1 + beta**2) * summary_hits.TP + beta**2 * summary_hits.FN + summary_hits.FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec6c424-0e41-4b28-aa20-8415be04c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat criteria, hits and summary data frames\n",
    "summary = pd.concat((summary_criteria, summary_hits), axis=1)\n",
    "if 'approach' in hits_stn.dims:\n",
    "    summary.sort_values('approach', inplace=True)\n",
    "elif 'model' in hits_stn.dims:\n",
    "    summary.sort_values('model', inplace=True)\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c135435-9f6b-4d87-8403-5bea1d48f7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5bbbd5-c975-4d93-af68-fa249477475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_kge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6aaaae-b9ae-4254-ada1-07807868bab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "summary.to_csv(f'{path_out}skill_by_criteria.csv', float_format='%.3f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59353dd6-c6bb-4a4a-8b0b-21ad515c7461",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dtype=float)\n",
    "df['recall'] = np.arange(.1, .91, .1)\n",
    "df['precision'] = np.arange(.1, .91, .1)[::-1]\n",
    "\n",
    "for b in [.8, 1, 1.25]:\n",
    "    df[f'f{b}'] = (1 + b**2) * df.precision * df.recall / (b**2 * df.precision + df.recall)\n",
    "\n",
    "    \n",
    "df.drop(['recall', 'precision'], axis=1).plot()\n",
    "df.plot()\n",
    "\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9944faeb-6e29-432f-ac18-c741199f178c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f15463b-12e9-4f6e-a352-0b0ddf9e580d",
   "metadata": {},
   "source": [
    "```Python\n",
    "hits_stn\n",
    "\n",
    "hits_1D1P = hits_stn.sel(approach='1_deterministic_+_1_probabilistic',\n",
    "                         probability=0.375,\n",
    "                         persistence='1/1',\n",
    "                         leadtime=min_leadtime)\n",
    "\n",
    "hits_BW = hits_stn.sel(approach='brier_weighted',\n",
    "                       probability=0.375,\n",
    "                       persistence='1/1',\n",
    "                         leadtime=min_leadtime)\n",
    "\n",
    "hits_diff = hits_BW - hits_1D1P\n",
    "\n",
    "tp = hits_diff['TP'].to_pandas()\n",
    "\n",
    "tp[tp == 0]\n",
    "\n",
    "tp[tp < 0]\n",
    "\n",
    "stations[tp > 0].value_counts('river')\n",
    "\n",
    "stations[tp > 0].value_counts('catchment')\n",
    "\n",
    "stations[tp > 0][stations.catchment == 'Rhine'].sort_values(['catchment', 'subcatchment', 'river'])\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
