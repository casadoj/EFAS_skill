{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2765e5b3-1233-4484-a0c6-2ccf2ee56dbb",
   "metadata": {},
   "source": [
    "# Reanalysis preprocessing\n",
    "***\n",
    "\n",
    "__Author__: Chus Casado<br>\n",
    "__Date__:   31-05-2022<br>\n",
    "\n",
    "__Introduction__:<br>\n",
    "This code processes the raw EFAS reanalysis discharge data to extract the data necessary for the following steps in the skill analysis.\n",
    "\n",
    "The raw discharge data was downloaded from the Climate Data Store (CDS) and consists of NetCDF files for every year of the analysis. These NetCDF files contain values for the complete EFAS domain, but the succeeding analysis only require the time series for specific points: the selected reporting points. The codes extracts this timeseries and saves the result in a folder of the repository.\n",
    "\n",
    "In a second step, the discharge timeseries are compared against a discharge return period to create a new binary timeseries of exceedance/non-exceedance over the specified threshold. To account for events in which the peak discharge is close to the threshold, there's an option to create a 3-class exceedance timeseries: 0, non-exceendance; 1, exceedance over the reduced threshold ($0.95\\cdot Q_{rp}$); 2, exceedance over the actual threshold ($Q_{rp}$). By default, the reducing factor is $0.95$, but this value can be changed.\n",
    "\n",
    "**Questions**:<br>\n",
    "\n",
    "**To do**:<br>\n",
    "* [ ] How to define in the configuration file (`config.yml`) the two reporting point input files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e12ad6b4-05e2-45c1-b1fd-108774dca9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas as gpd\n",
    "import yaml\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "path_root = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a12b65-e1ca-40c6-a29b-a7091bd9522d",
   "metadata": {},
   "source": [
    "## 1 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa54e412-6c38-4d18-9875-2fe6d837145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../conf/config.yml\", \"r\", encoding='utf8') as ymlfile:\n",
    "    cfg = yaml.load(ymlfile, Loader=yaml.FullLoader)\n",
    "\n",
    "# area threshold\n",
    "area_threshold = cfg.get('reporting_points', {}).get('area', 500)\n",
    "\n",
    "# return period\n",
    "rp = cfg.get('return_period', {}).get('threshold', 5)\n",
    "\n",
    "# percent buffer over the discharge threshold\n",
    "reducing_factor = cfg.get('return_period', {}).get('reducing_factor', None)\n",
    "\n",
    "# start and end of the study period\n",
    "start = cfg.get('study_period', {}).get('start', None)\n",
    "end = cfg.get('study_period', {}).get('end', None)\n",
    "\n",
    "# PATHS\n",
    "\n",
    "# local directory where I have saved the raw discharge data\n",
    "path_in = cfg.get('paths', {}).get('input', {}).get('discharge', {}).get('reanalysis', f'../data/discharge/reanalysis/')\n",
    "\n",
    "# NetCDF file that contains the discharge thresholds for each reporting point\n",
    "file_thresholds = cfg.get('return_period', {}).get('file', '../data/thresholds/return_levels.nc')\n",
    "\n",
    "# reporting points\n",
    "file_in_stations = cfg.get('paths', {}).get('input', {}).get('reporting_points', '../data/reporting_points/')\n",
    "path_out_stations = cfg.get('paths', {}).get('out', {}).get('reporting_points', '../results/reporting_points/')\n",
    "file_out_stations = f'{path_out_stations}reporting_points_over_{area_threshold}km2.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd35423c-bf40-4eb7-9fef-08fcddb0c0dd",
   "metadata": {},
   "source": [
    "## 2 Stations\n",
    "\n",
    "Load the table with all EFAS fixed reporting point and filter those points for which discharge data will be extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4090439-ae39-4f2c-bb67-01f4f5a1fb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load table of fixed reporting points\n",
    "stations = pd.read_csv(file_in_stations, index_col='station_id')\n",
    "# stations.index = stations.index.astype(str)\n",
    "stations.index.name = 'id'\n",
    "# filter stations and fields\n",
    "mask = (stations['DrainingArea.km2.LDD'] >= area_threshold) & (stations.FixedRepPoint == True)\n",
    "stations = stations.loc[mask, ['StationName', 'LisfloodX', 'LisfloodY', 'DrainingArea.km2.LDD', 'Catchment', 'River', 'EC_Catchments', 'Country code']]\n",
    "stations.columns = stations.columns = ['name', 'X', 'Y', 'area', 'subcatchment', 'river', 'catchment', 'country']\n",
    "stations[['strahler', 'pfafstetter']] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b809446c-b1ce-4022-aa7b-6d1bd5b4577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load shapefile with edited river and catchment names\n",
    "points_edited = gpd.read_file('../data/GIS/fixed_report_points_500.shp')\n",
    "points_edited.set_index('station_id', inplace=True, drop=True)\n",
    "points_edited.index = points_edited.index.astype(int)\n",
    "points_edited = points_edited[['StationNam', 'LisfloodX', 'LisfloodY', 'DrainingAr', 'Subcatchme',\n",
    "                               'River', 'Catchment', 'Country co', 'strahler', 'pfafstette']]\n",
    "points_edited.columns = stations.columns\n",
    "# select points with a Pfafstetter code\n",
    "mask = points_edited.pfafstetter.isnull()\n",
    "points_edited = points_edited.loc[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8086ef7-ce55-4184-8c14-8f168e7e101a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. stations:\t2371\n"
     ]
    }
   ],
   "source": [
    "# correct names of catchments and rivers\n",
    "ids = list(set(stations.index).intersection(points_edited.index))\n",
    "stations = stations.loc[ids]\n",
    "for id in ids:\n",
    "    for col in ['subcatchment', 'river', 'catchment']:\n",
    "        if points_edited.loc[id, col] != np.nan:\n",
    "            stations.loc[id, col] = points_edited.loc[id, col]\n",
    "\n",
    "# add subcatchment and river order\n",
    "stations.loc[ids, ['strahler', 'pfafstetter']] = points_edited.loc[ids, ['strahler', 'pfafstetter']]\n",
    "\n",
    "# rename columns\n",
    "#stations.columns = ['name', 'X', 'Y', 'area', 'subcatchment', 'river', 'catchment', 'country', 'strahler', 'subcatchment_order']\n",
    "\n",
    "print('no. stations:\\t{0}'.format(stations.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aab79515-371d-43b9-bde0-552ab0a3a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xarrys with station coordinates that will be used to extract data\n",
    "x = xr.DataArray(stations.X, dims='id')\n",
    "y = xr.DataArray(stations.Y, dims='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bd462c-d693-4986-a926-ba0b56d8c02a",
   "metadata": {},
   "source": [
    "## 3 Discharge data\n",
    "\n",
    "It loads the EFAS discharge reanalyses for the complete EFAS domain, and out of if only it extracts the discharge time series for the previously selected reporting points and the study period. The discharge timeseries are saved in a _parquet_ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf0cd530-28e7-40d5-8601-478e2de8f7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\casadje\\AppData\\Local\\Temp\\ipykernel_6228\\40025936.py:29: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for stn in tqdm_notebook(dis.id.data):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c149961f48264b5ca573ff6b4b1cfb0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var = 'discharge'\n",
    "\n",
    "# output folder\n",
    "path_out = cfg.get('paths', {}).get('output', {}).get(var, {}).get('reanalysis', f'../data/{var}/reanalysis/')\n",
    "if os.path.exists(path_out) is False:\n",
    "    os.makedirs(path_out)\n",
    "\n",
    "# load dataset and extract variable discharge\n",
    "dis = xr.open_mfdataset(f'{path_in}*.nc')['dis06']\n",
    "dis.close()\n",
    "\n",
    "# trim data to the study period\n",
    "dis = dis.sel(time=slice(start, end))\n",
    "\n",
    "# extract discharge for the selected stations\n",
    "dis = dis.sel(x=x, y=y, method='nearest')\n",
    "dis = dis.drop(['x', 'y', 'step', 'surface', 'latitude', 'longitude', 'valid_time'])\n",
    "\n",
    "# compute the lazy DataArray\n",
    "dis = dis.compute()\n",
    "\n",
    "# add 6 h to the timesteps\n",
    "dis =dis.rename({'time': 'datetime'})\n",
    "dis['datetime'] = dis.datetime + np.timedelta64(6, 'h')\n",
    "\n",
    "# save extraction as NetCDF files\n",
    "dis.name = var\n",
    "for stn in tqdm_notebook(dis.id.data):\n",
    "    dis.sel(id=stn).to_netcdf(f'{path_out}{stn:>04}.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f7f0ae-da93-4861-b901-cb05626a0fb3",
   "metadata": {},
   "source": [
    "## 4 Exceedance\n",
    "\n",
    "### 4.1 Discharge thresholds\n",
    "\n",
    "The discharge thresholds are the discharge values for return periods 1.5, 2, 5, 10, 20, 50, 100, 200 and 500 years. The data is supplied in a NetCDF file that contains all the river network in Europe. This NetCDF is loaded as an _xarray_ and the values corresponding to the selected reporting points are extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6572738f-55f2-4365-af91-f088dfbf0e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load thresholds\n",
    "thresholds = xr.open_dataset(file_thresholds)\n",
    "\n",
    "# extract thresholds for the selected stations\n",
    "thresholds = thresholds.sel(x=x, y=y, method='nearest')\n",
    "thresholds = thresholds.drop(['x', 'y'])\n",
    "\n",
    "# add thresholds to the DataFrame of stations\n",
    "for var, da in thresholds.items():\n",
    "    stations.loc[thresholds.id, var] = da.values.round(1)\n",
    "\n",
    "# export DataFrame of stations\n",
    "stations.to_parquet(file_out_stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03efa13-8857-4695-8ff1-7e31b45ca0db",
   "metadata": {},
   "source": [
    "### 4.2 Exceedance over threshold\n",
    "\n",
    "This block of code computes the exceedances of the 5-year return period out of the discharge timeseries and thresholds that were previously extracted. The results are seved in a _parquet_ file that will be used in the succeeding analys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5732330f-e960-4c9a-8a6a-25f51c501a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\casadje\\AppData\\Local\\Temp\\ipykernel_6228\\2053547964.py:24: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for stn in tqdm_notebook(exceedance.id.data):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81fefbea9eb34432b593336408bf1fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var = 'exceedance'\n",
    "\n",
    "# output folder\n",
    "path_out = cfg.get('paths', {}).get('output', {}).get(var, {}).get('reanalysis', f'../data/{var}/reanalysis/')\n",
    "if os.path.exists(path_out) is False:\n",
    "    os.makedirs(path_out)\n",
    "\n",
    "# compute exceedance\n",
    "thr = f'rl{rp}'\n",
    "exceedance = dis >= thresholds[thr]\n",
    "\n",
    "if reducing_factor is not None:\n",
    "    # compute exceendance over the reduced threshold\n",
    "    exceedance_buffer = dis >= thresholds[thr] * (1 - reducing_factor)\n",
    "    \n",
    "    # create a 3-class exceedance DataArray:\n",
    "    # 0: non-exceedance\n",
    "    # 1: exceeedance over the reduced threshold\n",
    "    # 2: exceedance over the threshold\n",
    "    exceedance = np.maximum(exceedance.astype(int) * 2, exceedance_buffer.astype(int))\n",
    "\n",
    "# save as NetCDF files\n",
    "exceedance.name = var\n",
    "for stn in tqdm_notebook(exceedance.id.data):\n",
    "    exceedance.sel(id=stn).to_netcdf(f'{path_out}{stn:>04}.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
