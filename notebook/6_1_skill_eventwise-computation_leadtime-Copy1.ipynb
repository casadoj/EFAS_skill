{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fd5f453-13c1-47c1-ad27-8af80b47ee08",
   "metadata": {},
   "source": [
    "# Skill assessment - computation\n",
    "***\n",
    "\n",
    "**Author**: Chus Casado Rodr√≠guez<br>\n",
    "**Date**: 20-03-2023<br>\n",
    "\n",
    "\n",
    "**Introduction**:<br>\n",
    "In this notebook I will analyse the EFAS skill in predicting flood events in general, i.e., looking whether events where predicted at some point in time, regardless of neither the offset nor the duration of the event.\n",
    "\n",
    "**Questions**:<br>\n",
    "\n",
    "* [ ] Take into account the model spread?\n",
    "* [ ] Aggregate results by river/administrative area? EFAS aims at alerting administrations about incoming events in there administrative area, shouldn't that aggregation be included in the results?\n",
    "* [ ] Remove extremely bad performing stations.\n",
    "\n",
    "**Pending tasks**:<br>\n",
    "\n",
    "* [x] Weighting the model average by the Brier score?\n",
    "* [x] Sort stations by catchment area (or other order)?\n",
    "* [x] Persistence\n",
    "* [ ] Analyse only the periods/stations close to an observed event and compute f1 for this extraction. Later on, on the complementary subset of data another metric must be computed to avoid false positives, p.e., false alarm ratio.\n",
    "\n",
    "\n",
    "\n",
    "**Interesting links**<br>\n",
    "[Evaluation metrics for imbalanced classification](https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/)<br>\n",
    "[Cross entropy for machine learning](https://machinelearningmastery.com/cross-entropy-for-machine-learning/)<br>\n",
    "[Probability metrics for imbalanced classification](https://machinelearningmastery.com/probability-metrics-for-imbalanced-classification/)<br>\n",
    "[ROC curves and precision-recall curves for imbalanced classification](https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification/)<br>\n",
    "[Instructions for sending EFAS flood notifications](https://efascom.smhi.se/confluence/display/EDC/Instructions+for+sending%2C+upgrading+and+deactivating+EFAS+Flood+Notifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ee7a0f-f62b-4a8b-8147-c46a2e2471ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import operator\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "# import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "path_root = os.getcwd()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.chdir('../py/')\n",
    "from computations import *\n",
    "from plots import *\n",
    "os.chdir(path_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4e0fda-fb63-48b5-9cc3-679d702d934a",
   "metadata": {},
   "source": [
    "## 1 Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826d534e-e8e3-410f-8bc1-6ab40dc0c903",
   "metadata": {},
   "source": [
    "### 1.1 Notification criteria\n",
    "\n",
    "#### Probability threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4265e9c6-daf0-4538-b5f4-504bf79f0813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability thresholds\n",
    "thresholds = np.arange(.05, .96, .05).round(2)\n",
    "# thresholds = np.round(sigmoid(np.linspace(-10, 10, 50)), 5)\n",
    "probabilities = xr.DataArray(thresholds, dims=['probability'], coords={'probability': thresholds})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10b5514-f62d-4efc-81d1-bf88a9849dfd",
   "metadata": {},
   "source": [
    "#### Persistence\n",
    "\n",
    "A list of tuples with two values: the first value is the width of the window rolling sum, and the second value the minimum number of positives in that window so that a notification is raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd790a6-704e-402c-8d1a-79a25cc1ea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "persistence = [(1, 1), (2, 2), (2, 3), (3, 3), (2, 4), (3, 4), (4, 4)]\n",
    "persistence = {'/'.join([str(i) for i in pers]): pers for pers in persistence}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d537e30d-2cc1-4560-895e-480c70d3a79d",
   "metadata": {},
   "source": [
    "#### Leadtime\n",
    "\n",
    "Notifications are only sent with a minimum leadtime (h)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0059b69c-bdd6-4369-9e0f-d0a9415f3f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_leadtime = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665c8ad7-1c86-4146-800b-0b6fc8be8862",
   "metadata": {},
   "source": [
    "### 1.2 Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a0a6a6-bcbd-4056-8b6c-0eae6a8dacca",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'EFAS'\n",
    "\n",
    "# path where results will be saved\n",
    "results_path = '../results/'\n",
    "path_out = f'{results_path}skill/{name}/eventwise/'\n",
    "if os.path.exists(path_out) is False:\n",
    "    os.makedirs(path_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf9fefe-8375-44af-b1c0-f1886b763c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coordinate reference system when plotting maps\n",
    "proj = ccrs.LambertAzimuthalEqualArea(central_longitude=10, central_latitude=52, false_easting=4321000, false_northing=3210000, globe=ccrs.Globe(ellipse='GRS80'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ca1667-e5d2-45fb-83a1-647f9c9c4e7a",
   "metadata": {},
   "source": [
    "## 2 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b284a86-2d64-4907-a259-e3c67b6de2d5",
   "metadata": {},
   "source": [
    "### 2.1 Stations\n",
    "\n",
    "I load all the stations that where selected in a previous [notebook](3_0_select_stations.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad2ba6a-e095-4c1c-8f2c-3738dee497be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load selected points for all the catchments\n",
    "stations = pd.DataFrame()\n",
    "catchments = []\n",
    "folders = os.listdir(f'{results_path}reporting_points/')\n",
    "for folder in folders:\n",
    "    try:\n",
    "        stn_cat = pd.read_csv(f'{results_path}reporting_points/{folder}/points_selected.csv', index_col='station_id')\n",
    "        stations = pd.concat((stations, stn_cat))\n",
    "        catchments.append(folder)\n",
    "    except:\n",
    "        continue\n",
    "print('no. stations:\\t\\t\\t{0}'.format(stations.shape[0]))\n",
    "\n",
    "# remove unnecessary attributes\n",
    "stations.drop(['rl1.5', 'rl2', 'rl10', 'rl20', 'rl50', 'rl100', 'rl200', 'rl500', 'strahler', 'pfafstetter', 'country'], axis=1, inplace=True)\n",
    "\n",
    "# convert into integers\n",
    "stations[['X', 'Y', 'area', 'rl5']] = stations[['X', 'Y', 'area', 'rl5']].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6898ef9-0c78-4b77-959b-fb87de8716c5",
   "metadata": {},
   "source": [
    "### 2.2 Forecast: exceedance\n",
    "\n",
    "I load the preprocessed forecast data. In a previous [notebook](4_0_forecast_exceedance_review.ipynb), the forecasted discharge was converted to probability of exceeding the 5-year return period threshold. The ouput of that process is a NetCDF file per station with the forecasted probability of exceedance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c38388-8774-48d5-b80a-a9ae0884243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find NetCDF files\n",
    "path_forecast = '../data/exceedance/forecast/'\n",
    "files = glob.glob(f'{path_forecast}*.nc')\n",
    "files = [file for file in files if int(file.split(sep='\\\\')[-1].split('/')[-1].split('.')[0]) in stations.index]\n",
    "\n",
    "# load data to a chunked DataArray\n",
    "fore_exc = xr.open_mfdataset(files, combine='nested', concat_dim='id', chunks={'id': 1}).exceedance\n",
    "fore_exc['id'] = fore_exc.id.astype(int)\n",
    "\n",
    "# study period based on the extent of the forecast data\n",
    "#start, end = [(fore_exc.forecast[i] + fore_exc.leadtime[i]).data for i in [0, -1]]\n",
    "#start, end = [(date - np.datetime64('1970-01-01T01:00:00Z')) / np.timedelta64(1, 's') for date in [start, end]]\n",
    "#start, end = [datetime.fromtimestamp(timestamp) for timestamp in [start, end]]\n",
    "\n",
    "#print(f'Study period\\nstart:\\t{start}\\nend:\\t{end}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6e04c8-3020-45b6-a0f6-96ecae47fcff",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Reformat data\n",
    "\n",
    "To be able to compute skill in a simple manner, I need to reshape the exceedance forecast. Up until now, the exceedance forecast is saved in a matrix where the `forecast` is one dimension, and the `leadtime` is another dimension, in a way that there aren't missing values in the matrix. However, this shape is not convenient for comparing against the observed exceedances of the discharge threshold. Instead, I will reshape the original exceendance forecast into a new matrix in which a dimension named `datetime` represents actual date and time, and another dimension represents leadtime. In this way, a column in the matrix represents the same timestep and can be easily compared against observations. The drawback of this approach is that it will create missing values in the lower-left and upper-right corners of the matrix; therefore, I will remove these parts of the matrix (`trim=True`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4f7332-fd90-4896-8eb5-0ff41f5ede86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the DataArray of forecasted exceedance\n",
    "pred = reshape_DataArray(fore_exc, trim=True, chunks={'id': 1})\n",
    "del fore_exc\n",
    "\n",
    "print(pred.dims)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c23cc9-47d1-45a9-9387-66788d90aed1",
   "metadata": {},
   "source": [
    "### 2.3 Reanalysis: exceedance & events\n",
    "\n",
    "I load the preprocessed reanalysis data. In a previous [notebook](2_2_reanalysis_preprocessing.ipynb), the reanalysis discharge data was preprocessed to create timeseries of exceedance over the 5-year return period threshold.\n",
    "\n",
    "Out of the exceedance timeseries I calculate another timeseries of the onset of flood events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c62d689-6c50-4751-9f83-68ebaff3ec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_reanalysis = '../data/exceedance/reanalysis/'\n",
    "\n",
    "# load probability of exceeding the discharge threshold in the REANALYSIS data\n",
    "rean_exc = pd.read_parquet(f'{path_reanalysis}/exceedance_rl5.parquet')\n",
    "rean_exc.columns = rean_exc.columns.astype(int)\n",
    "rean_exc = rean_exc.loc[pd.to_datetime(pred.datetime.data), stations.index.tolist()]\n",
    "\n",
    "# compute onsets of the flood events\n",
    "rean_onsets = rean_exc.astype(int).diff(axis=0) == 1\n",
    "rean_onsets.iloc[0,:] = rean_exc.iloc[0,:]\n",
    "\n",
    "# create a DataArray with the number of observed events per station\n",
    "n_events_obs = xr.DataArray(rean_onsets.sum(), dims=['id'], coords={'id': rean_onsets.columns.tolist()})\n",
    "stations['n_events_5'] = n_events_obs.to_pandas()\n",
    "print('no. events:\\t\\t\\t{0}'.format(n_events_obs.sum().data))\n",
    "del rean_onsets\n",
    "\n",
    "# select stations with events\n",
    "mask_stn = (n_events_obs > 0).to_pandas()\n",
    "print('no. stations with events:\\t{0}'.format(mask_stn.sum()))\n",
    "\n",
    "# colormap used for the maps\n",
    "cmap, norm = create_cmap('Reds', np.arange(0, n_events_obs.max(), 1), 'no. events', [0, (.5, .5, .5, .5)])\n",
    "plot_map_stations(stations.X, stations.Y, n_events_obs.to_pandas(), mask=~mask_stn,\n",
    "                  cmap=cmap, norm=norm, size=5, figsize=(8, 8),alpha=.7)\n",
    "plt.colorbar(plot_map_stations.colorbar, shrink=.33, label='no. events')\n",
    "plt.savefig(f'{path_out}/map_observed_events.png', dpi=300, bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf9aac8-121d-4fa4-abcf-994389d8e552",
   "metadata": {},
   "source": [
    "> ***Figure 1**. Number of observed flood events in the selected reporting points.Small gray dots represent points without observed events.*\n",
    "\n",
    "The number of events has increased after giving priority to reporting points upstream during the selection process. Out of the 900 selected reporting points, 322 suffered a flood event in the last two years, summing up to a total of 526 observed flood events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563ce24a-bac0-479a-acc1-1759afb27150",
   "metadata": {},
   "source": [
    "##### Reformat data\n",
    "\n",
    "I convert the reanalysis data into a `xarray.DataArray`, which will be useful in the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1518df41-719d-4c4f-9d7b-e3b63af21aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataArray with observed threshold exceedance\n",
    "obs = df2da(rean_exc, dims=['id', 'datetime'], plot=False, figsize=(16, 20), title='observed exceendace')\n",
    "del rean_exc\n",
    "\n",
    "# expected probability of an exceedance\n",
    "obs = obs.astype(int)\n",
    "\n",
    "print(obs.dims)\n",
    "print(obs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc24db9-d53a-4325-9360-463ce52cb737",
   "metadata": {},
   "source": [
    "The following plot is a graphical explanation of the new format in which forecast exceedance probability is stored. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a9d4d8-be29-4031-85e6-8730a365a187",
   "metadata": {},
   "source": [
    "### 2.4 Weighing factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d71041-be65-417b-b965-330ef8393dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by the number of membes\n",
    "weights_member = xr.open_dataarray(f'{path_out}weights_member.nc')\n",
    "\n",
    "# by the Brier score\n",
    "weights_brier = xr.open_dataarray(f'{path_out}weights_brier.nc', engine='netcdf4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c9a1f0-2e0d-475a-9b19-cc35c9ff5b6b",
   "metadata": {},
   "source": [
    "## 3 Assess skill\n",
    "\n",
    "In this section I will compute the skill of the EFAS predictions in different ways. In all the following sections I will work with three metrics: recall, precision and the f1-score. The three metrics are based in the contingency table of hits ($TP$ for true positives), false alarms ($FP$ for false positives) and misses ($FN$ for false negatives).\n",
    "\n",
    "$$recall = \\frac{TP}{TP + FN}$$\n",
    "$$precision = \\frac{TP}{TP + FP}$$\n",
    "$$f1 = \\frac{2 \\cdot TP}{2 \\cdot TP + FN + FP}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa55160-c6a2-456f-950d-b3af15a8dac2",
   "metadata": {},
   "source": [
    "### 3.2 Where events predicted at any point in time?\n",
    "\n",
    "The objective of this section is to check if observed events where predicted at all, no matter leadtime.\n",
    "\n",
    "To convert exceedance probability for each meteo forcing into predicted events we need to come up with a total exceedance probability, i.e., combine the probabilities of each meteo forcing into a single probability value. This total probability will later be compared against a probability threshold to discern events. I will test four different approaches:\n",
    "\n",
    "* `current`:  the current notification criteria. At least a probabilistic and deterministic model must exceed the probability threshold.\n",
    "* `model_mean`: a simple mean over the 4 forcings.\n",
    "* `member_weighted`: a mean weighted by the number of members that each meteo forcing contains. In this approach the probabilistic models, specifically that from ECMWF, prevail.\n",
    "* `brier_weighted`: a mean weighted by the previously calculated Brier score. This is an approach in between the simple mean and the mean weighted by the number of members. Probabilistic forcings will prevail because they proved to be more skillful, but their relative importance is lower than in the previous approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28940917-a845-47be-a0a2-b3d288fe7842",
   "metadata": {},
   "source": [
    "#### 3.2.1 Exceedance over probability threshold\n",
    "\n",
    "In this section I will first compute the total probability using the four approaches previously explained, and then compare the results against the probability thresholds. The outcome will be a boolean dataset of exceedances thresholds named `pred_exc` with 5 dimensions (approach, id, leadtime, datetime, probability)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7338ad6-2688-4435-8edd-f4fbdcd1c133",
   "metadata": {},
   "source": [
    "##### Current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cceb3ed-72c3-4acf-9811-c2ae2cf2c86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exceedance according to current criteria\n",
    "deterministic = (pred.sel(model=['EUD', 'DWD']) >= probabilities).any('model')\n",
    "probabilistic = (pred.sel(model=['EUE', 'COS']) >= probabilities).any('model')\n",
    "current = deterministic & probabilistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd0298-c39a-492f-8302-3325bfb57c1a",
   "metadata": {},
   "source": [
    "##### Model mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01af47e-014b-4af3-be6f-d649e2b19a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exceedance according to mean over models\n",
    "model_mean = pred.mean('model', skipna=True) >= probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80bc9ef-13e6-4636-84e5-7319e9f832d2",
   "metadata": {},
   "source": [
    "##### Member weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f19b519-b182-42d2-b369-6173d1e93c1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exceedance according to the mean over models weighted by the number of members\n",
    "member_weighted = pred.weighted(weights_member).mean('model', skipna=True) >= probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e1dd49-3a9a-4cd3-be9f-0772407aea4f",
   "metadata": {},
   "source": [
    "##### Brier weighted\n",
    "\n",
    "To create a weight based on the Brier score I need to invert the values, since lower Brier score values represent better models. Therefore, I compute the inverse of the squared Brier score. To normalize weights (values between 0 and 1) I divide the previous weight matrix by its sum over models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1565b503-50ef-43b2-95b7-4058c3e4833a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exceedance according to the mean over models weighted by the inverse Brier score\n",
    "brier_weighted = pred.weighted(weights_brier.fillna(0)).mean('model', skipna=True) >= probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986de516-b223-4737-9a02-aba3af078f5c",
   "metadata": {},
   "source": [
    "##### Combine approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dcc9eb-b971-4806-9386-e3c4e9aa299a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge all total probability approaches in a single DataArray\n",
    "pred_exc = xr.Dataset({\n",
    "                        'current': current,\n",
    "                        'model_mean': model_mean,\n",
    "                        'member_weighted': member_weighted,\n",
    "                        'brier_weighted': brier_weighted,\n",
    "                        }).to_array(dim='approach')\n",
    "\n",
    "pred_exc.dims, pred_exc.shape\n",
    "\n",
    "del pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b184cba5-be1b-4e7b-8403-4355483f15a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# heatmap of weights\n",
    "fig, axes = plt.subplots(nrows=2, figsize=(6, 3), constrained_layout=True, sharex=True, sharey=True)\n",
    "Weights = xr.Dataset({'no. member': weights_member, 'Brier score': weights_brier})\n",
    "for i, (ax, (var, da)) in enumerate(zip(axes, Weights.items())):\n",
    "    htm = plot_DataArray(da, vmin=0, vmax=1, ax=ax, ytick_step=1, xtick_step=1, title=f'weighted by {var}', cbar_kws={'shrink': .66})\n",
    "    if i == len(axes) - 1:\n",
    "        ax.set_xlabel('leadtime (h)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ebc6c1-2470-4292-a97a-22c3eb0023c9",
   "metadata": {},
   "source": [
    "> ***Figure 5**. Weighting matrixes used to compute total probability according to the number of members of the meteorological forcing (top) or the skill measured in terms of Brier score (bottom).*\n",
    "\n",
    "The previous plot shows the weighting factors for the mean weighted by the number of members of each model (top), and the mean weighted by the performace of the model measured in terms of Brier score (bottom). When taking into account the number of members, obviously COSMO-LEPS and EUE get the vast majority of the weight, rendering no importance to any of the deterministic models. Between the two probabilistic models, EUE prevails over COSMO-LEPS, even though we've seen that their performance is comparable. However, when weighting according to performance, COSMO-LEPS and EUE get a very similar value during the leadtime span for which COSMO-LEPS is available. The probabilistic models have lower weights, but not as insignificat as when weighting by the number of members. In this sense, this last weighting method is a halfway point between the simple model mean and the mean weighted by the number of members."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8430c1-5592-4e83-ada1-1ab5de7593a0",
   "metadata": {},
   "source": [
    "#### 3.2.2 Compute skill\n",
    "\n",
    "The computation of skill consists on three steps:\n",
    "\n",
    "1. Define events according to the notification criteria (persistence and minimum leadtime). The probability threshold was already taken into account when computing the exceedance over threshold in the previous section.\n",
    "\n",
    "2. Compute hits, misses and false alarms by comparing observation and predictions. At this step a window function is applied to count as hits predictions that have minor time lags compared with the observation.\n",
    "\n",
    "3. Compute skill metrics (recall, precicion and f1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69761486-4af0-45b9-bef1-9f3c113b8474",
   "metadata": {},
   "source": [
    "##### Define events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1179c78e-b8f3-4538-ae91-d79b0fde6cea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_leadtime = 60\n",
    "resample = None\n",
    "path = f'{path_out}no_resample_by_leadtime/'\n",
    "\n",
    "for label, pers in tqdm_notebook(persistence.items()):\n",
    "    \n",
    "    #  check if the output files already exist\n",
    "    file_suffix = f'_persistence_{label}.nc'.replace('/', '-')\n",
    "    nc_files = [f for f in glob.glob(f'{path}*{file_suffix}') if 'TP' in f or 'FN' in f or 'FP' in f]\n",
    "    if len(nc_files) == 3:\n",
    "        print(f'Persistence {label} had already been computed.')\n",
    "        continue\n",
    "\n",
    "    # compute predicted events\n",
    "    pred_events = compute_events(pred_exc, persistence=pers, resample=resample, min_leadtime=min_leadtime)#by_leadtime=True)\n",
    "\n",
    "    # calculate the number of predicted events\n",
    "    n_events_pred = count_events(pred_events).compute()\n",
    "    # export as NetCDF\n",
    "    file_out = f'{path}predicted_events{file_suffix}'\n",
    "    print(f'Exporting file {file_out}')\n",
    "    n_events_pred.to_netcdf(file_out)\n",
    "\n",
    "    # compute hits, misses and false alarms\n",
    "    if 'leadtime' in pred_events.dims:\n",
    "        hits = [compute_hits(obs, pred_events.sel(leadtime=lt), center=True, w=5) for lt in pred_events.leadtime.data]\n",
    "        hits = xr.concat(hits_lt, dim='leadtime').compute()\n",
    "    else:\n",
    "        hits = compute_hits(obs, pred_events, center=True, w=5).compute()\n",
    "    # export results as NetCDF\n",
    "    for var, da in hits.items():\n",
    "        file_out = f'{path}{var}{file_suffix}'\n",
    "        print(f'Exporting file {file_out}')\n",
    "        da.to_netcdf(file_out)\n",
    "\n",
    "    del pred_events, hits, n_events_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7734337d-e815-4dda-89b1-f0f43818ac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resample = '12h'\n",
    "\n",
    "for label, pers in tqdm_notebook(persistence.items()):\n",
    "\n",
    "    #  check if the output files already exist\n",
    "    file_suffix = f'_persistence_{label}.nc'.replace('/', '-')\n",
    "    nc_files = [f for f in glob.glob(f'{path_out}new/*{file_suffix}') if 'TP' in f or 'FN' in f or 'FP']\n",
    "    if len(nc_files) == 3:\n",
    "        print(f'Persistence {label} had already been computed.')\n",
    "        continue\n",
    "    \n",
    "    # compute predicted events\n",
    "    pred_events = compute_events(pred_exc, persistence=pers, resample='12h', min_leadtime=min_leadtime)\n",
    "\n",
    "    # calculate the number of predicted events\n",
    "    n_events_pred = count_events(pred_events).compute()\n",
    "    # export as NetCDF\n",
    "    file_out = f'{path_out}predicted_events{file_suffix}'\n",
    "    print(f'Exporting file {file_out}')\n",
    "    n_events_pred.to_netcdf(file_out)\n",
    "\n",
    "    # compute hits, misses and false alarms\n",
    "    hits_lt = [compute_hits(obs, pred_events.sel(leadtime=lt), center=True, w=5) for lt in pred_events.leadtime.data]\n",
    "    hits_lt = xr.concat(hits_lt, dim='leadtime').compute() \n",
    "    # export results as NetCDF\n",
    "    for var, da in hits_lt.items():\n",
    "        file_out = f'{path_out}new/{var}{file_suffix}'\n",
    "        print(f'Exporting file {file_out}')\n",
    "        da.to_netcdf(file_out)\n",
    "\n",
    "    del pred_events, hits_lt, n_events_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f42131-1faa-43d4-a9f7-a311992e53bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
