{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a2493eb",
   "metadata": {},
   "source": [
    "# Skill assessment\n",
    "***\n",
    "\n",
    "**Author**: Chus Casado Rodr√≠guez<br>\n",
    "**Date**: 03-08-2023<br>\n",
    "\n",
    "\n",
    "**Introduction**:<br>\n",
    "In this notebook I will analyse the EFAS skill in predicting flood events in general, i.e., looking whether events where predicted at some point in time, regardless of neither the offset nor the duration of the event.\n",
    "\n",
    "**Interesting links**<br>\n",
    "[Evaluation metrics for imbalanced classification](https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/)<br>\n",
    "[Cross entropy for machine learning](https://machinelearningmastery.com/cross-entropy-for-machine-learning/)<br>\n",
    "[Probability metrics for imbalanced classification](https://machinelearningmastery.com/probability-metrics-for-imbalanced-classification/)<br>\n",
    "[ROC curves and precision-recall curves for imbalanced classification](https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification/)<br>\n",
    "[Instructions for sending EFAS flood notifications](https://efascom.smhi.se/confluence/display/EDC/Instructions+for+sending%2C+upgrading+and+deactivating+EFAS+Flood+Notifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ee7a0f-f62b-4a8b-8147-c46a2e2471ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import seaborn as sns\n",
    "import cartopy.crs as ccrs\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm_notebook\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import pickle\n",
    "import yaml\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split, KFold\n",
    "\n",
    "path_root = os.getcwd()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.chdir('../py/')\n",
    "from compute import *\n",
    "#from compute import hits2skill, define_area_ranges, hits_by_area, summarize_by_area\n",
    "from convert import dict2da\n",
    "from optimize import find_best_criterion, find_best_criteria, find_best_criteria_cv\n",
    "from plot.results import lineplot_hits, lineplot_skill, plot_skill_training, plot_hits_by_variable, plot_skill_by_variable, plot_skill_by_probability\n",
    "from plot.maps import create_cmap, map_stations, map_hits, map_skill, map_events\n",
    "os.chdir(path_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b0a37e-716a-4a13-b6ec-1a474d080918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the default text font size\n",
    "plt.rc('font', size=15)\n",
    "# Set the axes title font size\n",
    "plt.rc('axes', titlesize=16)\n",
    "# Set the axes labels font size\n",
    "plt.rc('axes', labelsize=15)\n",
    "# Set the font size for x tick labels\n",
    "plt.rc('xtick', labelsize=13)\n",
    "# Set the font size for y tick labels\n",
    "plt.rc('ytick', labelsize=13)\n",
    "# Set the legend font size\n",
    "plt.rc('legend', fontsize=13)\n",
    "# Set the font size of the figure title\n",
    "plt.rc('figure', titlesize=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4e0fda-fb63-48b5-9cc3-679d702d934a",
   "metadata": {},
   "source": [
    "## 1 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9900bcc1-319d-46ce-bcc7-1e64404a7bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../conf/config_NWP_leadtime_ranges.yml\", \"r\", encoding='utf8') as ymlfile:\n",
    "    cfg = yaml.load(ymlfile, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0f91d7-4689-4ee0-8839-548071e79a8f",
   "metadata": {},
   "source": [
    "### 1.1 Reporting points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f00a4e-1c59-4a35-93da-3fc207f88ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# area threshold\n",
    "area_threshold = cfg.get('reporting_points', {}).get('area', 500)\n",
    "\n",
    "# reporting points\n",
    "path_stations = cfg.get('reporting_points', {}).get('output', '../results/reporting_points/')\n",
    "file_stations = f'{path_stations}reporting_points_over_{area_threshold}km2.parquet'\n",
    "\n",
    "# catchments\n",
    "catchments = cfg.get('reporting_points', {}).get('catchments', None)\n",
    "\n",
    "# minimum performance required from the reporting points\n",
    "min_kge = cfg.get('reporting_points', {}).get('KGE', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1185a7cd-a77a-4137-bd8f-9103abd38c68",
   "metadata": {},
   "source": [
    "### 1.2 Hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7394f9de-8e47-40de-bda0-6cdf4c16ade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of the rolling window used to compute hits\n",
    "window = cfg.get('hits', {}).get('window', 1)\n",
    "\n",
    "# dissagregate the analysis by seasons?\n",
    "seasonality = cfg.get('hits', {}).get('seasonality', False)\n",
    "\n",
    "# path that contains the NetCDFs with hit, misses and false alarms pro\n",
    "path_in = cfg.get('hits', {}).get('output', '../results/hits/')\n",
    "path_in = f'{path_in}window_{window}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e08960-70df-464f-b0f5-5635b080ddf9",
   "metadata": {},
   "source": [
    "### 1.3 Skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dba0a11-2dcb-44da-92b2-594547118224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current operationa criteria\n",
    "current_criteria = cfg.get('skill', {}).get('current_criteria', None)\n",
    "\n",
    "# fixed notification criteria\n",
    "min_leadtime = cfg.get('skill', {}).get('leadtime', 60)\n",
    "min_area = cfg.get('skill', {}).get('area', 2000)\n",
    "\n",
    "# coefficient of the fbeta-score\n",
    "beta = cfg.get('skill', {}).get('beta', 1) #[.8, 1, 1.2]\n",
    "metric = f'f{beta}'\n",
    "\n",
    "# optimization parameters\n",
    "kfold = cfg.get('skill', {}).get('optimization', {}).get('kfold', None)\n",
    "train_size = cfg.get('skill', {}).get('optimization', {}).get('train_size', .8)\n",
    "stratify = cfg.get('skill', {}).get('optimization', {}).get('stratify', False)\n",
    "tolerance = cfg.get('skill', {}).get('optimization', {}).get('tolerance', 1e-2)\n",
    "min_spread = cfg.get('skill', {}).get('optimization', {}).get('minimize_spread', True)\n",
    "\n",
    "# path where results will be saved\n",
    "path_out = cfg.get('skill', {}).get('output', f'../results/skill/')\n",
    "if min_kge is not None:\n",
    "    path_out = f'{path_out}window_{window}/kge_{min_kge}/'\n",
    "else:\n",
    "    path_out = f'{path_out}window_{window}/no_kge/'\n",
    "for path in [path_out, f'{path_out}{metric}/']:\n",
    "    if os.path.exists(path) is False:\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9737b56-1e73-4101-b2a9-e52ffb05c0b8",
   "metadata": {},
   "source": [
    "## 2 Data\n",
    "### 2.1 Reporting points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f476112-311f-4e14-9619-a7e82ebbe048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load table of fixed reporting points\n",
    "stations = pd.read_parquet(file_stations)\n",
    "stations[['X', 'Y', 'area']] = stations[['X', 'Y', 'area']].astype(int)\n",
    "\n",
    "# select stations that belong to the selected catchments\n",
    "if catchments is not None:\n",
    "    if isinstance(catchments, list) is False:\n",
    "        catchments = [catchments]\n",
    "    stations = stations.loc[stations.catchment.isin(catchments),:]\n",
    "\n",
    "# remove points with a performance (KGE) lower than the established threshold\n",
    "if min_kge is not None:\n",
    "    mask_kge = ~(stations.KGE <= min_kge)\n",
    "    stations = stations.loc[mask_kge]\n",
    "else:\n",
    "    # remove station with erroneous behaviour\n",
    "    stations = stations.loc[~(stations.n_events_obs >= 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab57573-7be4-46c6-8520-9948cd1e33ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask stations with events\n",
    "stations_w_events = (stations.n_events_obs > 0)\n",
    "\n",
    "print('All points')\n",
    "print('----------')\n",
    "print(f'no. reporting points:\\t\\t{stations.shape[0]}')\n",
    "print('no. stations with events:\\t{0}'.format(stations_w_events.sum()))\n",
    "print('no. observed events:\\t\\t{0}'.format(stations.n_events_obs.sum()))\n",
    "\n",
    "# select stations according to catchment area\n",
    "if min_area > area_threshold:\n",
    "    stations_optimize = stations.loc[stations.area >= min_area].index\n",
    "else:\n",
    "    stations_optimize = stations.index\n",
    "\n",
    "print('\\nPoints selected for otimization')\n",
    "print('-------------------------------')\n",
    "print(f'no. reporting points:\\t\\t{len(stations_optimize)}')\n",
    "print('no. stations with events:\\t{0}'.format((stations.loc[stations_optimize, 'n_events_obs'] > 0).sum()))\n",
    "print('no. observed events:\\t\\t{0}'.format(stations.loc[stations_optimize, 'n_events_obs'].sum()))\n",
    "\n",
    "# suffix that will be used when saving plots\n",
    "suffix = f'{min_area}km2_{len(stations_optimize)}points'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5186b23-9639-49fa-9f75-f55cce348029",
   "metadata": {},
   "source": [
    "**Distribution of catchment area**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20f23b5-0454-4943-b7ef-c20fc7c85065",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = area_threshold\n",
    "xmax = 500001#np.ceil(stations.area.max() / 500) * 500\n",
    "bins = np.arange(xmin, xmax, 500).astype(int)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5.5))\n",
    "sns.histplot(stations.area, ax=ax, bins=bins, label='all')\n",
    "sns.histplot(stations[stations_w_events].area, ax=ax, color='orange', bins=bins, label='w/ events')\n",
    "ax.axvline(min_area, color='k', ls=':', lw=.75)\n",
    "ax.set(xlabel='area (km¬≤)', ylabel='no. reporting points', xlim=(xmin, 50000));\n",
    "ax.xaxis.set_major_locator(MultipleLocator(10000))\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(2000))\n",
    "ax.yaxis.set_major_locator(MultipleLocator(100))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(20))\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "ax.legend();\n",
    "\n",
    "plt.savefig(f'{path_out}area_distribution_{suffix}.jpg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb112cb-8c44-4c38-8a13-c30bd57ddb07",
   "metadata": {},
   "source": [
    "> ***Figure 1**. Distribution of the reporting points according to catchment area. The complete set of reporting points is shown in blue, and the subset of reporting points with observed flood events during the study period is shown in red. The balck, dotted line represents the minimum catchment area that will be used for the optimization of the notification criteria.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c9fee9-82e2-4f8c-908c-0f2b2d102011",
   "metadata": {},
   "source": [
    "Two ideas to extract from the previous plot:\n",
    "\n",
    "* When considering all the catchment areas, only **41% of the fixed reporting points had a flood event** during the study period. This figure is very similar (37%) when considering points with a catchment area larger than 2000 km¬≤.\n",
    "\n",
    "* **40% of the fixed reporting points have a catchment area smaller than 2000 km¬≤**, therefore the are excluded from the optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bdbed9-6609-44fa-8229-b68dbc2b6dd9",
   "metadata": {},
   "source": [
    "**Map of number of \"observed\" events**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d131a4-75fe-4077-ab65-318323f5e3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_events(stations, 'n_events_obs', yscale='log', save=f'{path_out}/map_observed_events_500km2_{stations.shape[0]}.jpg')\n",
    "map_events(stations.loc[stations_optimize], 'n_events_obs', yscale='log', alpha=1, save=f'{path_out}/map_observed_events_{suffix}.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfe35be-0f72-4afc-9952-123342d65c86",
   "metadata": {},
   "source": [
    "> ***Figure 2**. Number of observed flood events during the study period.*\n",
    "\n",
    "The geographical distribution of events is not even. There is a higher proportion of stations with events in Central Europe, British Isles and the Mediterranean catchments than in Estearn and North-Eastern Europe. During the study period there were major events in the Rhine, Meuse and Ebro, which can be seen in the map.\n",
    "\n",
    "The reporting points with more than 5 flood events during the study period were removed, since it is suspicious that the 5-year return period was exceeded so many times in only 2 years of study period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acbef3c-6231-44ad-8e33-c66e1b1a06e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2 Hits, misses and false alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe8d8f0-3f7f-4507-a2fd-41b66e80069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hits for each station\n",
    "hits_stn = xr.open_mfdataset(f'{path_in}*.nc', combine='nested', concat_dim='id')\n",
    "\n",
    "# extract selected stations\n",
    "stations = stations.loc[set(stations.index).intersection(hits_stn.id.data)]\n",
    "hits_stn = hits_stn.sel(id=stations.index.to_list()).compute()\n",
    "\n",
    "# convert to NaN lead times that can't be reached due to model limitations or persistence\n",
    "hits_stn = limit_leadtime(hits_stn)\n",
    "\n",
    "# subset of the 'hits' dataset with the stations selected for the optimization\n",
    "stations_optimize = list(set(stations_optimize).intersection(hits_stn.id.data))\n",
    "hits_opt = hits_stn.sel(id=stations_optimize).sum('id', skipna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed739ff-5e2e-4844-a038-7912f78cc25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hits for the benchmark\n",
    "hits_stn_current = xr.open_mfdataset('{0}*.nc'.format(path_in.replace('NWP', 'combination')), combine='nested', concat_dim='id')\n",
    "hits_stn_current = hits_stn_current.sel(current_criteria).compute()\n",
    "\n",
    "# convert to NaN lead times that can't be reached due to model limitations or persistence\n",
    "hits_stn_current = limit_leadtime(hits_stn_current)\n",
    "\n",
    "# subset of the 'hits' dataset with the stations selected for the optimization\n",
    "hits_opt_current = hits_stn_current.sel(id=stations_optimize).sum('id', skipna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d715613-88bb-45e2-a0f6-ec01c693ab7f",
   "metadata": {},
   "source": [
    "## 3 Analysis\n",
    "\n",
    "In this section I will compute the skill of the EFAS predictions in different ways. In all the following sections I will work with three metrics: $recall$, $precision$ and the $f_{beta}$ score. The three metrics are based in the contingency table of hits ($TP$ for true positives), false alarms ($FP$ for false positives) and misses ($FN$ for false negatives).\n",
    "\n",
    "$$recall = \\frac{TP}{TP + FN}$$\n",
    "$$precision = \\frac{TP}{TP + FP}$$\n",
    "$$f_{beta} = \\frac{(1 + \\beta^2) \\cdot TP}{(1 + \\beta^2) \\cdot TP + \\beta^2 \\cdot FN + FP}$$\n",
    "\n",
    "### 3.1 Skill computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313de1ab-db62-44ae-b02a-021b6c458628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skill by station\n",
    "skill_stn = hits2skill(hits_stn, beta=beta)\n",
    "\n",
    "# skill dataset for optimizing criteria\n",
    "skill_opt = hits2skill(hits_opt, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce8ea44-4b04-477c-827c-91cf3f9b1f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skill of the benchmark\n",
    "skill_opt_current = hits2skill(hits_opt_current, beta=beta)\n",
    "skill_opt_current = skill_opt_current.where(skill_opt_current != 0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fedc56-687d-4c20-a388-f40a1c2d6266",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = cm.get_cmap('Oranges', 128)\n",
    "bottom = cm.get_cmap('Blues_r', 128)\n",
    "newcolors = np.vstack((top(np.linspace(0.2, .95, 128)),\n",
    "                       bottom(np.linspace(.05, .8, 128))))\n",
    "OrBu = ListedColormap(newcolors, name='OrangeBlue')\n",
    "\n",
    "for pers in skill_opt.persistence.data:\n",
    "    file = '{0}{1}/skill_probability_leadtime_{2}.jpg'.format(path_out, metric, pers.replace('/', '-'))\n",
    "    plot_skill_by_probability(skill_opt, probability=np.round(np.arange(.05, .96, .05), 3), metric='f0.8', persistence=pers, coldim='model',\n",
    "                              benchmark=skill_opt_current, l=1, alpha=.5, ref_lt=60, ref_p=None, xlabel='leadtime (d)', cmap=OrBu, xlim=(0, 7),\n",
    "                              save=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2a9c56-b61d-491e-8636-6d75ea647edf",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ca18e4-09a2-4129-adb7-24e8cef527e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_skill_by_criteria(skill, linedim, fixdim, coldim='approach', ref_line=None, ref_lt=None, metric='f1', benchmark=None, save=None, **kwargs):\n",
    "    \"\"\"It generates a graph with as many line plots as approaches in the 'skill' dataset. The line plots reprensent the evolution of skill depending on the probability threshold\n",
    "    \n",
    "    Inputs:\n",
    "    -------\n",
    "    skill:              xr.Dataset (area, persistence, approach, probability). It contains as variables recall, precision and the specified metric\n",
    "    probability:        list or np.array. List of probability thresholds to be plotted\n",
    "    persistence:        str. Fixed value of persistence\n",
    "    coldim:             string. Name of the dimension that defines each of the plots in the graph\n",
    "    reference:          int of float. Fixed value of the 'variable' for which 'optimal_criteria' was fitted\n",
    "    metric:             string. Name of the target metric. This metric should be a variable in both datasets 'skill' and 'optmized_criteria'\n",
    "    current_criteria:   dict. It contains the current operation criteria used in EFAS {'approach', 'probability', 'persistence'}\n",
    "    save:               string. Path where the graph will be saved. By default is 'None', and the graph is not saved.\n",
    "    \n",
    "    Ouput:\n",
    "    ------\n",
    "    The graph is plotted on the screen, and saved if a path is set in the attribute 'save'\n",
    "    \"\"\"\n",
    "    \n",
    "    cmap = plt.get_cmap(kwargs.get('cmap', 'coolwarm_r'))\n",
    "    lw = kwargs.get('lw', 1.2)\n",
    "    alpha = kwargs.get('alpha', .666)\n",
    "    \n",
    "    ncols = len(skill[coldim])\n",
    "    fig, axes = plt.subplots(ncols=ncols, sharex=True, sharey=True, figsize=kwargs.get('figsize', (4.5 * ncols, 4)))\n",
    "    \n",
    "    if benchmark is not None:\n",
    "        df_bm = benchmark.to_pandas()\n",
    "        \n",
    "    linevalues = list(linedim.values())[0]\n",
    "    linedim = list(linedim)[0]\n",
    "    colors = ListedColormap(cmap(np.linspace(0, 1, len(linevalues)))).colors\n",
    "    for ax, key in zip(axes, skill[coldim].data):\n",
    "        if benchmark is not None:\n",
    "            ax.plot((df_bm.index - 12) / 24, df_bm[metric], c='k', lw=lw * 1.2, label='current', zorder=25)\n",
    "        \n",
    "        for v, c in zip(linevalues, colors):\n",
    "            criteria = {coldim: key, linedim: v}\n",
    "            criteria.update(fixdim)\n",
    "            df = skill.sel(criteria).to_pandas()\n",
    "            if v == ref_line:\n",
    "                ax.plot((df.index - 12) / 24, df['f0.8'], c='k', ls='--', lw=lw, alpha=1, zorder=24) #, label=f'P ‚â• {v:.2f}'\n",
    "            # elif p == .4:\n",
    "            #     ax.plot((df.index - 12) / 24, df['f0.8'], c='k', ls=':', lw=lw, alpha=1, label=f'P ‚â• {p:.2f}', zorder=24)\n",
    "            else:\n",
    "                ax.plot((df.index - 12) / 24, df['f0.8'], c=c, lw=lw, alpha=alpha)#, label=f'P ‚â• {v:.2f}')\n",
    "                \n",
    "        if ref_lt is not None:\n",
    "            ax.axvline((ref_lt - 12) / 24, c='k', ls='-', lw=lw / 2)\n",
    "        # ax.text(2, .999, 'start notifications', rotation=90, horizontalalignment='right', verticalalignment='top', fontsize=10)\n",
    "        # ax.axvline(5.5, c='k', ls=':', lw=lw / 2)\n",
    "        # ax.text(5.5, .999, 'end COSMO', rotation=90, horizontalalignment='right', verticalalignment='top', fontsize=10)\n",
    "        # ax.axvline(7, c='k', ls=':', lw=lw / 2)\n",
    "        # ax.text(7, .999, 'end DWD', rotation=90, horizontalalignment='right', verticalalignment='top', fontsize=10)\n",
    "        ax.set_xlabel(kwargs.get('xlabel', 'lead time ‚â• (d)'))\n",
    "        if ax == axes[0]:\n",
    "            ax.set_ylabel(f'{metric} (-)')\n",
    "        ax.set_title(key.replace('_', ' '))\n",
    "        \n",
    "    ax.set(xlim=kwargs.get('xlim', (0, 9)), ylim=kwargs.get('ylim', (-.02, 1.02)))\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, ncol=5, bbox_to_anchor=kwargs.get('loc_legend', [.14, -.1, .6, .08]), frameon=False);\n",
    "\n",
    "    if save is not None:\n",
    "        plt.savefig(save, dpi=300, bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25d299c-8272-4268-a180-c79bd2a1113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "linedim = {'persistence': ['1/1', '2/2', '3/3']}\n",
    "fixdim = {'probability': 0.5}\n",
    "plot_skill_by_criteria(skill_opt, linedim, fixdim, coldim='model', metric='f0.8',\n",
    "                          benchmark=None, l=1, alpha=1, ref_lt=60, ref_p=None, xlabel='leadtime (d)', cmap=OrBu, #xlim=(0, 7),\n",
    "                          save=None)#f'{path_out}{metric}/skill_probability_leadtime.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43a4944-bdd2-4884-b15e-03683f19d166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_skill_by_persistence(skill, xdim='probability', coldim='approach', linedim='persistence', metric='f1',\n",
    "                              benchmark=None, save=None, **kwargs):\n",
    "    \"\"\"It generates a graph with as many line plots as approaches in the 'skill' dataset. The line plots reprensent the evolution of skill depending on persistence\n",
    "    \n",
    "    Inputs:\n",
    "    -------\n",
    "    skill:              xr.Dataset (area, persistence, approach, probability). It contains as variables recall, precision and the specified metric\n",
    "    probability:        list or np.array. List of probability thresholds to be plotted\n",
    "    coldim:             string. Name of the dimension that defines each of the plots in the graph\n",
    "    reference:          int of float. Fixed value of the 'variable' for which 'optimal_criteria' was fitted\n",
    "    metric:             string. Name of the target metric. This metric should be a variable in both datasets 'skill' and 'optmized_criteria'\n",
    "    current_criteria:   dict. It contains the current operation criteria used in EFAS {'approach', 'probability', 'persistence'}\n",
    "    save:               string. Path where the graph will be saved. By default is 'None', and the graph is not saved.\n",
    "    \n",
    "    Ouput:\n",
    "    ------\n",
    "    The graph is plotted on the screen, and saved if a path is set in the attribute 'save'\n",
    "    \"\"\"\n",
    "    \n",
    "    lw = kwargs.get('lw', 1.2)\n",
    "    alpha = kwargs.get('alpha', .666)\n",
    "    cmap = plt.get_cmap(kwargs.get('cmap', 'coolwarm'))\n",
    "    colors = ListedColormap(cmap(np.linspace(0, 1, len(skill[linedim])))).colors\n",
    "\n",
    "    ncols = len(skill_opt[coldim])\n",
    "    fig, axes = plt.subplots(ncols=ncols, figsize=(4.5 * ncols, 4), sharex=True, sharey=True)\n",
    "\n",
    "    for ax, col in zip(axes, skill[coldim].data):\n",
    "\n",
    "        da = skill[metric].sel({coldim: col})\n",
    "        \n",
    "        if benchmark is not None:\n",
    "            # ax.axvline(current_criteria[xdim], lw=lw / 2, c='k', zorder=0)\n",
    "            ax.scatter(benchmark[xdim], benchmark[metric].data, marker='x', lw=lw, c='k', zorder=20, label='current')\n",
    "        for line, color in zip(da[linedim].data, colors):\n",
    "            serie = da.sel({linedim: line}).to_pandas()\n",
    "            ax.plot(serie.index, serie, c=color, lw=lw, alpha=alpha, label=line)\n",
    "\n",
    "        ax.set_xlabel(xdim)\n",
    "        if ax == axes[0]:\n",
    "            ax.set_ylabel(f'{metric} (-)')\n",
    "        ax.set_title(col.replace('_', ' '))\n",
    "\n",
    "    ax.set(xlim=(skill[xdim].min(), skill[xdim].max()), ylim=(-.02, 1.02))\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, bbox_to_anchor=kwargs.get('loc_legend', [.78, .62, .2, .3]), frameon=False);\n",
    "\n",
    "    if save is not None:\n",
    "        plt.savefig(save, dpi=300, bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ab1776-3096-4336-9cc5-e20488a0b9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = skill_opt_current.sel(leadtime=lt)\n",
    "\n",
    "benchmark.probability.data, benchmark[metric].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554e3c2e-87b6-40dd-92b9-7cdf31bbfaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = cm.get_cmap('Oranges_r', 128)\n",
    "bottom = cm.get_cmap('Blues', 128)\n",
    "newcolors = np.vstack((top(np.linspace(0.2, .95, 128)),\n",
    "                       bottom(np.linspace(.05, .8, 128))))\n",
    "OrBu = ListedColormap(newcolors, name='OrangeBlue')\n",
    "\n",
    "for lt in skill_opt.leadtime.data:\n",
    "    plot_skill_by_persistence(skill_opt.sel(leadtime=lt), coldim='model', metric='f0.8', benchmark=skill_opt_current.sel(leadtime=lt), cmap=OrBu,\n",
    "                              save=f'{path_out}{metric}/skill_persistence_probability_{lt:03}h.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ee4a6a-7212-4341-85e1-4e147616bd27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bff8f899-117f-4b96-a279-ed7bb3eddf3d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4720dfcf-35b2-4556-b608-fca8fecfb41a",
   "metadata": {},
   "source": [
    "### 3.2 Analyse overall performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07a4d0f-75f2-4943-b784-f16d35eaf3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to simplify the plot, they will show only the following values of persistence and leadtime\n",
    "persistences = ['1/1']#, '2/2', '3/3']\n",
    "if min_leadtime is None:\n",
    "    leadtimes = skill_opt.leadtime.data # [12, 36, 60, 84]#, 108, 132]\n",
    "    min_leadtime = 60\n",
    "else:\n",
    "    if isinstance(min_leadtime, int):\n",
    "        leadtimes = [min_leadtime]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b47926-3aee-48e1-b96d-faca228d5cb9",
   "metadata": {},
   "source": [
    "#### 3.2.1 Hits, misses and false alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d654d55-e7eb-4f8a-86db-fe05ed344d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lineplot_hits(hits_opt.sel(persistence=persistences, leadtime=leadtimes),\n",
    "              coldim='leadtime', rowdim='persistence', linedim='model',\n",
    "              ylim=(-.05, 2.05), xticks=hits_opt.probability.data[2::8],\n",
    "              loc_legend=[0.15, -.04, .5, .1],\n",
    "              save=f'{path_out}{metric}/hits_lineplot_persistenceVSleadtimeVSprobability_{suffix}.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c3c298-6237-41e6-9115-242f3a00fb97",
   "metadata": {},
   "source": [
    "> ***Figure 3**. Evolution of hits, misses and false alarms depending on probability (X axis), persistence (rows), and lead time (columns). The Y axis is normalized by the number of observed events. The black, horizonal line, which represents the number of observed events, is the reference. Blue lines represent the hits (TP) for each of the approaches to combine the meteorological forecasts; the difference between the reference line and these blue lines are the misses (events that were not forecasted). Red lines represent the total number of prediced events; therefore, the difference between them and the blue lines are the false alarms (wrongly predicted events). The vertical, dashed line indicates the probability threshold that maximizes skill, including the skill value.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36f8ccb-73b7-4140-bf55-76218b1cc0cb",
   "metadata": {},
   "source": [
    "The first outcome of this plot is that no matter the combination of criteria, we cannot predict all the observed events. Even for the shortest leadtime, lowest probability threshold and most relaxed persistency, the hit rate ($\\frac{hits}{obs}$) is around 0.80. However, to achieve this hit rate value, the false hit rate ($\\frac{pred-hits}{obs}$) is dramatically large. In fact, since our target skill metric is $f_{beta}$, we want to optimize a combination of those two rates; the result is that we need to allow for a lower hit rate in order not to minimize the amount of false alarms.\n",
    "\n",
    "If we analyse the evolution regarding thre three variables (lead time, persistence and probability), we get the following conclusions:\n",
    "\n",
    "* **Lead time**. As expected, skill improves with shorter leadtimes, as the uncertainty in the prediction dicreases.\n",
    "\n",
    "* **Persistence**. There is a clear tendency to overpredict especially for lower probability thresholds, where the total amount of prediced events go well beyond the number of observed events. The main role of persistency is to limit this overprediction.\n",
    "\n",
    "* **Probability**. It plays a similar role as persistence. By increasing the probability threshold we reduce the number of false alarms. The optimal value of probability is the one that comprimises correctly the number of hits, misses and false alarms. Since probability and persistence play a similar role, there is a trade-off between those two variables. Whenever persistence is more relaxed (or non-existen), the probability threshold is higher; and viceversa. For a fixed persistence, the optimal probability threshold is higher for shorter lead times; since the uncertainty on the prediction is lower, the probability threshold can be higher.\n",
    "\n",
    "* **Approach**. The hit rate is fairly similar regarless of the method used to combine the meteorological forcings. On the contray, the false hit rate is very sensitive to the approach, especially with more relaxed persistence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f414e7f-bc55-4bb0-85db-eafb7ff93c49",
   "metadata": {},
   "source": [
    "#### 3.2.2 Skill: recall, precision and fbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1c7e17-b7d0-4888-b26c-0829517f1eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "lineplot_skill(skill_opt.sel(persistence=persistences, leadtime=leadtimes),\n",
    "               metric=metric, coldim='leadtime', linedim='model',\n",
    "               xticks=skill_opt.probability.data[2::8],\n",
    "               save=f'{path_out}{metric}/skill_lineplot_persistenceVSleadtimeVSprobability_{suffix}.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad6c3c7-c21d-45c0-971b-b7d5e43d5bf7",
   "metadata": {},
   "source": [
    "> ***Figure 4**. Evolution of skill depending on probability (X axis), persistence (rows), and lead time (columns). Black lines represents the the target skill metric for each of the approaches to combine the meteorological forecasts, which is a combination of recall (blue lines) and precision (red lines). The dotted lines represent the optimal probability threshold and the associated value of the target metric.*\n",
    "\n",
    "The plot shows the well known interplay between recall and precision. In this case, recall is high for small probability thresholds; when this threshold is low, the system produces more notifications and the number of misses reduces. On the other hand, precision is high for large probability thresholds; notifications are sent only when the certainty of the event is high, so the number of false alarms is minimum.\n",
    "\n",
    "The target metric is a combination of both recall and precision. For that metric, we look for the optimal probability threshold. Fortunately, in the majority of plots we see that the target metric (black lines) has a convex curve, so it is possible to find the optimal value. Only for very short lead time and more relaxed persitence the target metric has a continuously increasing behaviour.\n",
    "\n",
    "The conclusions regarding each of the four variables are similar as before:\n",
    "\n",
    "* **Lead time**. Skill increases with lead time. As said before, lead time also influences the optimal probability threshold, with larger values for shorter lead times.\n",
    "\n",
    "* **Persistence**. Skill reduces with persistence. It also affects the optimal probability threshold, with higher values for more relaxed persistence.\n",
    "\n",
    "* **Probability**. As explained before, in most of the combinations of persistence and leadtime the target skill metric shows a convex behaviour in relation with probability. \n",
    "\n",
    "* **Approach**. The difference among the approaches is noticeable only when persistence is relaxed. For instance, for no persistence (persistence 1/1), the _model mean_ behaves clearly different from the other approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dcf30b-e803-47e5-968d-ddf4e6d7d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skill for a fixed lead time\n",
    "for lt in leadtimes:\n",
    "    lineplot_skill(skill_opt.sel(persistence=persistences, leadtime=lt).dropna('model', how='all'),\n",
    "                   metric=metric, coldim=None, linedim='model',\n",
    "                   xticks=skill_opt.probability.data[2::8], linewidth=1.2, alpha=1,\n",
    "                   loc_legend=[1.125, .79, .2, .1], color={'COS': 'steelblue', 'DWD': 'lightsteelblue', 'EUD': 'C1', 'EUE': 'navajowhite'},\n",
    "                   save=f'{path_out}{metric}/skill_lineplot_persistenceVSprobability_{suffix}_{lt:03}h.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a1c31e-1a67-4f49-b6c6-41772a3fca62",
   "metadata": {},
   "source": [
    "> ***Figure 5**. Evolution of skill depending on probability (X axis) and persistence (rows). Each column represents a skill metric. In each plot the solid lines represent the approaches to combine the meteorological forcings. The dotted lines represent probability threshold optimized for the target skill metric and the associated value of the metric.*\n",
    "\n",
    "This plot is similar to the previous, but now the lead time is fixed to 60 h (more than 2 days as it is the current procedure). Each of the skill metrics is represented in a different column and the approaches are distinct by the line colours.\n",
    "\n",
    "* Regardless of the set of criteria (persistence, probability and approach), the maximum values of the target metric are in the order of 0.50. This means that the selection of the optimal set of criteria purely on the skill value would be very uncertain.\n",
    "\n",
    "* In general, the highest skill is achieved with no persistence, except for the _model mean_ approach, which has a clearly distinct behaviour. As already mentioned, the stronger the persistence, the more similar the results among approaches.\n",
    "\n",
    "* The values of precision for the optimal probability threshold are consistently higher than those of recall, as it could be expected since the target metric is $f_{0.8}$, which gives a higher importance to precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cf32c8-5990-4543-958a-9e6ad32967b8",
   "metadata": {},
   "source": [
    "#### 3.2.3 Optimize criteria\n",
    "\n",
    "In this section we will derive a optimal set of notification criteria based on the target skill metric. To avoid overfitting, the sample of reporting points is first divided in a training and a test subset. This division is done in a stratified way after randomly shuflling the points, to keep the proportion of observed events in the subsets and avoid geographic biases, respectively.\n",
    "\n",
    "To increase the robustness of the optimization, cross-validation is applied if the parameter `kfold` is set in the configuration file. In that case, `kfold` subsets of stations are generated, again in a stratified and random manner. The average skill over the subsets will be the data used to find the optimal criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a7ab8b-b466-4ce6-b3ad-6fc6597db86a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 2\n",
    "\n",
    "# divide stations in train and test samples\n",
    "X = stations_optimize\n",
    "y = stations.loc[X, 'n_events_obs']\n",
    "if stratify:\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, train_size=train_size, random_state=seed, shuffle=True, stratify=y)\n",
    "else:\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, train_size=train_size, random_state=seed, shuffle=True)\n",
    "\n",
    "best_criteria = {}\n",
    "best_model = {}\n",
    "for leadtime in hits_stn.leadtime.data:\n",
    "    \n",
    "    print(f'leadtime: {leadtime:>3} h')\n",
    "    print('---------------\\n')\n",
    "    \n",
    "    # subset of the 'hits' dataset for the training and test sets\n",
    "    hits_train = hits_stn.sel(id=Xtrain, leadtime=leadtime)\n",
    "    hits_test = hits_stn.sel(id=Xtest, leadtime=leadtime)\n",
    "\n",
    "    # optimize the notification criteria\n",
    "    if kfold is not None: # apply a cross-validation approach\n",
    "        skill_train, best_criteria_lt = find_best_criteria_cv(hits_train,\n",
    "                                                           stations.loc[Xtrain, 'n_events_obs'],\n",
    "                                                           dims=list(min_spread),\n",
    "                                                           kfold=kfold, train_size=train_size, random_state=seed, stratify=stratify,\n",
    "                                                           beta=beta, tolerance=tolerance, min_spread=list(min_spread.values()))\n",
    "    else:\n",
    "        # skill of the training sample\n",
    "        skill_train = hits2skill(hits_train.sum('id', skipna=True), beta=beta)\n",
    "        # best criteria for each approach\n",
    "        best_criteria_lt = find_best_criteria(skill_train, dims=list(min_spread),\n",
    "                                           metric=metric, tolerance=tolerance, min_spread=list(min_spread.values()))\n",
    "\n",
    "    # extract criteria as a dictionary\n",
    "    dims = [var for var in best_criteria_lt if var not in ['recall', 'precision', metric]]\n",
    "    best_criteria_lt = {model: {dim: best_criteria_lt.sel(model=model)[dim].data for dim in dims} for model in best_criteria_lt.model.data}\n",
    "    for model in best_criteria_lt:\n",
    "        best_criteria_lt[model]['model'] = model\n",
    "    best_criteria[leadtime] = best_criteria_lt\n",
    "\n",
    "    # skill of the train set for the optimized criteria\n",
    "    skill_train = dict2da({model: skill_train.sel(sel) for model, sel in best_criteria_lt.items()}, dim='model')\n",
    "\n",
    "\n",
    "    # skill of the test set for the optimized criteria\n",
    "    skill_test = hits2skill(hits_test.sum('id', skipna=True), beta=beta)\n",
    "    skill_test = dict2da({model: skill_test.sel(sel) for model, sel in best_criteria_lt.items()}, dim='model')\n",
    "\n",
    "    # performance of the complete set of stations\n",
    "    skill_all = dict2da({model: skill_opt.sel(leadtime=leadtime).sel(sel) for model, sel in best_criteria_lt.items()}, dim='model')\n",
    "\n",
    "    # plot results of the optimization\n",
    "    plot_skill_training(skill_train, skill_test, skill_all, ylim=(-0.05, 1.05), xdim='model',\n",
    "                        save=f'{path_out}{metric}/skill_training_{suffix}_{leadtime:03}h.jpg')\n",
    "\n",
    "    # print on screen results\n",
    "    for model, dct in best_criteria_lt.items():\n",
    "        print(model.replace('_', ' '))\n",
    "        print('.' * len(model))\n",
    "        for label, value in dct.items():\n",
    "            if label == 'model':\n",
    "                continue\n",
    "            print(f'{label}:\\t{value}')\n",
    "        print('{0}(train|test):\\t{1:.3f}|{2:.3f}\\n'.format(metric,\n",
    "                                                         skill_train.sel(model=model).median()[metric].data,\n",
    "                                                         skill_test.sel(model=model).median()[metric].data))\n",
    "\n",
    "    # model with the highest skill\n",
    "    best_model[leadtime] = str(skill_test[metric].idxmax('model').data)\n",
    "\n",
    "# export best criteria\n",
    "file = f'{path_out}{metric}/optimized_criteria_{suffix}.pkl'\n",
    "with open(file, 'wb') as f:\n",
    "    pickle.dump(best_criteria, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e203b81-e92e-4ac4-8eae-a0a55717a36b",
   "metadata": {},
   "source": [
    "> ***Figure 6**. Skill resulting of the otpimization process for each of the methods used to combine the meteorological forcings: 1D+1P, one deterministic and 1 probabilistic; MM, model mean; MW, member weighted; BW, Brier weihted; C, current operational criteria. If cross-validation was applied, the boxplots show the variance in the skill among the kfolds; if not, the black dots represent the skill of the training set. In either case, the orange dot represent the skill of the test set and the blue dots that of the complete set of reporting points.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d053bb3d-2408-4d00-b706-00180448de49",
   "metadata": {},
   "source": [
    "According to the performance on the test set (orange dots), **the optimal criteria is the one that uses the _member weighted_ approach with no persistence and a probability threshold of 40%**. However, for the training set the highest-performing approach was _1 deterministic and 1 probabilistic_, but this approach seems to suffer from overfitting, since it is the second lowest-performing in the test set.\n",
    "\n",
    "Since the target metric benefits precision over recall, the precision values are higher than those of recall. This difference is enhanced for the _member weighted_ (the best-performing) and the _current_ criteria.\n",
    "\n",
    "Persistence is not necessary in two out of four approaches: _1 deterministic and 1 probabilistic_, _member weighted_. The other two approaches have an optimized persistence of $4/4$.</font>\n",
    "\n",
    "In general, the optimized criteria, regarless of the approach, outperform the current operational criteria. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b371fb-3ae7-44f3-8f21-4fca4383fad6",
   "metadata": {},
   "source": [
    "### 3.3 Analyse skill by reporting points\n",
    "\n",
    "Once we have optimized the notification criteria for each approach, we will have a look to the distribution of the hits/misses/false alarms and the skill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c67621c-ed43-49ca-88f3-727f6b546472",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define colormap for the skill metrics\n",
    "top = cm.get_cmap('Oranges_r', 128)\n",
    "bottom = cm.get_cmap('Blues', 128)\n",
    "newcolors = np.vstack((top(np.linspace(0.2, .8, 128)),\n",
    "                       bottom(np.linspace(0.2, .8, 128))))\n",
    "OrBu = ListedColormap(newcolors, name='OrangeBlue')\n",
    "cmap_f1, norm_f1 = create_cmap(OrBu, np.arange(0, 1.01, 0.05), name='skill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821b3550-b808-4ecb-91e0-dd37d2daa30f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# map hits/misses/false alarmas and performance for each of the total probability approaches\n",
    "s = 2\n",
    "alpha = .5\n",
    "for leadtime in leadtimes:\n",
    "    for key, criteria in best_criteria[leadtime].items():\n",
    "\n",
    "        title = '{0}\\nprobability = {1}\\npersistence = {2}'.format(key.replace('_', ' '), criteria['probability'], criteria['persistence'])\n",
    "\n",
    "        # extract TP, FN, FP for this approach\n",
    "        hits_stn_best = hits_stn.sel(leadtime=leadtime).sel(criteria)\n",
    "        for var, da in hits_stn_best.items():\n",
    "            stations[var] = da.to_pandas()\n",
    "\n",
    "        # plot maps of TP, FN, FP\n",
    "        map_hits(stations.loc[stations_optimize], cols=['TP', 'FN', 'FP'], mask=stations_w_events, s=s, alpha=alpha,\n",
    "                 title=title,\n",
    "                 save=f'{path_out}{metric}/hits_maps_reporting_points_{suffix}_{key}_{leadtime:03}h.jpg')\n",
    "\n",
    "        # compute metrics\n",
    "        stations['recall'] = stations.TP / (stations.TP + stations.FN)\n",
    "        stations['precision'] = stations.TP / (stations.TP + stations.FP)\n",
    "        stations[metric] = (1 +  beta**2) * stations.TP / ((1 +  beta**2) * stations.TP + beta**2 * stations.FN + stations.FP)\n",
    "\n",
    "        # plot maps of performance\n",
    "        map_skill(stations.loc[stations_optimize], cols=['recall', 'precision', metric], bins=50, cmap=cmap_f1, norm=norm_f1,\n",
    "                  s=s, alpha=alpha,\n",
    "                  title=title,\n",
    "                  save=f'{path_out}{metric}/skill_maps_reporting_points_{suffix}_{key}_{leadtime:03}h.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfec845-0646-4e38-913e-a636101fa0cc",
   "metadata": {},
   "source": [
    "> ***Figure 7**. Maps of hits, misses and false alarms for the criteria otimized for each approach. The colour scale changes depending on the variable; orange (darker orange) means worse values, whereas blue (darker blue) better values. In the case of hits (TP) and misses (FN) a mask has been applied to remove reporting points with no observed events (gray points), since none of these variables can be computed if there are no observations to predict or miss. The histograms at the bottom show the distributions of hits, misses and false alarms over the whole domain.*\n",
    "\n",
    "> ***Figure 8**. Maps of skill for the criteria otimized for each approach. Orange values represent poor skill, whereas blue values high skill; gray dots represent points for which the metric can not be computed. The histograms at the bottom show the distribution of skill over the whole domain.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d4eb7c-378e-450a-8733-6da40108f9b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hits_stn_best = hits_stn.sel(leadtime=min_leadtime).sel(best_criteria[min_leadtime][best_model[min_leadtime]])\n",
    "for var, da in hits_stn_best.items():\n",
    "    stations[var] = da.to_pandas()\n",
    "stations['recall'] = stations.TP / (stations.TP + stations.FN)\n",
    "stations['precision'] = stations.TP / (stations.TP + stations.FP)\n",
    "stations[metric] = (1 +  beta**2) * stations.TP / ((1 +  beta**2) * stations.TP + beta**2 * stations.FN + stations.FP)\n",
    "\n",
    "# export station including skill\n",
    "stations.to_parquet('{0}{1}/{2}'.format(path_out, metric, file_stations.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524b3971-9fe8-4ffd-bbf2-d96454e27329",
   "metadata": {},
   "source": [
    "### 3.4 Analyse skill by catchment area\n",
    "\n",
    "So far we have analyzed only stations with a catchment area larger or equal than a fixed value (2000 km¬≤). Also, in the optimization of the notification criteria this minimum catchment area was fixed.\n",
    "\n",
    "In this section we will analyze how results change according to the catchment area. First, we will see the evolution of skill over catchment area for the notification criteria optimized for a minimum catchment area. Later, we will derive a new optimization criteria in which the probability threshold varies according to catchment area. This derivation is repeated for every approach, and the persistence criterion is fixed for each approach to the value optimized in the previous sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efd4c9a-d394-400d-954f-9c6a1a346d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an array of catchment area thresholds\n",
    "area_max = np.ceil(stations.area.max() / 500) * 500\n",
    "areas = define_area_ranges(500, area_max, scale='semilog')\n",
    "\n",
    "# no. stations and events by catchment area threshold\n",
    "stations_area = summarize_by_area(stations.area, stations.n_events_obs, areas)\n",
    "\n",
    "# hits and skill by catchment area\n",
    "hits_area = hits_by_area(hits_stn.sel(leadtime=leadtimes), stations.area, areas)\n",
    "skill_area = hits2skill(hits_area, beta=beta)\n",
    "skill_area = skill_area.dropna('area', how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36505b5c-8664-4266-9d6c-9869273dc9a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criteria_area = {}\n",
    "for area in tqdm_notebook(areas):\n",
    "        \n",
    "    # divide stations in train and test samples\n",
    "    X = stations.loc[stations.area >= area].index\n",
    "    if len(X) == 0:\n",
    "        break\n",
    "    y = stations.loc[X, 'n_events_obs']\n",
    "    if stratify:\n",
    "        Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, train_size=train_size, random_state=seed, shuffle=True, stratify=y)\n",
    "    else:\n",
    "        Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, train_size=train_size, random_state=seed, shuffle=True)\n",
    "\n",
    "    # subset of the 'hits' dataset for the training and test sets\n",
    "    hits_train = hits_stn.sel(id=Xtrain, leadtime=leadtimes)\n",
    "\n",
    "    # optimize the notification criteria\n",
    "    try:\n",
    "        if kfold is not None: # apply a cross-validation approach\n",
    "            skill_train, criteria = find_best_criteria_cv(hits_train,\n",
    "                                                          stations.loc[Xtrain, 'n_events_obs'],\n",
    "                                                          dims='probability',\n",
    "                                                          kfold=kfold, train_size=train_size, random_state=seed, stratify=stratify,\n",
    "                                                          beta=beta, tolerance=tolerance, min_spread=min_spread['probability'])\n",
    "        else:\n",
    "            # skill of the training sample\n",
    "            skill_train = hits2skill(hits_train.sum('id', skipna=True), beta=beta)\n",
    "            # best criteria for each approach\n",
    "            criteria = find_best_criteria(skill_train, dims='probability',\n",
    "                                          metric=metric, tolerance=tolerance, min_spread=min_spread['probability'])\n",
    "\n",
    "        criteria_area[area] = criteria['probability']\n",
    "            \n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "criteria_area = dict2da(criteria_area, dim='area')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3d66d1-01ec-4ebb-a665-d83dd07bcf41",
   "metadata": {},
   "source": [
    "#### 3.4.1 Stations and events according to catchment area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0767b6d-e939-416a-9eae-8cf00ccc5d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 3\n",
    "lw = 1\n",
    "alpha = .8\n",
    "c1 = 'orange'\n",
    "c2 = 'steelblue'\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(4, 4))\n",
    "\n",
    "ax1.plot(stations_area.index, stations_area.n_stations, alpha=alpha, c=c1, lw=lw, zorder=2)\n",
    "ax1.set_xlabel('area ‚â• (km¬≤)')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_ylabel('no. reporting points', c=c1)\n",
    "ymin1, ymax1 = 0, 3000\n",
    "yticks = np.linspace(ymin1, ymax1, 6).astype(int)\n",
    "ax1.set_yticks(yticks)\n",
    "ax1.set_yticklabels(yticks, c=c1)\n",
    "ax1.set_ylim(ymin1 - ymax1 * .02, ymax1 * 1.02)\n",
    "\n",
    "ax1.axvline(x=min_area, ls=':', lw=.5, color='k', zorder=0)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(stations_area.index, stations_area.n_events_obs, alpha=alpha, c=c2, lw=lw, zorder=1)\n",
    "ax2.set_ylabel('no. observed events', c=c2)\n",
    "ymin2, ymax2 = 0, 1500\n",
    "yticks = np.linspace(ymin2, ymax2, 6).astype(int)\n",
    "ax2.set_yticks(yticks)\n",
    "ax2.set_yticklabels(yticks, c=c2)\n",
    "ax2.set(xlim=(500, area_max), ylim=(ymin2 - ymax2 * .02, ymax2 * 1.02));\n",
    "\n",
    "plt.savefig(f'{path_out}points_observedEvents_vs_area_{suffix}.jpg', dpi=300, bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afbd985-db94-47fb-b32b-61e8c8af1c00",
   "metadata": {},
   "source": [
    "> ***Figure 9**. Number of reporting points (orange) and observed events (blue) by catchment area.*\n",
    "\n",
    "The plot represents both the number of reporting points and the number of observed events over a increasing catchment area threshold. Note that the X axis is in logarithmic scale, and that the primary Y axis (reporting points) has a scale double than the secondary Y axis (events).\n",
    "\n",
    "There is a clear 2:1 relation between the number of reporting points and the number of observed events. Both variables dicrease exponentially with catchment area. However, for small catchments (lower than 2000 km¬≤ approx.) the 2:1 relation disappears; the number of events increases faster than that of reporting points with dicreasing area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ec66fe-8b40-49d0-9246-e7f9455db3e6",
   "metadata": {},
   "source": [
    "#### 3.4.2 Current vs optimized criteria\n",
    "\n",
    "**Hits, misses and false alarms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8d1a09-593e-46aa-9427-095cead404ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lt in leadtimes:\n",
    "    plot_hits_by_variable(hits_area.sel(leadtime=lt), optimal_criteria=best_criteria[lt], variable='area', coldim='model',\n",
    "                          reference=min_area, current_criteria=best_criteria[lt]['EUE'],\n",
    "                          xscale='log', xlabel='area ‚â• (km¬≤)', xlim=(criteria_area.area.min(), criteria_area.area.max()),\n",
    "                          loc_legend=[.87, .8, .2, .1],\n",
    "                          save=f'{path_out}{metric}/hits_vs_area_{suffix}_{lt:03}h.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5497b79-6c29-42d0-9606-f4a2f573a380",
   "metadata": {},
   "source": [
    "> ***Figure 10**. Evolution of hits, misses and false alarms with catchment area threshold. Each plot represents a different approach to combine the meteorological forcings. The primary Y axis is normalized by the number of observed events to allow for comparison; the secondary Y axis indicates the probability threshold. The continuous lines are the hits, whereas the shadows are the false alarms; the difference between the reference line ($\\frac{x}{obs}=1$) and the hits are the misses. The dotted lines are the probability thresholds. Black objects represent the current operational criteria and blue ones the criteria optimized for a fixed area threshold (represented by a vertical, solid, black line).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2822e2b9-7b20-48d8-97c0-7c915edeec68",
   "metadata": {},
   "source": [
    "**Skill**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25157721-720f-4b76-b7f4-ead62986bc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lt in leadtimes:\n",
    "    plot_skill_by_variable(skill_area.sel(leadtime=lt), optimal_criteria=best_criteria[lt], variable='area', coldim='model',\n",
    "                           reference=min_area, metric=metric, current_criteria=best_criteria[lt]['EUE'],\n",
    "                           xscale='log', xlabel='area ‚â• (km¬≤)', loc_text=3, loc_legend=[.87, .8, .2, .1],\n",
    "                           save=f'{path_out}{metric}/skill_vs_area_{suffix}_{lt:03}h.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a44ed8c-552b-48c3-810c-1d42050d5b15",
   "metadata": {},
   "source": [
    "> ***Figure 11**. Evolution of skill with catchment area threshold. Each plot represents a different approach in which the meteorological forcings are combined. The primary Y axis indicates skill, and the secondary Y axis indicates the probability threshold. The continuous lines are the target skill score ($f_{0.8}$), and the shadows represent the difference between $precision$ and $recall$. The dotted lines are the probability thresholds. Black objects represent the current operational criteria and blue ones the criteria optimized for a fixed area threshold (represented by the vertical, solid, black line).*\n",
    "\n",
    "This figure shows both the change in the notification criteria (probability and persistence) and the effects on the skill. \n",
    "\n",
    "In general, the nofitication criteria have shifted towards higher probability thresholds (dotted, blue line), and no persistence. This is the case for all approaches but _model mean_, for which a persistence of $4/4$ and a low probability threshold were the optimal criteria. As explained before, there is a trade-off between persistence and probability, which is seen in this figure; higher probability thresholds require less strict persistence and viceversa.\n",
    "\n",
    "The skill of the system, measured in terms of $f_{0.8}$, improves with catchment area, as it was expected. Very large catchment areas have a skill close to 1. However, the curves are not continuously increasing; in the area range from 30,000 to 70,000 km¬≤ there is a loss of skill that must be analyzed. When moving towards smaller catchments, the loss in skill is not dramatic, which means that the catchment threshold could be lowered.\n",
    "\n",
    "The spread between $precision$ and $recall$ is in general lower with the optimized criteria. Figure 6 showed that the current operational criteria have a much higher $precision$ than $recall$, which is shown here with the wide gray shade. This spread in the current criteria increases towards smaller catchment areas and slightly dicreases toward larger areas. With the optimized criteria the behaviour changes significantly. In general, the spread is low for the fixed area threshold (2000 km¬≤), and it increases towards both sides, larger and smaller areas. Only the _member weighted_ approach, the highest-performing, has a different behaviour, very similar to the current operation criteria.\n",
    "\n",
    "The vertical line at 2000 km¬≤ shows the changes achieved with the optimization (this is the minimum catchment area fixed in the optimizatin). The skill improves for every approach, both in terms of $f_{0.8}$ and the spread between $precision$ and $recall$. The improvement in skill seen at 2000 km¬≤ expands throughout the catchment area values, with enhanced skill for larger catchment areas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552798d2-952c-4d39-9652-a561caaa2f2c",
   "metadata": {},
   "source": [
    "#### 3.4.3 Fixed criteria vs area optimized criteria\n",
    "\n",
    "In the previous section we have analyzed how the skill of the system varies over catchment area for a fixed value of the probability threshold. But, what if we tune the probability threshold according to catchment area? Would it improved the skill of the system?\n",
    "\n",
    "**Hits, misses and false alarms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3942f9-93d4-4bd8-a672-ea0c173537c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lt in leadtimes:\n",
    "    plot_hits_by_variable(hits_area.sel(leadtime=lt), optimal_criteria=best_criteria[lt], variable='area', coldim='model',\n",
    "                          reference=min_area, optimized_criteria=criteria_area.sel(leadtime=lt),\n",
    "                          xscale='log', xlabel='area ‚â• (km¬≤)', xlim=(criteria_area.area.min(), criteria_area.area.max()),\n",
    "                          loc_text=1, loc_legend=[.9, .8, .2, .1],\n",
    "                          save=f'{path_out}{metric}/hits_vs_area_varying_probability_{suffix}_{lt:03}h.jpg', )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dc1999-a808-490d-8743-e83847422e50",
   "metadata": {},
   "source": [
    "> ***Figure 12**. Evolution of hits, misses and false alarms with catchment area threshold. Each plot represents a different approach to combine the meteorological forcings. The primary Y axis is normalized by the number of observed events to allow for comparison; the secondary Y axis indicates the probability threshold. The continuous lines are the hits, the shadows are the false alarms, and the difference between the reference line ($\\frac{x}{obs}=1$) and the hits are the misses. The dotted lines show the probability threshold. Blue objects are the results for the criteria optimized for a fixed area threshold (represented by a vertical, solid, black line), and orange objects those for the criteria optimized for every area threshold.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c5db3-1bd8-47ce-9c8e-ef8c550c4fa3",
   "metadata": {},
   "source": [
    "**Skill**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5945c714-52cf-4b88-b0c1-057f2e5ca2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lt in leadtimes:\n",
    "    plot_skill_by_variable(skill_area.sel(leadtime=lt), optimal_criteria=best_criteria[lt], variable='area', coldim='model',\n",
    "                           reference=min_area, metric=metric, optimized_criteria=criteria_area.sel(leadtime=lt),\n",
    "                           xscale='log', xlabel='area ‚â• (km¬≤)', loc_text=2, loc_legend=[.9, .8, .2, .1],\n",
    "                           save=f'{path_out}{metric}/skill_vs_area_varying_probability_{suffix}_{lt:03}h.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d530bbb-bbf4-4203-b8c3-bedde8aabf54",
   "metadata": {},
   "source": [
    "> ***Figure 13**. Evolution of skill with catchment area threshold. Each plot represents a different approach in which the meteorological forcings are combined. The primary Y axis indicates skill, and the secondary Y axis indicates the probability threshold. The continuous lines are the target skill score ($f_{0.8}$), and the shadows represent the difference between $precision$ and $recall$. The dotted lines show the probability threshold. Blue objects are the results for the criteria optimized for a fixed area threshold (represented by a vertical, solid, black line), and orange objects those for the criteria optimized for every area threshold.*\n",
    "\n",
    "This figure is similar to Figure 11, but the comparison now is between the criteria optimized for a fixed area threshold (2000 km¬≤) and for a varying area threshold. For the area threshold of 2000 km¬≤ (vertical, black line) the values should be the same for the two approaches.\n",
    "\n",
    "* The probability threshold shows a similar behaviour among approaches. It goes towards slighly lower values for catchment areas below the 2000 km¬≤ threshold, it increases from that threshold towards larger areas up to a point from which it dicreases severely, being very low for very large catchments. Only the _member weighted_ approach has a more erratic behaviour.\n",
    "\n",
    "* The skill measured as $f_{0.8}$ is very similar with both approaches. For areas lower than 2000 km¬≤ the skill is practically the same. For larger areas, the main improvement is at the range between 30,000 and 70,000 km¬≤, for which the fixed criteria shows a loss in skill. The biggest improvement is achieved in the _brier weighted_ approach.\n",
    "\n",
    "* The spread between $precision$ and $recall$ do change towards larger spread, especially fot the _1 deterministic and 1 probabilistic_ and the _brier weighted_ approach.\n",
    "\n",
    "The main outcome of this experiment is that the global skill of the system does not improve severely with a varying probability threshold. Therefore, for the sake of simplificity, a fixed probability threshold is advisable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
