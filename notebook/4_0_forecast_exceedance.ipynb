{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fd5f453-13c1-47c1-ad27-8af80b47ee08",
   "metadata": {},
   "source": [
    "# Forecast exceedance\n",
    "***\n",
    "\n",
    "**Author**: Chus Casado<br>\n",
    "**Date**: 23-02-2023<br>\n",
    "\n",
    "**Introduction**:<br>\n",
    "\n",
    "\n",
    "**Questions**:<br>\n",
    "\n",
    "\n",
    "**Tasks to do**:<br>\n",
    "\n",
    "**Interesting links**<br>\n",
    "[Pythonic way to perform statistics across multiple variables with Xarray](https://towardsdatascience.com/pythonic-way-to-perform-statistics-across-multiple-variables-with-xarray-d0221c78e34a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4ee7a0f-f62b-4a8b-8147-c46a2e2471ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path_root = os.getcwd()\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.chdir('../py/')\n",
    "from notifications import *\n",
    "os.chdir(path_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ec6de5-35d0-4e78-a74d-0b9cc867050c",
   "metadata": {},
   "source": [
    "### 1 Discharge forecast\n",
    "\n",
    "#### List available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1132a46-020a-4564-b164-09953a40605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_forecast = 'E:/casadje/Documents/skill_assessment/data/CDS/forecast/'\n",
    "\n",
    "models = ['COS', 'DWD', 'EUD', 'EUE']\n",
    "\n",
    "# list files\n",
    "fore_files = {model: [] for model in models}\n",
    "for year in [2020, 2021, 2022]:\n",
    "    for month in range(1, 13):    \n",
    "        # list files\n",
    "        for model in models:\n",
    "            fore_files[model] += glob.glob(f'{path_forecast}{model}/{year}/{month:02d}/*.nc')\n",
    "\n",
    "# count files and check if all are avaible\n",
    "n_files = pd.Series(data=[len(fore_files[model]) for model in models], index=models)\n",
    "\n",
    "# list of forecast from the beginning to the end of the data\n",
    "start, end = datetime(1900, 1, 1), datetime(2100, 1, 1)\n",
    "for model in models:\n",
    "    st, en = [datetime.strptime(fore_files[model][step][-13:-3], '%Y%m%d%H') for step in [0, -1]]\n",
    "    start = max(st, start)\n",
    "    end = min(en, end)\n",
    "dates = pd.date_range(start, end, freq='12h')\n",
    "\n",
    "# find missing files\n",
    "if any(n_files != len(dates)):\n",
    "    missing = {}\n",
    "    for model in models:\n",
    "        filedates = [datetime.strptime(file[-13:-3], '%Y%m%d%H') for file in fore_files[model]]    \n",
    "        missing[model] = [date for date in dates if date not in filedates]\n",
    "    print('mising files:', missing)\n",
    "\n",
    "# trim files to the period where all models are available\n",
    "for model in models:\n",
    "    fore_files[model] = [file for file in fore_files[model] if start <= datetime.strptime(file[-13:-3], '%Y%m%d%H') <= end]\n",
    "    print('{0}:\\t{1} files'.format(model, len(fore_files[model])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79709b93-c32f-4bac-81b0-69a5ffb6cc57",
   "metadata": {},
   "source": [
    "## 2 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356c2fd7-ae1c-434c-b947-08c417f1bb8b",
   "metadata": {},
   "source": [
    "### 2.1 Stations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "435ab471-c719-4419-898c-2b91a40bcf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. stations:\t\t\t900\n"
     ]
    }
   ],
   "source": [
    "# load selected points for all the catchments\n",
    "stations = pd.DataFrame()\n",
    "catchments = []\n",
    "results_path = '../results/select_reporting_points/'\n",
    "for folder in os.listdir(results_path):\n",
    "    try:\n",
    "        stn_cat = pd.read_csv(f'{results_path}{folder}/points_selected.csv', index_col='station_id')\n",
    "        stations = pd.concat((stations, stn_cat))\n",
    "        catchments.append(folder)\n",
    "    except:\n",
    "        continue\n",
    "print('no. stations:\\t\\t\\t{0}'.format(stations.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cc81fe-1c33-4bec-9075-67d2ea01dc4d",
   "metadata": {},
   "source": [
    "### 2.2 Reforecast data: exceedance probability\n",
    "\n",
    "This section will iteratively (station by station) load all the available forecast and compute the probability of exceeding the discharge threshold for each of the meteorological forcings. The result will be a NetCDF file for each station that contains the exceedance probability. These files will be later used in the skill assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cff2b77d-9afc-4920-921c-adf2df95880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export files station by station\n",
    "path = f'../data/exceedance/forecast/'\n",
    "if os.path.exists(path) is False:\n",
    "    os.makedirs(path)\n",
    "\n",
    "# select stations that haven't been processed before\n",
    "files = glob.glob(f'{path}*.nc')\n",
    "if len(files) > 0:\n",
    "    old_stations = [int(file.split('\\\\')[-1].split('.')[0]) for file in files]\n",
    "    new_stations = set(stations.index).difference(old_stations)\n",
    "    stations = stations.loc[new_stations]\n",
    "    print('no. new stations:\\t\\t\\t{0}'.format(stations.shape[0]))\n",
    "\n",
    "# generate a DataArray with the discharge threshold of the stations in the catchment\n",
    "thresholds = xr.DataArray(stations.rl5, dims='id', coords={'id': stations.index.astype(str).tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c02555b-504c-404e-9ff5-6fdeaa205fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COS\tE:/casadje/Documents/skill_assessment/data/CDS/forecast/COS/2021/03\\COS2021032700.nc\r"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "# compute exceedance\n",
    "exceedance = compute_exceedance_2(fore_files, thresholds)\n",
    "\n",
    "for stn in exceedance.id.data:\n",
    "    file = f'{stn:>04}.nc'\n",
    "    # file = f'{stn:04d}.nc'\n",
    "    if file in os.listdir(path):\n",
    "        print(f'File {file} already exists')\n",
    "        continue\n",
    "    else:\n",
    "        exceedance.sel(id=stn).to_netcdf(f'{path}{file}')\n",
    "        \n",
    "end = time.perf_counter()\n",
    "\n",
    "print('excecution time: {0:.1f} s'.format(end - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
