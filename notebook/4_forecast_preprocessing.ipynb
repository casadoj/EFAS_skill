{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fd5f453-13c1-47c1-ad27-8af80b47ee08",
   "metadata": {},
   "source": [
    "# Forecast exceedance\n",
    "***\n",
    "\n",
    "**Author**: Chus Casado<br>\n",
    "**Date**: 23-03-2023<br>\n",
    "\n",
    "**Introduction**:<br>\n",
    "\n",
    "\n",
    "**Questions**:<br>\n",
    "\n",
    "\n",
    "**Tasks to do**:<br>\n",
    "\n",
    "**Interesting links**<br>\n",
    "[Pythonic way to perform statistics across multiple variables with Xarray](https://towardsdatascience.com/pythonic-way-to-perform-statistics-across-multiple-variables-with-xarray-d0221c78e34a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4ee7a0f-f62b-4a8b-8147-c46a2e2471ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path_root = os.getcwd()\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.chdir('../py/')\n",
    "from computations import *\n",
    "from plots import *\n",
    "os.chdir(path_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ec6de5-35d0-4e78-a74d-0b9cc867050c",
   "metadata": {},
   "source": [
    "### 1 Discharge forecast\n",
    "\n",
    "#### List available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1132a46-020a-4564-b164-09953a40605d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COS:\t1460 files\n",
      "DWD:\t1460 files\n",
      "EUD:\t1460 files\n",
      "EUE:\t1460 files\n"
     ]
    }
   ],
   "source": [
    "path_forecast = 'E:/casadje/Documents/skill_assessment/data/CDS/forecast/'\n",
    "\n",
    "models = ['COS', 'DWD', 'EUD', 'EUE']\n",
    "\n",
    "# list files\n",
    "fore_files = {model: [] for model in models}\n",
    "for year in [2020, 2021, 2022]:\n",
    "    for month in range(1, 13):    \n",
    "        # list files\n",
    "        for model in models:\n",
    "            fore_files[model] += glob.glob(f'{path_forecast}{model}/{year}/{month:02d}/*.nc')\n",
    "\n",
    "# count files and check if all are avaible\n",
    "n_files = pd.Series(data=[len(fore_files[model]) for model in models], index=models)\n",
    "\n",
    "# list of forecast from the beginning to the end of the data\n",
    "start, end = datetime(1900, 1, 1), datetime(2100, 1, 1)\n",
    "for model in models:\n",
    "    st, en = [datetime.strptime(fore_files[model][step][-13:-3], '%Y%m%d%H') for step in [0, -1]]\n",
    "    start = max(st, start)\n",
    "    end = min(en, end)\n",
    "dates = pd.date_range(start, end, freq='12h')\n",
    "\n",
    "# find missing files\n",
    "if any(n_files != len(dates)):\n",
    "    missing = {}\n",
    "    for model in models:\n",
    "        filedates = [datetime.strptime(file[-13:-3], '%Y%m%d%H') for file in fore_files[model]]    \n",
    "        missing[model] = [date for date in dates if date not in filedates]\n",
    "    print('mising files:', missing)\n",
    "\n",
    "# trim files to the period where all models are available\n",
    "for model in models:\n",
    "    fore_files[model] = [file for file in fore_files[model] if start <= datetime.strptime(file[-13:-3], '%Y%m%d%H') <= end]\n",
    "    print('{0}:\\t{1} files'.format(model, len(fore_files[model])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79709b93-c32f-4bac-81b0-69a5ffb6cc57",
   "metadata": {},
   "source": [
    "## 2 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356c2fd7-ae1c-434c-b947-08c417f1bb8b",
   "metadata": {},
   "source": [
    "### 2.1 Stations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf3d2f2-75b3-4ac1-871b-858efdd5a920",
   "metadata": {},
   "source": [
    "If the preprocessing of the discharge forecast was only to be done in the selected reporting points, the code to run is the following\n",
    "\n",
    "```Python\n",
    "# load selected points for all the catchments\n",
    "stations = pd.DataFrame()\n",
    "catchments = []\n",
    "results_path = '../results/reporting_points/'\n",
    "for folder in os.listdir(results_path):\n",
    "    try:\n",
    "        stn_cat = pd.read_csv(f'{results_path}{folder}/points_selected.csv', index_col='station_id')\n",
    "        stations = pd.concat((stations, stn_cat))\n",
    "        catchments.append(folder)\n",
    "    except:\n",
    "        continue\n",
    "print('no. stations:\\t\\t\\t{0}'.format(stations.shape[0]))\n",
    "```\n",
    "\n",
    "Instead, if the preprocessing is to be done in all the reporting points above a certain area threshold, the code to run is this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1be45fa8-3be8-4dbc-b12c-89c940897ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_threshold = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "732dce9a-fa43-4f56-822f-690dec686e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. stations:\t2371\n"
     ]
    }
   ],
   "source": [
    "# load table of fixed reporing points\n",
    "stations = pd.read_csv('../data/Station-2022-10-27v12.csv', index_col='station_id')\n",
    "\n",
    "# filter stations and fields\n",
    "mask = (stations['DrainingArea.km2.LDD'] >= area_threshold) & (stations.FixedRepPoint == True)\n",
    "stations = stations.loc[mask, ['StationName', 'LisfloodX', 'LisfloodY', 'Catchment', 'River', 'EC_Catchments', 'Country code']]\n",
    "\n",
    "print(f'No. stations:\\t{stations.shape[0]}')\n",
    "\n",
    "# # xarrys with station coordinates that will be used to extract data\n",
    "# x = xr.DataArray(stations.LisfloodX, dims='id')\n",
    "# y = xr.DataArray(stations.LisfloodY, dims='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f589975-5d50-4c45-b838-616a4098c23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StationName</th>\n",
       "      <th>LisfloodX</th>\n",
       "      <th>LisfloodY</th>\n",
       "      <th>Catchment</th>\n",
       "      <th>River</th>\n",
       "      <th>EC_Catchments</th>\n",
       "      <th>Country code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Schwabelweis</td>\n",
       "      <td>4477500.0</td>\n",
       "      <td>2882500.0</td>\n",
       "      <td>Danube</td>\n",
       "      <td>Danube</td>\n",
       "      <td>Danube</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hofkirchen</td>\n",
       "      <td>4547500.0</td>\n",
       "      <td>2847500.0</td>\n",
       "      <td>Danube</td>\n",
       "      <td>Danube</td>\n",
       "      <td>Danube</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pfelling</td>\n",
       "      <td>4517500.0</td>\n",
       "      <td>2867500.0</td>\n",
       "      <td>Danube</td>\n",
       "      <td>Danube</td>\n",
       "      <td>Danube</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barby</td>\n",
       "      <td>4452500.0</td>\n",
       "      <td>3207500.0</td>\n",
       "      <td>Elbe</td>\n",
       "      <td>Elbe</td>\n",
       "      <td>Elbe</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wittenberg / Lutherstadt</td>\n",
       "      <td>4497500.0</td>\n",
       "      <td>3197500.0</td>\n",
       "      <td>Elbe</td>\n",
       "      <td>Elbe</td>\n",
       "      <td>Elbe</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5225</th>\n",
       "      <td>Treignes</td>\n",
       "      <td>3937500.0</td>\n",
       "      <td>3012500.0</td>\n",
       "      <td>Meuse</td>\n",
       "      <td>Viroin</td>\n",
       "      <td>Meuse</td>\n",
       "      <td>BE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5228</th>\n",
       "      <td>Tabreux</td>\n",
       "      <td>4002500.0</td>\n",
       "      <td>3047500.0</td>\n",
       "      <td>Meuse</td>\n",
       "      <td>Ourthe</td>\n",
       "      <td>Meuse</td>\n",
       "      <td>BE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5230</th>\n",
       "      <td>Chaudfontaine Pisc</td>\n",
       "      <td>4017500.0</td>\n",
       "      <td>3057500.0</td>\n",
       "      <td>Meuse</td>\n",
       "      <td>Vesdre</td>\n",
       "      <td>Meuse</td>\n",
       "      <td>BE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5231</th>\n",
       "      <td>Solre Us</td>\n",
       "      <td>3902500.0</td>\n",
       "      <td>3037500.0</td>\n",
       "      <td>Meuse</td>\n",
       "      <td>Haute sambre</td>\n",
       "      <td>Meuse</td>\n",
       "      <td>BE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5232</th>\n",
       "      <td>Lessines Us</td>\n",
       "      <td>3887500.0</td>\n",
       "      <td>3082500.0</td>\n",
       "      <td>Scheldt</td>\n",
       "      <td>Dendre</td>\n",
       "      <td>Scheldt</td>\n",
       "      <td>BE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1471 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         StationName  LisfloodX  LisfloodY Catchment  \\\n",
       "station_id                                                             \n",
       "1                       Schwabelweis  4477500.0  2882500.0    Danube   \n",
       "2                         Hofkirchen  4547500.0  2847500.0    Danube   \n",
       "3                           Pfelling  4517500.0  2867500.0    Danube   \n",
       "4                              Barby  4452500.0  3207500.0      Elbe   \n",
       "5           Wittenberg / Lutherstadt  4497500.0  3197500.0      Elbe   \n",
       "...                              ...        ...        ...       ...   \n",
       "5225                        Treignes  3937500.0  3012500.0     Meuse   \n",
       "5228                         Tabreux  4002500.0  3047500.0     Meuse   \n",
       "5230              Chaudfontaine Pisc  4017500.0  3057500.0     Meuse   \n",
       "5231                        Solre Us  3902500.0  3037500.0     Meuse   \n",
       "5232                     Lessines Us  3887500.0  3082500.0   Scheldt   \n",
       "\n",
       "                   River EC_Catchments Country code  \n",
       "station_id                                           \n",
       "1                 Danube        Danube           DE  \n",
       "2                 Danube        Danube           DE  \n",
       "3                 Danube        Danube           DE  \n",
       "4                   Elbe          Elbe           DE  \n",
       "5                   Elbe          Elbe           DE  \n",
       "...                  ...           ...          ...  \n",
       "5225              Viroin         Meuse           BE  \n",
       "5228              Ourthe         Meuse           BE  \n",
       "5230              Vesdre         Meuse           BE  \n",
       "5231        Haute sambre         Meuse           BE  \n",
       "5232              Dendre       Scheldt           BE  \n",
       "\n",
       "[1471 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cc81fe-1c33-4bec-9075-67d2ea01dc4d",
   "metadata": {},
   "source": [
    "### 2.2 Reforecast data: exceedance probability\n",
    "\n",
    "This section will iteratively (station by station) load all the available forecast and compute the probability of exceeding the discharge threshold for each of the meteorological forcings. The result will be a NetCDF file for each station that contains the exceedance probability. These files will be later used in the skill assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cff2b77d-9afc-4920-921c-adf2df95880d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. new stations:\t\t\t1471\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'rl5'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno. new stations:\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(stations\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# generate a DataArray with the discharge threshold of the stations in the catchment\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m thresholds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray(\u001b[43mstations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrl5\u001b[49m, dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, coords\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: stations\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()})\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\pandas\\core\\generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5569\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5570\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5571\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5572\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5573\u001b[0m ):\n\u001b[0;32m   5574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'rl5'"
     ]
    }
   ],
   "source": [
    "# export files station by station\n",
    "path = f'../data/exceedance/forecast/'\n",
    "if os.path.exists(path) is False:\n",
    "    os.makedirs(path)\n",
    "\n",
    "# select stations that haven't been processed before\n",
    "files = glob.glob(f'{path}*.nc')\n",
    "if len(files) > 0:\n",
    "    old_stations = [int(file.split('\\\\')[-1].split('.')[0]) for file in files]\n",
    "    new_stations = set(stations.index).difference(old_stations)\n",
    "    stations = stations.loc[new_stations]\n",
    "    print('no. new stations:\\t\\t\\t{0}'.format(stations.shape[0]))\n",
    "\n",
    "# generate a DataArray with the discharge threshold of the stations in the catchment\n",
    "thresholds = xr.DataArray(stations.rl5, dims='id', coords={'id': stations.index.astype(str).tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c02555b-504c-404e-9ff5-6fdeaa205fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "# compute exceedance\n",
    "exceedance = compute_exceedance_2(fore_files, thresholds)\n",
    "\n",
    "for stn in exceedance.id.data:\n",
    "    file = f'{stn:>04}.nc'\n",
    "    if file in os.listdir(path):\n",
    "        print(f'File {file} already exists')\n",
    "        continue\n",
    "    else:\n",
    "        exceedance.sel(id=stn).to_netcdf(f'{path}{file}')\n",
    "        \n",
    "end = time.perf_counter()\n",
    "\n",
    "print('excecution time: {0:.1f} s'.format(end - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
