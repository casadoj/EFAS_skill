{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fd5f453-13c1-47c1-ad27-8af80b47ee08",
   "metadata": {},
   "source": [
    "# Forecast preprocessing\n",
    "***\n",
    "\n",
    "**Author**: Chus Casado<br>\n",
    "**Date**: 31-05-2023<br>\n",
    "\n",
    "**Introduction**:<br>\n",
    "This code computes the probability of the forecasted discharge of exceeding a threshold associated with a specific return period.\n",
    "\n",
    "The input data are:\n",
    "* The discharge forecast for the complete set of reporting points, numerical weather prediction (NWP) model and the complete study period. This data is saved in NetCDF format in a hard disk; due to its size it cannot be included in the GitHub repository.\n",
    "* The discharge thresholds associated to each reporting point, from which a specific return period (by default 5 years) will be used.\n",
    "\n",
    "The output is the probability of exceeding the specified return period. This is a matrix of multiple dimensions: station, NWP model, date-time, and lead time. Actually, 2 matrixes are computed, one related to the probability of exceeding the specified threshold ($Q_{rp}$), and another with the probability of exceeding a slighly lower threshold ($0.95\\cdot Q_{rp}$). This lower threshold is used to avoid false positives or false negatives in forecasts very close to the observation, but on opposite sides of the discharge threshold.\n",
    "\n",
    "The results are saved inside the repository as NetCDF, saving one file per reporting point.\n",
    "\n",
    "**Questions**:<br>\n",
    "\n",
    "\n",
    "**Tasks to do**:<br>\n",
    "* [ ] Probably, the `discharge2exceedance` function could be improved so the two discharge thresholds are computed at the same time. Since the function needs to load all the forecast discharge records, it is a waste of time the current procedure, in which all the records need to be loaded twice (once for each discharge threshold).\n",
    "\n",
    "**Interesting links**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4ee7a0f-f62b-4a8b-8147-c46a2e2471ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path_root = os.getcwd()\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "import yaml\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.chdir('../py/')\n",
    "from compute import *\n",
    "os.chdir(path_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c93f9bd-6b3d-4ee8-a815-4c5048c13ac3",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40c1f647-ee7e-44ec-a163-b789a8f90795",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../conf/config.yml\", \"r\", encoding='utf8') as ymlfile:\n",
    "    cfg = yaml.load(ymlfile, Loader=yaml.FullLoader)\n",
    "\n",
    "# area threshold\n",
    "area_threshold = cfg.get('reporting_points', {}).get('area', 500)\n",
    "\n",
    "# return period\n",
    "rp = cfg.get('return_period', {}).get('threshold', 5)\n",
    "\n",
    "# percent buffer over the discharge threshold\n",
    "reducing_factor = cfg.get('return_period', {}).get('reducing_factor', None)\n",
    "\n",
    "# PATHS\n",
    "\n",
    "# local directory where I have saved the raw discharge data\n",
    "path_in = cfg.get('paths', {}).get('input', {}).get('discharge', {}).get('forecast', f'../data/discharge/reanalysis/')\n",
    "\n",
    "# path where the output exceedance datasets will be saved\n",
    "path_out = cfg.get('paths', {}).get('output', {}).get('exceedance', {}).get('forecast', f'../data/exceedance/forecast/')\n",
    "if os.path.exists(path_out) is False:\n",
    "    os.makedirs(path_out)\n",
    "    \n",
    "# reporting points\n",
    "path_stations = cfg.get('paths', {}).get('output', {}).get('reporting_points', '../results/reporting_points/')\n",
    "file_stations = f'{path_stations}reporting_points_over_{area_threshold}km2.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ec6de5-35d0-4e78-a74d-0b9cc867050c",
   "metadata": {},
   "source": [
    "### 1 Discharge forecast\n",
    "\n",
    "#### List available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2a7d7fe-2b33-41db-9d66-344913ea1a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COS:\t1460 files\n",
      "DWD:\t1460 files\n",
      "EUD:\t1460 files\n",
      "EUE:\t1460 files\n"
     ]
    }
   ],
   "source": [
    "# list files\n",
    "fore_files = {model: [] for model in list(models)}\n",
    "for year in [2021, 2022]:\n",
    "    for month in range(1, 13):    \n",
    "        # list files\n",
    "        for model in models:\n",
    "            fore_files[model] += glob.glob(f'{path_in}{model}/{year}/{month:02d}/*.nc')\n",
    "\n",
    "# count files and check if all are avaible\n",
    "n_files = pd.Series(data=[len(fore_files[model]) for model in models], index=models)\n",
    "\n",
    "# list of forecast from the beginning to the end of the data\n",
    "start, end = datetime(1900, 1, 1), datetime(2100, 1, 1)\n",
    "for model in models:\n",
    "    st, en = [datetime.strptime(fore_files[model][step][-13:-3], '%Y%m%d%H') for step in [0, -1]]\n",
    "    start = max(st, start)\n",
    "    end = min(en, end)\n",
    "dates = pd.date_range(start, end, freq='12h')\n",
    "\n",
    "# find missing files\n",
    "if any(n_files != len(dates)):\n",
    "    missing = {}\n",
    "    for model in models:\n",
    "        filedates = [datetime.strptime(file[-13:-3], '%Y%m%d%H') for file in fore_files[model]]    \n",
    "        missing[model] = [date for date in dates if date not in filedates]\n",
    "    print('mising files:', missing)\n",
    "\n",
    "# trim files to the period where all models are available\n",
    "for model in models:\n",
    "    fore_files[model] = [file for file in fore_files[model] if start <= datetime.strptime(file[-13:-3], '%Y%m%d%H') <= end]\n",
    "    print('{0}:\\t{1} files'.format(model, len(fore_files[model])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79709b93-c32f-4bac-81b0-69a5ffb6cc57",
   "metadata": {},
   "source": [
    "## 2 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356c2fd7-ae1c-434c-b947-08c417f1bb8b",
   "metadata": {},
   "source": [
    "### 2.1 Stations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9114c0d-e8b6-4e91-ba57-7ec1a11f8ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load table of fixed reporing points\n",
    "stations = pd.read_parquet(file_stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cc81fe-1c33-4bec-9075-67d2ea01dc4d",
   "metadata": {},
   "source": [
    "### 2.2 Reforecast data: exceedance probability\n",
    "\n",
    "This section will iteratively (station by station) load all the available forecast and compute the probability of exceeding the discharge threshold for each of the meteorological forcings. The result will be a NetCDF file for each station that contains the exceedance probability. These files will be later used in the skill assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cff2b77d-9afc-4920-921c-adf2df95880d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. new stations:\t\t\t0\n"
     ]
    }
   ],
   "source": [
    "# select stations that haven't been processed before\n",
    "files = glob.glob(f'{path_out}*.nc')\n",
    "if len(files) > 0:\n",
    "    old_stations = [int(file.split('\\\\')[-1].split('.')[0]) for file in files]\n",
    "    new_stations = set(stations.index).difference(old_stations)\n",
    "    stations = stations.loc[new_stations]\n",
    "print('no. new stations:\\t\\t\\t{0}'.format(stations.shape[0]))\n",
    "\n",
    "# generate a DataArray with the discharge threshold of the stations in the catchment\n",
    "thresholds = xr.DataArray(stations[f'rl{rp}'], dims='id', coords={'id': stations.index.astype(str).tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7625c8a2-c2df-4f45-9518-ba8cf004cce6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d268e3c9199468dbd1fc9050e283534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844519fc411d426bacadf1345c73b5fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1460 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COS\tE:/casadje/Documents/skill_assessment/data/CDS/forecast/COS/2021/01\\COS2021010100.nc\r"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The indexing operation you are attempting to perform is not valid on netCDF4.Variable object. Try loading your data into memory first by calling .load().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\xarray\\backends\\netCDF4_.py:103\u001b[0m, in \u001b[0;36mNetCDF4ArrayWrapper._getitem\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    102\u001b[0m         original_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_array(needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 103\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mgetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;66;03m# Catch IndexError in netCDF4 and return a more informative\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;66;03m# error message.  This is most often called when an unsorted\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m# indexer is used before the data is loaded from disk.\u001b[39;00m\n",
      "File \u001b[1;32msrc\\netCDF4\\_netCDF4.pyx:4383\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Variable.__getitem__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\netCDF4\\utils.py:458\u001b[0m, in \u001b[0;36m_out_array_shape\u001b[1;34m(count)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 458\u001b[0m     c \u001b[38;5;241m=\u001b[39m \u001b[43mcount\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# All elements should be identical.\u001b[39;00m\n\u001b[0;32m    459\u001b[0m     out\u001b[38;5;241m.\u001b[39mappend(c)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# exceedances over Q5\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m exceedance_q5 \u001b[38;5;241m=\u001b[39m \u001b[43mdischarge2exceedance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfore_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthresholds\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# * (1 + reducing_factor))\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# exceedances over 95% of the Q5\u001b[39;00m\n\u001b[0;32m      6\u001b[0m exceedance_buffer \u001b[38;5;241m=\u001b[39m discharge2exceedance(fore_files, thresholds \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m reducing_factor))\n",
      "File \u001b[1;32mE:\\casadje\\GitHub\\EFAS_skill\\py\\compute.py:108\u001b[0m, in \u001b[0;36mdischarge2exceedance\u001b[1;34m(model_files, thresholds, verbose)\u001b[0m\n\u001b[0;32m    104\u001b[0m dis[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleadtime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [timedelta(hours\u001b[38;5;241m=\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m6\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dis\u001b[38;5;241m.\u001b[39mleadtime))]\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# compute mean exceedance over the threshod\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# this steps also select the stations\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m exc \u001b[38;5;241m=\u001b[39m \u001b[43mdis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mthresholds\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmember\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mdims:\n\u001b[0;32m    110\u001b[0m     exc \u001b[38;5;241m=\u001b[39m exc\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmember\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\xarray\\core\\_typed_ops.py:242\u001b[0m, in \u001b[0;36mDataArrayOpsMixin.__gt__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__gt__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_binary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\xarray\\core\\dataarray.py:3081\u001b[0m, in \u001b[0;36mDataArray._binary_op\u001b[1;34m(self, other, f, reflexive)\u001b[0m\n\u001b[0;32m   3077\u001b[0m other_variable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(other, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariable\u001b[39m\u001b[38;5;124m\"\u001b[39m, other)\n\u001b[0;32m   3078\u001b[0m other_coords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(other, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoords\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   3080\u001b[0m variable \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 3081\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother_variable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3082\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reflexive\n\u001b[0;32m   3083\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m f(other_variable, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariable)\n\u001b[0;32m   3084\u001b[0m )\n\u001b[0;32m   3085\u001b[0m coords, indexes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoords\u001b[38;5;241m.\u001b[39m_merge_raw(other_coords, reflexive)\n\u001b[0;32m   3086\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_name(other)\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\xarray\\core\\_typed_ops.py:432\u001b[0m, in \u001b[0;36mVariableOpsMixin.__gt__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__gt__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_binary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\xarray\\core\\variable.py:2404\u001b[0m, in \u001b[0;36mVariable._binary_op\u001b[1;34m(self, other, f, reflexive)\u001b[0m\n\u001b[0;32m   2402\u001b[0m     other_data, self_data, dims \u001b[38;5;241m=\u001b[39m _broadcast_compat_data(other, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   2403\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2404\u001b[0m     self_data, other_data, dims \u001b[38;5;241m=\u001b[39m \u001b[43m_broadcast_compat_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2405\u001b[0m keep_attrs \u001b[38;5;241m=\u001b[39m _get_keep_attrs(default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2406\u001b[0m attrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attrs \u001b[38;5;28;01mif\u001b[39;00m keep_attrs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\xarray\\core\\variable.py:2873\u001b[0m, in \u001b[0;36m_broadcast_compat_data\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   2870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mhasattr\u001b[39m(other, attr) \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdims\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m   2871\u001b[0m     \u001b[38;5;66;03m# `other` satisfies the necessary Variable API for broadcast_variables\u001b[39;00m\n\u001b[0;32m   2872\u001b[0m     new_self, new_other \u001b[38;5;241m=\u001b[39m _broadcast_compat_variables(\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m-> 2873\u001b[0m     self_data \u001b[38;5;241m=\u001b[39m \u001b[43mnew_self\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\n\u001b[0;32m   2874\u001b[0m     other_data \u001b[38;5;241m=\u001b[39m new_other\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m   2875\u001b[0m     dims \u001b[38;5;241m=\u001b[39m new_self\u001b[38;5;241m.\u001b[39mdims\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\xarray\\core\\variable.py:346\u001b[0m, in \u001b[0;36mVariable.data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\xarray\\core\\variable.py:519\u001b[0m, in \u001b[0;36mVariable.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;124;03m\"\"\"The variable's data as a numpy.ndarray\"\"\"\u001b[39;00m\n\u001b[1;32m--> 519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_as_array_or_item\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\xarray\\core\\variable.py:259\u001b[0m, in \u001b[0;36m_as_array_or_item\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_as_array_or_item\u001b[39m(data):\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the given values as a numpy array, or as an individual item if\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03m    it's a 0d datetime64 or timedelta64 array.\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;124;03m    TODO: remove this (replace with np.asarray) once these issues are fixed\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 259\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\numpy\\core\\_asarray.py:102\u001b[0m, in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m like \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_like(a, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder, like\u001b[38;5;241m=\u001b[39mlike)\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\xarray\\core\\indexing.py:551\u001b[0m, in \u001b[0;36mMemoryCachedArray.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 551\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\xarray\\core\\indexing.py:548\u001b[0m, in \u001b[0;36mMemoryCachedArray._ensure_cached\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ensure_cached\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    547\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray, NumpyIndexingAdapter):\n\u001b[1;32m--> 548\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray \u001b[38;5;241m=\u001b[39m NumpyIndexingAdapter(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\numpy\\core\\_asarray.py:102\u001b[0m, in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m like \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_like(a, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder, like\u001b[38;5;241m=\u001b[39mlike)\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\xarray\\core\\indexing.py:521\u001b[0m, in \u001b[0;36mCopyOnWriteArray.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 521\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\numpy\\core\\_asarray.py:102\u001b[0m, in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m like \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_like(a, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder, like\u001b[38;5;241m=\u001b[39mlike)\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\xarray\\core\\indexing.py:422\u001b[0m, in \u001b[0;36mLazilyIndexedArray.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    421\u001b[0m     array \u001b[38;5;241m=\u001b[39m as_indexable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray)\n\u001b[1;32m--> 422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\xarray\\backends\\netCDF4_.py:90\u001b[0m, in \u001b[0;36mNetCDF4ArrayWrapper.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplicit_indexing_adapter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexingSupport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOUTER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\xarray\\core\\indexing.py:711\u001b[0m, in \u001b[0;36mexplicit_indexing_adapter\u001b[1;34m(key, shape, indexing_support, raw_indexing_method)\u001b[0m\n\u001b[0;32m    689\u001b[0m \u001b[38;5;124;03m\"\"\"Support explicit indexing by delegating to a raw indexing method.\u001b[39;00m\n\u001b[0;32m    690\u001b[0m \n\u001b[0;32m    691\u001b[0m \u001b[38;5;124;03mOuter and/or vectorized indexers are supported by indexing a second time\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;124;03mIndexing result, in the form of a duck numpy-array.\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    710\u001b[0m raw_key, numpy_indices \u001b[38;5;241m=\u001b[39m decompose_indexer(key, shape, indexing_support)\n\u001b[1;32m--> 711\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mraw_indexing_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_key\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtuple\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy_indices\u001b[38;5;241m.\u001b[39mtuple:\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;66;03m# index the loaded np.ndarray\u001b[39;00m\n\u001b[0;32m    714\u001b[0m     result \u001b[38;5;241m=\u001b[39m NumpyIndexingAdapter(np\u001b[38;5;241m.\u001b[39masarray(result))[numpy_indices]\n",
      "File \u001b[1;32mC:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\xarray\\backends\\netCDF4_.py:113\u001b[0m, in \u001b[0;36mNetCDF4ArrayWrapper._getitem\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;66;03m# Catch IndexError in netCDF4 and return a more informative\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;66;03m# error message.  This is most often called when an unsorted\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m# indexer is used before the data is loaded from disk.\u001b[39;00m\n\u001b[0;32m    108\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe indexing operation you are attempting to perform \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not valid on netCDF4.Variable object. Try loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data into memory first by calling .load().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    112\u001b[0m     )\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(msg)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array\n",
      "\u001b[1;31mIndexError\u001b[0m: The indexing operation you are attempting to perform is not valid on netCDF4.Variable object. Try loading your data into memory first by calling .load()."
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "# exceedances over Q5\n",
    "exceedance_q5 = discharge2exceedance(fore_files, thresholds) # * (1 + reducing_factor))\n",
    "# exceedances over 95% of the Q5\n",
    "exceedance_buffer = discharge2exceedance(fore_files, thresholds * (1 - reducing_factor))\n",
    "# join both DataArrays in a single Dataset\n",
    "exceedance = xr.Dataset({'high': exceedance_q5, 'low': exceedance_buffer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c178304c-91ce-47a9-9f0f-b41329462faa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# export files station by station\n",
    "for stn in tqdm_notebook(exceedance.id.data):\n",
    "    file = f'{stn:>04}.nc'\n",
    "    if file in os.listdir(path_out):\n",
    "        print(f'File {file} already exists')\n",
    "        continue\n",
    "    else:\n",
    "        exceedance.sel(id=stn).to_netcdf(f'{path_out}{file}')\n",
    "        \n",
    "end = time.perf_counter()\n",
    "\n",
    "print('excecution time: {0:.1f} s'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bed15f3-5052-4349-b2bc-6b54dfd9ebf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
