{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fd5f453-13c1-47c1-ad27-8af80b47ee08",
   "metadata": {},
   "source": [
    "# Forecast exceedance\n",
    "***\n",
    "\n",
    "**Author**: Chus Casado<br>\n",
    "**Date**: 02-02-2023<br>\n",
    "\n",
    "**Introduction**:<br>\n",
    "\n",
    "\n",
    "**Questions**:<br>\n",
    "\n",
    "\n",
    "**Tasks to do**:<br>\n",
    "\n",
    "**Interesting links**<br>\n",
    "[Pythonic way to perform statistics across multiple variables with Xarray](https://towardsdatascience.com/pythonic-way-to-perform-statistics-across-multiple-variables-with-xarray-d0221c78e34a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4ee7a0f-f62b-4a8b-8147-c46a2e2471ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path_root = os.getcwd()\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.chdir('../py/')\n",
    "from notifications import *\n",
    "os.chdir(path_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ec6de5-35d0-4e78-a74d-0b9cc867050c",
   "metadata": {},
   "source": [
    "### 1 Discharge forecast\n",
    "\n",
    "#### List available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f8ced3d-c64f-4a09-a4bc-90da1e5e92b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mising files: {'COS': [], 'DWD': [], 'EUD': [], 'EUE': []}\n",
      "COS:\t730 files\n",
      "DWD:\t730 files\n",
      "EUD:\t730 files\n",
      "EUE:\t730 files\n"
     ]
    }
   ],
   "source": [
    "path_forecast = 'E:/casadje/Documents/skill_assessment/data/CDS/forecast/'\n",
    "\n",
    "models = ['COS', 'DWD', 'EUD', 'EUE']\n",
    "\n",
    "# list files\n",
    "fore_files = {model: [] for model in models}\n",
    "for year in [2020, 2021, 2022]:\n",
    "    for month in range(1, 13):    \n",
    "        # list files\n",
    "        for model in models:\n",
    "            fore_files[model] += glob.glob(f'{path_forecast}{model}/{year}/{month:02d}/*.nc')\n",
    "\n",
    "# count files and check if all are avaible\n",
    "n_files = pd.Series(data=[len(fore_files[model]) for model in models], index=models)\n",
    "\n",
    "# list of forecast from the beginning to the end of the data\n",
    "start, end = datetime(1900, 1, 1), datetime(2100, 1, 1)\n",
    "for model in models:\n",
    "    st, en = [datetime.strptime(fore_files[model][step][-13:-3], '%Y%m%d%H') for step in [0, -1]]\n",
    "    start = max(st, start)\n",
    "    end = min(en, end)\n",
    "dates = pd.date_range(start, end, freq='12h')\n",
    "\n",
    "# find missing files\n",
    "if any(n_files != len(dates)):\n",
    "    missing = {}\n",
    "    for model in models:\n",
    "        filedates = [datetime.strptime(file[-13:-3], '%Y%m%d%H') for file in fore_files[model]]    \n",
    "        missing[model] = [date for date in dates if date not in filedates]\n",
    "    print('mising files:', missing)\n",
    "\n",
    "# trim files to the period where all models are available\n",
    "for model in models:\n",
    "    fore_files[model] = [file for file in fore_files[model] if start <= datetime.strptime(file[-13:-3], '%Y%m%d%H') <= end]\n",
    "    print('{0}:\\t{1} files'.format(model, len(fore_files[model])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79709b93-c32f-4bac-81b0-69a5ffb6cc57",
   "metadata": {},
   "source": [
    "## 2 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356c2fd7-ae1c-434c-b947-08c417f1bb8b",
   "metadata": {},
   "source": [
    "### 2.1 Stations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c0d96b5-5a09-401c-b9dd-3e846a92876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchments = ['Rhine', 'Ems', 'Weser', 'Elbe', 'Vistula', 'Oder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b30bae68-4c66-4742-84b0-31132947854b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rhine          \t44 stations\n",
      "Ems            \t1 stations\n",
      "Weser          \t10 stations\n",
      "Elbe           \t30 stations\n",
      "Vistula        \t43 stations\n",
      "Oder           \t32 stations\n",
      "total no. stations:\t160\n"
     ]
    }
   ],
   "source": [
    "# load selected points for all the catchments\n",
    "stations = pd.DataFrame()\n",
    "for catchment in catchments:\n",
    "    stn_cat = pd.read_csv(f'results/{catchment}/points_selected.csv', index_col='station_id')\n",
    "    print('{0: <15}\\t{1} stations'.format(catchment, stn_cat.shape[0]))\n",
    "    stations = pd.concat((stations, stn_cat))\n",
    "print('total no. stations:\\t{0}'.format(stations.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e03337c-6cae-49fe-a995-382242f60caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a DataArray with the discharge threshold of the stations in the catchment\n",
    "thresholds = xr.DataArray(stations.rl5, dims='id', coords={'id': stations.index.astype(str).tolist()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cc81fe-1c33-4bec-9075-67d2ea01dc4d",
   "metadata": {},
   "source": [
    "### 2.2 Reforecast data: exceedance probability\n",
    "\n",
    "This section will iteratively (station by station) load all the available forecast and compute the probability of exceeding the discharge threshold for each of the meteorological forcings. The result will be a NetCDF file for each station that contains the exceedance probability. These files will be later used in the skill assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51060389-bf2f-4d12-9bec-62bfff53e39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COS\tE:/casadje/Documents/skill_assessment/data/CDS/forecast/COS/2021/12\\COS2021123112.nc\n",
      "DWD\tE:/casadje/Documents/skill_assessment/data/CDS/forecast/DWD/2021/12\\DWD2021123112.nc\n",
      "EUD\tE:/casadje/Documents/skill_assessment/data/CDS/forecast/EUD/2021/12\\EUD2021123112.nc\n",
      "EUE\tE:/casadje/Documents/skill_assessment/data/CDS/forecast/EUE/2021/12\\EUE2021123112.nc\n",
      "excecution time: 672.1 s\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "# compute exceedance\n",
    "exceedance = compute_exceedance_2(fore_files, thresholds)\n",
    "\n",
    "# export files station by station\n",
    "path = f'../data/exceedance/forecast/test/'\n",
    "if os.path.exists(path) is False:\n",
    "    os.makedirs(path)\n",
    "for stn in exceedance.id.data:\n",
    "    file = f'{stn:>04}.nc'\n",
    "    # file = f'{stn:04d}.nc'\n",
    "    if file in os.listdir(path):\n",
    "        print(f'File {file} already exists')\n",
    "        continue\n",
    "    else:\n",
    "        exceedance.sel(id=stn).to_netcdf(f'{path}{file}')\n",
    "        \n",
    "end = time.perf_counter()\n",
    "\n",
    "print('excecution time: {0:.1f} s'.format(end - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
