{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "654baf6d-f8eb-49dc-a90d-d8dd284d451d",
   "metadata": {},
   "source": [
    "# Summarize skill results\n",
    "***\n",
    "\n",
    "**Author**: Chus Casado Rodr√≠guez<br>\n",
    "**Date**: 02-08-2023<br>\n",
    "\n",
    "\n",
    "**Introduction**:<br>\n",
    "This notebook creates a table comparing the skill of the diverse notification criteria optimized for different f-scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f417aff7-e56d-4497-8e8e-727ea08402f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path_root = os.getcwd()\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from datetime import datetime, timedelta\n",
    "import pickle\n",
    "import yaml\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.chdir('../py/')\n",
    "from compute import hits2skill, limit_leadtime\n",
    "os.chdir(path_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a899f4-7f7b-4404-a63e-f1344fa1f331",
   "metadata": {},
   "source": [
    "## 1 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2febe9c2-a0e7-441a-9c19-0109c3bd6aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../conf/config.yml\", \"r\", encoding='utf8') as ymlfile:\n",
    "    cfg = yaml.load(ymlfile, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e915052-7b61-41cc-981c-1b135c8b2357",
   "metadata": {},
   "source": [
    "### 1.1 Reporting points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea338ed0-5ebe-4565-8f2c-e2398bc6c6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# area threshold\n",
    "area_threshold = cfg.get('reporting_points', {}).get('area', 500)\n",
    "\n",
    "# reporting points\n",
    "path_stations = cfg.get('reporting_points', {}).get('output', '../results/reporting_points/')\n",
    "file_stations = f'{path_stations}reporting_points_over_{area_threshold}km2.parquet'\n",
    "\n",
    "# catchments\n",
    "catchments = cfg.get('reporting_points', {}).get('catchments', None)\n",
    "\n",
    "# minimum performance required from the reporting points\n",
    "min_kge = cfg.get('reporting_points', {}).get('KGE', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59b30d3-d313-4db6-b0f7-f4aa5acbf8b4",
   "metadata": {},
   "source": [
    "### 1.2 Hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ce26e71-7110-466e-bcd2-b2343ecf72d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lead time ranges\n",
    "leadtime = cfg.get('hits', {}).get('leadtime', None)\n",
    "\n",
    "# parameters of the rolling window used to compute hits\n",
    "window = cfg.get('hits', {}).get('window', 1)\n",
    "\n",
    "# dissagregate the analysis by seasons?\n",
    "seasonality = cfg.get('hits', {}).get('seasonality', False)\n",
    "\n",
    "# path that contains the NetCDFs with hit, misses and false alarms pro\n",
    "path_in = cfg.get('hits', {}).get('output', '../results/hits/')\n",
    "path_in = f'{path_in}window_{window}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65389aa3-8726-45ee-adec-5930ce6c8fb9",
   "metadata": {},
   "source": [
    "### 1.3 Skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8b31a26-f636-4b02-a16f-0a1167e28a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current operationa criteria\n",
    "current_criteria = cfg.get('skill', {}).get('current_criteria', None)\n",
    "\n",
    "# fixed notification criteria\n",
    "min_leadtime = cfg.get('skill', {}).get('leadtime', 60) \n",
    "min_area = cfg.get('skill', {}).get('area', 2000) \n",
    "\n",
    "# path where results will be saved\n",
    "path_out = cfg.get('skill', {}).get('output', f'../results/skill/')\n",
    "if min_kge is not None:\n",
    "    path_out = f'{path_out}window_{window}/kge_{min_kge}/'\n",
    "else:\n",
    "    path_out = f'{path_out}window_{window}/no_kge/'\n",
    "    \n",
    "# coefficient of the fbeta-score\n",
    "betas = [float(item[1:]) for item in os.listdir(path_out) if os.path.isdir(f'{path_out}{item}') and item.startswith('f')]\n",
    "betas = [1 if beta == 1.0 else beta for beta in betas]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8827e1d7-7c0c-43de-b83f-4409dba98094",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2 Data\n",
    "\n",
    "### 2.1 Reporting points\n",
    "\n",
    "I load all the stations that where selected in a previous [notebook](3_0_select_stations.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7758ac43-6d08-465c-913f-f09d2adc33f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All points\n",
      "----------\n",
      "no. reporting points:\t\t1979\n",
      "no. stations with events:\t966\n",
      "no. observed events:\t\t1683\n",
      "\n",
      "Points selected for otimization\n",
      "-------------------------------\n",
      "no. reporting points:\t\t1239\n",
      "no. stations with events:\t562\n",
      "no. observed events:\t\t874\n"
     ]
    }
   ],
   "source": [
    "# load table of fixed reporting points\n",
    "stations = pd.read_parquet(file_stations)\n",
    "stations[['X', 'Y', 'area']] = stations[['X', 'Y', 'area']].astype(int)\n",
    "\n",
    "# select stations that belong to the selected catchments\n",
    "if catchments is not None:\n",
    "    if isinstance(catchments, list) is False:\n",
    "        catchments = [catchments]\n",
    "    stations = stations.loc[stations.catchment.isin(catchments),:]\n",
    "\n",
    "# remove points with a performance (KGE) lower than the established threshold\n",
    "if min_kge is not None:\n",
    "    mask_kge = ~(stations.KGE <= min_kge)\n",
    "    stations = stations.loc[mask_kge]\n",
    "else:\n",
    "    # remove station with erroneous behaviour\n",
    "    stations = stations.loc[~(stations.n_events_obs >= 6)]\n",
    "\n",
    "# mask stations with events\n",
    "stations_w_events = (stations.n_events_obs > 0)\n",
    "\n",
    "print('All points')\n",
    "print('----------')\n",
    "print(f'no. reporting points:\\t\\t{stations.shape[0]}')\n",
    "print('no. stations with events:\\t{0}'.format(stations_w_events.sum()))\n",
    "print('no. observed events:\\t\\t{0}'.format(stations.n_events_obs.sum()))\n",
    "\n",
    "# select stations according to catchment area\n",
    "if min_area > area_threshold:\n",
    "    stations_optimize = stations.loc[stations.area >= min_area].index\n",
    "else:\n",
    "    stations_optimize = stations.index\n",
    "\n",
    "print('\\nPoints selected for otimization')\n",
    "print('-------------------------------')\n",
    "print(f'no. reporting points:\\t\\t{len(stations_optimize)}')\n",
    "print('no. stations with events:\\t{0}'.format((stations.loc[stations_optimize, 'n_events_obs'] > 0).sum()))\n",
    "print('no. observed events:\\t\\t{0}'.format(stations.loc[stations_optimize, 'n_events_obs'].sum()))\n",
    "\n",
    "# suffix that will be used when saving plots\n",
    "suffix = f'{min_area}km2_{len(stations_optimize)}points'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c959c12-b037-40a9-aa8e-62cb4e4e2803",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2 Hits, misses and false alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6926cdde-578c-40b7-884d-e493da060be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hits for each station\n",
    "hits_stn = xr.open_mfdataset(f'{path_in}*.nc', combine='nested', concat_dim='id')\n",
    "\n",
    "# extract selected stations\n",
    "hits_stn = hits_stn.sel(id=stations.index.to_list()).compute()\n",
    "\n",
    "# convert to NaN lead times that can't be reached due to model limitations or persistence\n",
    "hits_stn = limit_leadtime(hits_stn)\n",
    "\n",
    "# subset of the 'hits' dataset with the stations selected for the optimization\n",
    "if min_leadtime is None:\n",
    "    hits_opt = hits_stn.sel(id=stations_optimize).sum('id', skipna=False)\n",
    "else:\n",
    "    hits_opt = hits_stn.sel(id=stations_optimize, leadtime=min_leadtime).sum('id', skipna=False)\n",
    "\n",
    "if 'approach' in hits_stn.dims:\n",
    "    dim = 'approach'\n",
    "elif 'model' in hits_stn.dims:\n",
    "    dim = 'model'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53af8555-835c-4d54-a967-b530054a5cb2",
   "metadata": {},
   "source": [
    "## 3 Analysis\n",
    "\n",
    "In this section I will compute the skill of the EFAS predictions in different ways. In all the following sections I will work with three metrics: $recall$, $precision$ and the $f_{beta}$ score. The three metrics are based in the contingency table of hits ($TP$ for true positives), false alarms ($FP$ for false positives) and misses ($FN$ for false negatives).\n",
    "\n",
    "$$recall = \\frac{TP}{TP + FN}$$\n",
    "$$precision = \\frac{TP}{TP + FP}$$\n",
    "$$f_{beta} = \\frac{(1 + \\beta^2) \\cdot TP}{(1 + \\beta^2) \\cdot TP + \\beta^2 \\cdot FN + FP}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfdfc6d-19a1-4cdf-81e2-27dc2c7b3a24",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.2 Compare approaches\n",
    "#### 3.2.1 Import optimize criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff220536-3de4-498a-ae31-14fbb61495f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criteria = {}\n",
    "for beta in betas:\n",
    "    metric = f'f{beta}'\n",
    "    file = glob.glob(f'{path_out}{metric}/*{suffix}.pkl')[0]\n",
    "    opt_crit = pickle.load(open(file, 'rb'))\n",
    "        \n",
    "    # if criteria was fitted for a single lead time value\n",
    "    if min_leadtime is not None:\n",
    "        if dim == 'approach':\n",
    "            criteria['current'] = current_criteria\n",
    "        for key, crit in opt_crit.items():\n",
    "            if metric in crit:\n",
    "                del crit[metric]\n",
    "            criteria[f'{metric}_{key}'] = crit\n",
    "            \n",
    "    # if criteria was fitted for several lead time ranges\n",
    "    else:\n",
    "        for lt, crit1 in opt_crit.items():\n",
    "            if dim == 'approach':\n",
    "                current_criteria['leadtime'] = lt\n",
    "                criteria[f'current_{lt}'] =  current_criteria.copy()\n",
    "            for key2, crit2 in crit1.items():\n",
    "                if metric in crit2:\n",
    "                    del crit2[metric]\n",
    "                crit2['leadtime'] = lt\n",
    "                criteria[f'{metric}_{lt}_{key2}'] = crit2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fef52d5f-9721-4a2c-acaf-4fa7f2659293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del criteria['current_60']\n",
    "#del criteria['current_144']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcae12c-e390-4109-8f94-8b3d362faa82",
   "metadata": {},
   "source": [
    "#### 3.2.2 Compare approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0cdd873-a2fc-4d3c-99b9-ac6616860e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approach</th>\n",
       "      <th>window</th>\n",
       "      <th>KGE</th>\n",
       "      <th>OF</th>\n",
       "      <th>probability</th>\n",
       "      <th>persistence</th>\n",
       "      <th>TP</th>\n",
       "      <th>FN</th>\n",
       "      <th>FP</th>\n",
       "      <th>no_events</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f0.8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>current</th>\n",
       "      <td>1D+1P</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td></td>\n",
       "      <td>0.300</td>\n",
       "      <td>3/3</td>\n",
       "      <td>361</td>\n",
       "      <td>513</td>\n",
       "      <td>230</td>\n",
       "      <td>874</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.610829</td>\n",
       "      <td>0.514656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f0.8_1_deterministic_+_1_probabilistic</th>\n",
       "      <td>1D+1P</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>f0.8</td>\n",
       "      <td>0.650</td>\n",
       "      <td>1/1</td>\n",
       "      <td>388</td>\n",
       "      <td>486</td>\n",
       "      <td>206</td>\n",
       "      <td>874</td>\n",
       "      <td>0.443936</td>\n",
       "      <td>0.653199</td>\n",
       "      <td>0.551710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f0.8_brier_weighted</th>\n",
       "      <td>BW</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>f0.8</td>\n",
       "      <td>0.525</td>\n",
       "      <td>1/1</td>\n",
       "      <td>388</td>\n",
       "      <td>486</td>\n",
       "      <td>196</td>\n",
       "      <td>874</td>\n",
       "      <td>0.443936</td>\n",
       "      <td>0.664384</td>\n",
       "      <td>0.556535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f0.8_model_mean</th>\n",
       "      <td>MM</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>f0.8</td>\n",
       "      <td>0.825</td>\n",
       "      <td>1/1</td>\n",
       "      <td>319</td>\n",
       "      <td>555</td>\n",
       "      <td>148</td>\n",
       "      <td>874</td>\n",
       "      <td>0.364989</td>\n",
       "      <td>0.683084</td>\n",
       "      <td>0.509724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f0.8_member_weighted</th>\n",
       "      <td>MW</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>f0.8</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1/1</td>\n",
       "      <td>389</td>\n",
       "      <td>485</td>\n",
       "      <td>200</td>\n",
       "      <td>874</td>\n",
       "      <td>0.445080</td>\n",
       "      <td>0.660441</td>\n",
       "      <td>0.555540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       approach  window  KGE    OF  \\\n",
       "current                                   1D+1P       1  0.5         \n",
       "f0.8_1_deterministic_+_1_probabilistic    1D+1P       1  0.5  f0.8   \n",
       "f0.8_brier_weighted                          BW       1  0.5  f0.8   \n",
       "f0.8_model_mean                              MM       1  0.5  f0.8   \n",
       "f0.8_member_weighted                         MW       1  0.5  f0.8   \n",
       "\n",
       "                                        probability persistence   TP   FN  \\\n",
       "current                                       0.300         3/3  361  513   \n",
       "f0.8_1_deterministic_+_1_probabilistic        0.650         1/1  388  486   \n",
       "f0.8_brier_weighted                           0.525         1/1  388  486   \n",
       "f0.8_model_mean                               0.825         1/1  319  555   \n",
       "f0.8_member_weighted                          0.500         1/1  389  485   \n",
       "\n",
       "                                         FP  no_events    recall  precision  \\\n",
       "current                                 230        874  0.413043   0.610829   \n",
       "f0.8_1_deterministic_+_1_probabilistic  206        874  0.443936   0.653199   \n",
       "f0.8_brier_weighted                     196        874  0.443936   0.664384   \n",
       "f0.8_model_mean                         148        874  0.364989   0.683084   \n",
       "f0.8_member_weighted                    200        874  0.445080   0.660441   \n",
       "\n",
       "                                            f0.8  \n",
       "current                                 0.514656  \n",
       "f0.8_1_deterministic_+_1_probabilistic  0.551710  \n",
       "f0.8_brier_weighted                     0.556535  \n",
       "f0.8_model_mean                         0.509724  \n",
       "f0.8_member_weighted                    0.555540  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform criteria into a DataFrame\n",
    "summary_criteria = pd.concat([pd.DataFrame(crtr, index=[i]) for i, crtr in criteria.items()], axis=0)\n",
    "if dim == 'approach':\n",
    "    summary_criteria[dim] = [''.join([x[0].upper() for x in app.split('_')]) for app in summary_criteria[dim]]\n",
    "summary_criteria['window'] = window\n",
    "summary_criteria['KGE'] = min_kge\n",
    "summary_criteria['OF'] = [x.split('_')[0] if x.split('_')[0] != 'current' else '' for x in summary_criteria.index]\n",
    "if leadtime is None:\n",
    "    summary_criteria = summary_criteria[[dim, 'window', 'KGE', 'OF', 'probability', 'persistence']]\n",
    "else:\n",
    "    summary_criteria = summary_criteria[[dim, 'window', 'KGE', 'OF', 'leadtime', 'probability', 'persistence']]\n",
    "\n",
    "# compute hits, misses and false alarms\n",
    "if leadtime is None:\n",
    "    #summary_hits = pd.DataFrame({i: hits_opt.sel(leadtime=min_leadtime).sel(crtr).to_pandas() for i, crtr in criteria.items()}).transpose()\n",
    "    summary_hits = pd.DataFrame({i: hits_opt.sel(crtr).to_pandas() for i, crtr in criteria.items()}).transpose()\n",
    "else:\n",
    "    summary_hits = pd.DataFrame({i: hits_opt.sel(crtr).to_pandas() for i, crtr in criteria.items()}).transpose()\n",
    "\n",
    "summary_hits = summary_hits.dropna(axis=0, how='all').astype(int)\n",
    "summary_hits['no_events'] = summary_hits.TP + summary_hits.FN\n",
    "\n",
    "# compute skill\n",
    "summary_hits['recall'] = summary_hits.TP / (summary_hits.TP + summary_hits.FN)\n",
    "summary_hits['precision'] = summary_hits.TP / (summary_hits.TP + summary_hits.FP)\n",
    "for beta in betas:\n",
    "    summary_hits[f'f{beta}'] = (1 + beta**2) * summary_hits.TP / ((1 + beta**2) * summary_hits.TP + beta**2 * summary_hits.FN + summary_hits.FP)\n",
    "\n",
    "# concat criteria, hits and summary data frames\n",
    "summary = pd.concat((summary_criteria, summary_hits), axis=1)\n",
    "if leadtime is None:\n",
    "    summary.sort_values([dim, 'OF'], inplace=True)\n",
    "else:\n",
    "    summary.sort_values([dim, 'leadtime', 'OF'], inplace=True)\n",
    "\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba6aaaae-b9ae-4254-ada1-07807868bab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "summary.to_csv(f'{path_out}skill_by_criteria.csv', float_format='%.3f', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae0b897-ce83-4fb8-af43-3c60f5185c5d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa4af34-de0b-4742-a02c-e1d709c79165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5222b519-ff3a-4713-9735-335e70b62d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "lw = 1\n",
    "reference = None\n",
    "var = 'model'\n",
    "\n",
    "ncols = len(summary[var].unique())\n",
    "\n",
    "fig, axes = plt.subplots(ncols=ncols, figsize=(4.5 * ncols, 4), sharex=True, sharey=True)\n",
    "\n",
    "if reference is not None:\n",
    "    summary_ref = summary.loc[(summary[var] ==  reference) & (summary.OF == '')]\n",
    "for ax, app in zip(axes, summary[var].unique()):\n",
    "    \n",
    "    if reference is not None:\n",
    "        ax.plot(summary_ref.leadtime, summary_ref['f0.8'], c='k', ls='-', lw=lw, label='current')\n",
    "        ax.plot(summary_ref.leadtime, summary_ref.probability, c='k', ls=':', lw=lw, label='current')\n",
    "        ax.fill_between(summary_ref.leadtime, summary_ref.recall, summary_ref.precision, color='k', alpha=.05)\n",
    "    \n",
    "    summary_app = summary.loc[(summary[var] ==  app) & (summary.OF == 'f0.8')]\n",
    "    ax.plot(summary_app.leadtime, summary_app['f0.8'], c='steelblue', ls='-', lw=lw, label=app)\n",
    "    ax.plot(summary_app.leadtime, summary_app.probability, c='steelblue', ls=':', lw=lw, label=app)\n",
    "    ax.fill_between(summary_app.leadtime, summary_app.recall, summary_app.precision, color='steelblue', alpha=.15)\n",
    "    \n",
    "    ax.axvline(60, c='k', ls='-', lw=.5)\n",
    "    ax.set_title(app)\n",
    "    ax.set(xlabel='leadtime(h)')\n",
    "    \n",
    "axes[0].set(xlim=(12, 228), xlabel='leadtime (h)',\n",
    "           ylim=(0, 1), ylabel='f0.8 (-)')\n",
    "xticks = np.arange(12, 229, 24)\n",
    "axes[0].set_xticks(xticks)\n",
    "axes[0].set_xticklabels([str(x) if i %2 == 0 else '' for i, x in enumerate(xticks)]);\n",
    "#ax.xaxis.set_minor_locator(xticks);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3c82fc-77d5-4a92-8264-73320798242f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lw=1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "aux = summary.loc[(summary.approach ==  '1D+1P') & (summary.OF == '')]\n",
    "ax.plot(aux.leadtime, aux['f0.8'], c='k', ls='-', lw=lw, label='current')\n",
    "colours = ['orange', 'slategray', 'steelblue', 'lightsteelblue']\n",
    "for c, approach in zip(colours, summary.approach.unique()):\n",
    "    aux = summary.loc[(summary.approach ==  approach) & (summary.OF == 'f0.8')]\n",
    "    ax.plot(aux.leadtime, aux['f0.8'], c=c, lw=lw, label=approach)\n",
    "ax.axvline(60, c='k', ls=':', lw=lw)\n",
    "ax.set(xlim=(12, 228), xlabel='leadtime(h)',\n",
    "       ylim=(0, 1), ylabel='f0.8 (-)')\n",
    "xticks = np.arange(12, 229, 24)\n",
    "ax.set_xticks(xticks)\n",
    "ax.spines[['top', 'right']].set_visible(False)\n",
    "fig.legend(bbox_to_anchor=[1, .7, .15, .19]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ff4c08-0ad3-4251-b25f-cfb1d1c09633",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../py/')\n",
    "from plot.results import plot_skill_by_variable\n",
    "os.chdir(path_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af3f022-0d94-4464-843f-0da2129bc760",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_skill_by_variable(skill_opt, optimal_criteria=best_criteria, variable='leadtime', reference=min_leadtime, metric=metric, \n",
    "                       current_criteria=current_criteria, optimized_criteria=None,\n",
    "                       xlabel='leadtime ‚â• (h)', loc_text=1, xticks=4, loc_legend=[.87, .8, .2, .1],\n",
    "                       save=None)#f'{path_out}{metric}/skill_vs_leadtime_{suffix}.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90215ae6-c2c1-451e-a5cf-ba642bef271a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332b8475-25cc-411f-984e-80a05e07b50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = hits_opt.sel(model='EUE', leadtime=60, probability=0.65, persistence='1/1').to_pandas()\n",
    "hits['recall'] = hits.TP / hits[['TP', 'FN']].sum()\n",
    "hits['precision'] = hits.TP / hits[['TP', 'FP']].sum()\n",
    "for beta in betas:\n",
    "    hits[f'f{beta}'] = (1 + beta**2) * hits.TP / ((1 + beta**2) * hits.TP + beta**2 * hits.FN + hits.FP)\n",
    "hits.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8d1af3-3680-4e1b-ba67-eb774c609b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = hits_opt.sel(model='EUE', leadtime=60, persistence='1/1').to_pandas()\n",
    "for beta in betas:\n",
    "    hits[f'f{beta}'] = (1 + beta**2) * hits.TP / ((1 + beta**2) * hits.TP + beta**2 * hits.FN + hits.FP)\n",
    "    \n",
    "hits['f0.8']#.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e31980-565b-45c0-9670-ae3726c9f90b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f12cdec-b62f-4e55-842e-668c877bef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hits for each station\n",
    "hits1 = xr.open_mfdataset(f'../results/hits/NWP/leadtime_ranges/window_1/*.nc', combine='nested', concat_dim='id')\n",
    "\n",
    "# extract selected stations\n",
    "hits1 = hits1.sel(id=stations.index.to_list()).compute()\n",
    "\n",
    "# convert to NaN lead times that can't be reached due to model limitations or persistence\n",
    "hits1 = limit_leadtime(hits1)\n",
    "\n",
    "# subset of the 'hits' dataset with the stations selected for the optimization\n",
    "if min_leadtime is None:\n",
    "    hits1 = hits1.sel(id=stations_optimize)#.sum('id', skipna=False)\n",
    "else:\n",
    "    hits1 = hits1.sel(id=stations_optimize, leadtime=min_leadtime)#.sum('id', skipna=False)\n",
    "\n",
    "if 'approach' in hits1.dims:\n",
    "    dim = 'approach'\n",
    "elif 'model' in hits1.dims:\n",
    "    dim = 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d266562a-bd81-4942-96fe-b2ce4fcf616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits2 = xr.open_mfdataset(f'../results/hits/NWP/leadtime_ranges2/window_1/*.nc', combine='nested', concat_dim='id')\n",
    "\n",
    "# extract selected stations\n",
    "hits2 = hits2.sel(id=stations.index.to_list()).compute()\n",
    "\n",
    "# convert to NaN lead times that can't be reached due to model limitations or persistence\n",
    "hits2 = limit_leadtime(hits2)\n",
    "\n",
    "# subset of the 'hits' dataset with the stations selected for the optimization\n",
    "if min_leadtime is None:\n",
    "    hits2 = hits2.sel(id=stations_optimize)#.sum('id', skipna=False)\n",
    "else:\n",
    "    hits2 = hits2.sel(id=stations_optimize, leadtime=min_leadtime)#.sum('id', skipna=False)\n",
    "\n",
    "if 'approach' in hits2.dims:\n",
    "    dim = 'approach'\n",
    "elif 'model' in hits2.dims:\n",
    "    dim = 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c588a115-32ee-4450-83e2-7581b3bcbbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = dict(model = 'EUD',\n",
    "            leadtime = 60,\n",
    "            probability = 0.05,\n",
    "            persistence = '3/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411e19ec-fe42-4dd2-b832-8a0f0fa4cd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "stns = hits1.where(hits1.sel(crit)['TP'] != hits2.sel(crit)['TP'], drop=True).id.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60819b73-7304-4a76-91e7-40895be911ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits1.sel(id=stns).sel(crit).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38de185d-9764-4400-bb01-2062c5f72340",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits2.sel(id=stns).sel(crit).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d4109a-6d7c-4b76-bc02-71b1cd104168",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations.loc[[695, 778]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb12f772-139e-4527-a383-7c1dc63e228e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360b7fcc-29f3-4c50-82c0-8fbd3a31c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits2.sel(crit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b443852b-a235-4ba7-9e1d-b5806894e96a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6948ee90-8050-427a-8ecb-2496b022b118",
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = 60\n",
    "OF = 'f0.8'\n",
    "\n",
    "df = summary.loc[(summary.leadtime == lt) & (summary.OF == OF)].set_index('approach')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f342c50-1240-4733-8fea-3e077af9d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['probability', 'f0.8', 'recall', 'precision']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1487196-fffe-4ce8-8c14-4633d47070a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9d0e97d-8de9-46c2-b760-b8ab47f2ad72",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59353dd6-c6bb-4a4a-8b0b-21ad515c7461",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dtype=float)\n",
    "df['recall'] = np.arange(.1, .91, .1)\n",
    "df['precision'] = np.arange(.1, .91, .1)[::-1]\n",
    "\n",
    "for b in [.8, 1, 1.25]:\n",
    "    df[f'f{b}'] = (1 + b**2) * df.precision * df.recall / (b**2 * df.precision + df.recall)\n",
    "\n",
    "    \n",
    "df.drop(['recall', 'precision'], axis=1).plot()\n",
    "df.plot()\n",
    "\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9944faeb-6e29-432f-ac18-c741199f178c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f15463b-12e9-4f6e-a352-0b0ddf9e580d",
   "metadata": {},
   "source": [
    "```Python\n",
    "hits_stn\n",
    "\n",
    "hits_1D1P = hits_stn.sel(approach='1_deterministic_+_1_probabilistic',\n",
    "                         probability=0.375,\n",
    "                         persistence='1/1',\n",
    "                         leadtime=min_leadtime)\n",
    "\n",
    "hits_BW = hits_stn.sel(approach='brier_weighted',\n",
    "                       probability=0.375,\n",
    "                       persistence='1/1',\n",
    "                         leadtime=min_leadtime)\n",
    "\n",
    "hits_diff = hits_BW - hits_1D1P\n",
    "\n",
    "tp = hits_diff['TP'].to_pandas()\n",
    "\n",
    "tp[tp == 0]\n",
    "\n",
    "tp[tp < 0]\n",
    "\n",
    "stations[tp > 0].value_counts('river')\n",
    "\n",
    "stations[tp > 0].value_counts('catchment')\n",
    "\n",
    "stations[tp > 0][stations.catchment == 'Rhine'].sort_values(['catchment', 'subcatchment', 'river'])\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
