{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fd5f453-13c1-47c1-ad27-8af80b47ee08",
   "metadata": {},
   "source": [
    "# Forecast: exceedance - Loire\n",
    "***\n",
    "\n",
    "**Author**: Chus Casado<br>\n",
    "**Date**: 27-01-2023<br>\n",
    "\n",
    "**Introduction**:<br>\n",
    "\n",
    "\n",
    "**Questions**:<br>\n",
    "\n",
    "\n",
    "**Tasks to do**:<br>\n",
    "\n",
    "**Interesting links**<br>\n",
    "[Pythonic way to perform statistics across multiple variables with Xarray](https://towardsdatascience.com/pythonic-way-to-perform-statistics-across-multiple-variables-with-xarray-d0221c78e34a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4ee7a0f-f62b-4a8b-8147-c46a2e2471ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path_root = os.getcwd()\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.chdir('../py/')\n",
    "from notifications import *\n",
    "os.chdir(path_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ca1667-e5d2-45fb-83a1-647f9c9c4e7a",
   "metadata": {},
   "source": [
    "## 1 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f59d008-a915-4cdb-90e1-48ddd1bcb6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment = 'Loire'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b284a86-2d64-4907-a259-e3c67b6de2d5",
   "metadata": {},
   "source": [
    "### 1.1 Stations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ad2ba6a-e095-4c1c-8f2c-3738dee497be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. stations:\t27\n"
     ]
    }
   ],
   "source": [
    "# load selected points\n",
    "stations = pd.read_csv(f'results/{catchment}/points_selected.csv', index_col='station_id')\n",
    "print('no. stations:\\t{0}'.format(stations.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ec6de5-35d0-4e78-a74d-0b9cc867050c",
   "metadata": {},
   "source": [
    "### 1.2 Discharge forecast\n",
    "\n",
    "#### List available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93123b35-f171-464a-b717-c3dfde717967",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_forecast = 'E:/casadje/Documents/skill_assessment/data/CDS/forecast/'\n",
    "\n",
    "models = ['COS', 'DWD', 'EUD', 'EUE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab2a31eb-ecdc-4dac-8a65-15e1b212b1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mising files: {'COS': [], 'DWD': [], 'EUD': [], 'EUE': []}\n",
      "COS:\t730 files\n",
      "DWD:\t730 files\n",
      "EUD:\t730 files\n",
      "EUE:\t730 files\n"
     ]
    }
   ],
   "source": [
    "# list files\n",
    "fore_files = {model: [] for model in models}\n",
    "for year in [2020, 2021, 2022]:\n",
    "    for month in range(1, 13):    \n",
    "        # list files\n",
    "        for model in models:\n",
    "            fore_files[model] += glob.glob(f'{path_forecast}{model}/{year}/{month:02d}/*.nc')\n",
    "\n",
    "# count files and check if all are avaible\n",
    "n_files = pd.Series(data=[len(fore_files[model]) for model in models], index=models)\n",
    "\n",
    "# list of forecast from the beginning to the end of the data\n",
    "start, end = datetime(1900, 1, 1), datetime(2100, 1, 1)\n",
    "for model in models:\n",
    "    st, en = [datetime.strptime(fore_files[model][step][-13:-3], '%Y%m%d%H') for step in [0, -1]]\n",
    "    start = max(st, start)\n",
    "    end = min(en, end)\n",
    "dates = pd.date_range(start, end, freq='12h')\n",
    "\n",
    "# find missing files\n",
    "if any(n_files != len(dates)):\n",
    "    missing = {}\n",
    "    for model in models:\n",
    "        filedates = [datetime.strptime(file[-13:-3], '%Y%m%d%H') for file in fore_files[model]]    \n",
    "        missing[model] = [date for date in dates if date not in filedates]\n",
    "    print('mising files:', missing)\n",
    "\n",
    "# trim files to the period where all models are available\n",
    "for model in models:\n",
    "    fore_files[model] = [file for file in fore_files[model] if start <= datetime.strptime(file[-13:-3], '%Y%m%d%H') <= end]\n",
    "    print('{0}:\\t{1} files'.format(model, len(fore_files[model])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d30099-20a5-41c6-8c8d-d80751c43d8a",
   "metadata": {},
   "source": [
    "## 2 Analysis\n",
    "\n",
    "### 2.1 Reforecast data: exceedance probability\n",
    "\n",
    "This section will iteratively (station by station) load all the available forecast and compute the probability of exceeding the discharge threshold for each of the meteorological forcings. The result will be a NetCDF file for each station that contains the exceedance probability. These files will be later used in the skill assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8412297-882a-40cb-a3ed-aafb694b5f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station 2770 (  27 of   27) - EUE\r"
     ]
    }
   ],
   "source": [
    "n_stations = stations.shape[0]\n",
    "path = f'../data/exceedance/forecast/'\n",
    "\n",
    "for i, stn in enumerate(stations.index):    \n",
    "    \n",
    "    file = f'{stn:04d}.nc'\n",
    "    if file in os.listdir(path):\n",
    "        print(f'File {file} already exists')\n",
    "        continue\n",
    "            \n",
    "    dct = {}\n",
    "    for model in models:\n",
    "        \n",
    "        print(f'Station {stn:>4d} ({i+1:>4d} of {n_stations:>4d}) - {model}', end='\\r')\n",
    "        \n",
    "        # compute exceedance of discharge threshold\n",
    "        exceedance = compute_exceedance(fore_files[model], str(stn), stations.loc[stn, 'rl5'])\n",
    "        # limit to 10 days leadtime\n",
    "        if len(exceedance.leadtime) > 40:\n",
    "            exceedance = exceedance.isel(leadtime=slice(0, 40))\n",
    "        # if probabilistic, compute probability of exceedance\n",
    "        if 'member' in exceedance.dims:\n",
    "            dct[model] = exceedance.mean('member')\n",
    "        else:\n",
    "            dct[model] = exceedance\n",
    "    \n",
    "    # convert exceedance data into a Dataset\n",
    "    ds = xr.Dataset(dct, coords={'forecast': dct['EUE'].forecast, 'leadtime': dct['EUE'].leadtime})\n",
    "\n",
    "    # convert the dataset into a DataArray in which models is a dimension instead of different variables\n",
    "    da_list = [ds[model].expand_dims('model', axis=0).assign_coords(model=[model]).rename('exceedance') for model in models]\n",
    "    da = xr.merge(da_list)['exceedance']\n",
    "    \n",
    "    # export as NetCDF\n",
    "    da.to_netcdf(f'{path}{file}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
