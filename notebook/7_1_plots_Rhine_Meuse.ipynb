{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fd5f453-13c1-47c1-ad27-8af80b47ee08",
   "metadata": {},
   "source": [
    "# Presentation plots\n",
    "***\n",
    "\n",
    "**Author**: Chus Casado<br>\n",
    "**Date**: 27-02-2023<br>\n",
    "\n",
    "**Introduction**:<br>\n",
    "\n",
    "\n",
    "**Questions**:<br>\n",
    "\n",
    "\n",
    "**Tasks to do**:<br>\n",
    "\n",
    "**Interesting links**<br>\n",
    "[Pythonic way to perform statistics across multiple variables with Xarray](https://towardsdatascience.com/pythonic-way-to-perform-statistics-across-multiple-variables-with-xarray-d0221c78e34a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ee7a0f-f62b-4a8b-8147-c46a2e2471ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path_root = os.getcwd()\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas as gpd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.chdir('../py/')\n",
    "from computations import *\n",
    "from plots import *\n",
    "os.chdir(path_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7227b985-50c6-4182-a082-6aeaf2efa098",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_threshold = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b482260-6c53-412e-b1d7-93ac3191b846",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment = 'Rhine'\n",
    "catchments = ['Rhine', 'Meuse / Maas']\n",
    "\n",
    "# path where results will be saved\n",
    "path_out = f'../results/skill/explanation/{catchment}/'\n",
    "if os.path.exists(path_out) is False:\n",
    "    os.makedirs(path_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49413b2-588e-4912-9da4-773e7ed2b0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by the number of members\n",
    "path_in = '../data/'\n",
    "weights_member = xr.open_dataarray(f'{path_in}weights_member.nc')\n",
    "# by the Brier score\n",
    "weights_brier = xr.open_dataarray(f'{path_in}weights_brier.nc', engine='netcdf4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea61466-844d-4fa7-b038-f2efccb000d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criteria\n",
    "min_leadtime = 60\n",
    "file = f'{path_out}/best_criteria_by_approach.pkl'\n",
    "with open (file, 'rb') as f:\n",
    "    best_criteria = pickle.load(f)\n",
    "\n",
    "for approach, dct in best_criteria.items():\n",
    "    try:\n",
    "        dct['persistence'] = [int(x) for x in str(dct['persistence']).split('/')]\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61bc765-753c-4298-8dcb-6fda42fd4354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stn = 117\n",
    "# start, end = datetime(2021, 1, 10), datetime(2021, 2, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c8d5ed-9914-41b9-9117-f6818a3ea1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stn = 118\n",
    "# start, end = datetime(2021, 1, 10), datetime(2021, 2, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e9ef43-a2a4-4fde-ad4f-805e2055451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stn = 119\n",
    "# start, end = datetime(2021, 1, 10), datetime(2021, 2, 28)\n",
    "# start, end = datetime(2022, 10, 1), datetime(2022, 10, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f8fecc-e8c2-45ef-9b72-1d9d0b34e057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stn = 2022\n",
    "# start, end = datetime(2021, 5, 20), datetime(2021, 7, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9fa27c-ac57-4423-a016-a6b7f4089cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stn = 5225\n",
    "# start, end = datetime(2021, 7, 1), datetime(2021, 7, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c09eb1a-d603-4dbc-8ca2-b486bcce2327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stn = 356\n",
    "# start, end = datetime(2021, 7, 1), datetime(2021, 8, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64051430-3d34-415b-bc82-815a37264e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stn = 356\n",
    "# start, end = datetime(2021, 7, 1), datetime(2021, 8, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12121659-f1fd-4d36-b84b-dfba5f23918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stn = 337\n",
    "# start, end = datetime(2021, 6, 1), datetime(2021, 7, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6da202-bb2b-4160-9440-d9b5fabad9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stn = 359\n",
    "# start, end = datetime(2021, 6, 15), datetime(2021, 7, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ead081e-7048-4bef-8428-b19fda69acd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stn = 931\n",
    "# start, end = datetime(2021, 6, 15), datetime(2021, 7, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64886e4e-d113-4355-80f9-31d1e7297fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stn = 2562\n",
    "# start, end = datetime(2022, 8, 1), datetime(2022, 8, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a144f8a7-5f89-4ded-885b-0caf7f113d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stn = 2562\n",
    "# start, end = datetime(2021, 12, 10), datetime(2022, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b2edb9-f6f8-44bc-889f-65346cb90141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stn = 2766\n",
    "# start, end = datetime(2021, 7, 1), datetime(2021, 7, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50261e97-1453-4d88-9ffd-f126f9da3506",
   "metadata": {},
   "outputs": [],
   "source": [
    "stn = 2946\n",
    "start, end = datetime(2022, 3, 20), datetime(2022, 4, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ce7fc4-679c-42e8-9044-52381f2555b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stn = 2946\n",
    "start, end = datetime(2021, 7, 1), datetime(2021, 7, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f531a9-5429-4931-b9c1-3923b651c7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stn = 2946\n",
    "start, end = datetime(2021, 7, 1), datetime(2021, 7, 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aeb21e-8931-4ce4-8a2f-5751b700c062",
   "metadata": {},
   "source": [
    "**Nahe subcatchment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39df77c5-c31b-4076-ba15-7f9d7dae951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stn = 114 # 110\n",
    "start, end = datetime(2021, 7, 1), datetime(2021, 7, 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312bc9d8-ff8c-4747-b85e-ed75e05450aa",
   "metadata": {},
   "source": [
    "**Neckar subcatchment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e81799-fd0b-4b42-a9cc-35ae3da60788",
   "metadata": {},
   "outputs": [],
   "source": [
    "stn = 931 #33\n",
    "start, end = datetime(2021, 6, 1), datetime(2021, 7, 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88460d9f-4d3e-4814-8bbf-272a65e23116",
   "metadata": {},
   "source": [
    "**Main**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2ae757-b05f-46f7-916c-e232f576adf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stn = 119# 117# 118# \n",
    "start, end = datetime(2021, 1, 15), datetime(2021, 2, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0af3c09-0a2a-4f52-91ab-423dfb7a9be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stn = 119# 117# 118# \n",
    "start, end = datetime(2022, 10, 1), datetime(2022, 11, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e42095-4f7b-41f9-b24f-e8c8867cf346",
   "metadata": {},
   "outputs": [],
   "source": [
    "stn = 39# 34# 2929\n",
    "start, end = datetime(2021, 6, 20), datetime(2021, 7, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9300c1b-47cc-46b8-a57e-751d06b08a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end = datetime(2021, 6, 1), datetime(2021, 8, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ec6de5-35d0-4e78-a74d-0b9cc867050c",
   "metadata": {},
   "source": [
    "## 1 Discharge forecast\n",
    "\n",
    "#### List available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1132a46-020a-4564-b164-09953a40605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_forecast = 'E:/casadje/Documents/skill_assessment/data/CDS/forecast/'\n",
    "\n",
    "# list files\n",
    "fore_files = {model: [] for model in models}\n",
    "for year in [2020, 2021, 2022]:\n",
    "    for month in range(1, 13):    \n",
    "        # list files\n",
    "        for model in models:\n",
    "            fore_files[model] += glob.glob(f'{path_forecast}{model}/{year}/{month:02d}/*.nc')\n",
    "\n",
    "# count files and check if all are avaible\n",
    "n_files = pd.Series(data=[len(fore_files[model]) for model in models], index=models)\n",
    "\n",
    "# list of forecast from the beginning to the end of the data\n",
    "for model in models:\n",
    "    st, en = [datetime.strptime(fore_files[model][step][-13:-3], '%Y%m%d%H') for step in [0, -1]]\n",
    "    start = max(st, start)\n",
    "    end = min(en, end)\n",
    "dates = pd.date_range(start, end, freq='12h')\n",
    "\n",
    "# find missing files\n",
    "if any(n_files != len(dates)):\n",
    "    missing = {}\n",
    "    for model in models:\n",
    "        filedates = [datetime.strptime(file[-13:-3], '%Y%m%d%H') for file in fore_files[model]]    \n",
    "        missing[model] = [date for date in dates if date not in filedates]\n",
    "    print('mising files:', missing)\n",
    "\n",
    "# trim files to the period where all models are available\n",
    "for model in models:\n",
    "    fore_files[model] = [file for file in fore_files[model] if start <= datetime.strptime(file[-13:-3], '%Y%m%d%H') <= end]\n",
    "    print('{0}:/t{1} files'.format(model, len(fore_files[model])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79709b93-c32f-4bac-81b0-69a5ffb6cc57",
   "metadata": {},
   "source": [
    "## 2 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356c2fd7-ae1c-434c-b947-08c417f1bb8b",
   "metadata": {},
   "source": [
    "### 2.1 Stations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a339f39-99d5-44c8-bf8d-e905c0bbb6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load table of fixed reporing points\n",
    "area_threshold = 500\n",
    "# stations = pd.read_parquet(f'../results/reporting_points/reporting_points_over_{area_threshold}km2.parquet')\n",
    "stations = pd.read_parquet(f'../results/reporting_points/reporting_points_over_{area_threshold}km2_Rhine_Meuse.parquet')\n",
    "stations = stations.loc[stations.catchment.isin(catchments),:]\n",
    "print(f'no. reporting points in the {catchment} catchment:\\t{stations.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdc9d37-33e9-4928-8e7f-e5d590fe621b",
   "metadata": {},
   "source": [
    "### Reanalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d66d93-0854-450b-95bf-fc4da5830677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load probability of exceeding the discharge threshold in the REANALYSIS data\n",
    "Qobs = pd.read_parquet(f'../data/discharge/reanalysis/EFAS_discharge_reanalysis.parquet')\n",
    "Qobs.columns = Qobs.columns.astype(int)\n",
    "Qobs = Qobs[stations.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a12ea04-bb76-4867-9054-44bbb40dc6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hydrograph(stn, obs, models, fore_files, thresholds, verbose=False, save=None, **kwargs):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    start, end = obs.index[0], obs.index[-1]\n",
    "    ymax = kwargs.get('ymax', thresholds.rl20 * 2)\n",
    "    fs = kwargs.get('fontsize', 11)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=len(models), figsize=kwargs.get('figsize', (16, 4 * len(models))),\n",
    "                             sharex=True, sharey=True, constrained_layout=True)\n",
    "\n",
    "    for ax, model in zip(axes, models):\n",
    "        \n",
    "        # plot forecasted discharge\n",
    "        for file in fore_files[model]:\n",
    "            \n",
    "            if verbose:\n",
    "                print(f'{model}\\t{file}', end='\\r')\n",
    "\n",
    "            # open dataaray with dicharge data\n",
    "            dis = xr.open_dataarray(file).isel(time=slice(1, None))\n",
    "            dis['time'] = dis.time - np.timedelta64(6, 'h')\n",
    "            # limit the forecast to its maximum leadtime\n",
    "            if len(dis.time) > models[model]['leadtimes']:\n",
    "                dis = dis.isel(time=slice(None, models[model]['leadtimes']))\n",
    "            dis_stn = dis.sel(stations=str(stn))\n",
    "\n",
    "            if 'member' in dis_stn.dims:\n",
    "                for member in dis_stn.member.data:\n",
    "                    ax.plot(dis_stn.time, dis_stn.sel(member=member), c='steelblue', lw=.33, alpha=.15)\n",
    "            else:\n",
    "                ax.plot(dis_stn.time, dis_stn, c='steelblue', lw=.5, alpha=.33)\n",
    "    \n",
    "        # plot observed discharge\n",
    "        ax.plot(obs.index, obs, c='k', lw=.8, zorder=5)\n",
    "\n",
    "        ax.set(xlim=(start + timedelta(days=10), end), ylim=(0, ymax))\n",
    "        ax.set_ylabel('Q (m3/s)', fontsize=fs + 1)\n",
    "        xticks = pd.date_range(start, end, freq=kwargs.get('freq', 'd')).date\n",
    "        ax.tick_params(labelsize=fs)\n",
    "        ax.set_xticks(xticks, labels=xticks, rotation=90)\n",
    "\n",
    "        if thresholds is not None:\n",
    "            ax.fill_between(pd.date_range(start, end), thresholds['rl1.5'], thresholds['rl2'], color='green', edgecolor=None, alpha=.1, zorder=0, label='1.5-year')\n",
    "            ax.fill_between(pd.date_range(start, end), thresholds['rl2'], thresholds['rl5'], color='yellow', edgecolor=None, alpha=.1, zorder=0, label='2-year')\n",
    "            ax.fill_between(pd.date_range(start, end), thresholds['rl5'], thresholds['rl20'], color='red', edgecolor=None, alpha=.1, zorder=0, label='5-year')\n",
    "            ax.fill_between(pd.date_range(start, end), thresholds['rl20'], ymax, color='mediumpurple', edgecolor=None, alpha=.1, zorder=0, label='20-year')\n",
    "\n",
    "        ax.set_title(model, fontsize=fs + 2);\n",
    "\n",
    "        if verbose:\n",
    "            print()\n",
    "\n",
    "    if 'title' in kwargs:\n",
    "        fig.suptitle(kwargs['title'], fontsize=fs + 3);\n",
    "    \n",
    "    if save is not None:\n",
    "        plt.savefig(save, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4223aa3-e935-438d-94a4-d2e0274263b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stn in [1977, 1360, 5225, 5226]:\n",
    "    \n",
    "    if (stations.loc[stn, ['TP', 'FN', 'FP']] == 0).all():\n",
    "        continue\n",
    "    \n",
    "    subcatchment = stations.loc[stn, 'subcatchment']\n",
    "    path = f'{path_out}{subcatchment}/'\n",
    "    if os.path.exists(path) is False:\n",
    "        os.makedirs(path)\n",
    "    thresholds = stations.loc[stn, ['rl1.5', 'rl2', 'rl5', 'rl20']].squeeze()\n",
    "    title = '{0} - {1} ({2})'.format(stn, *stations.loc[stn, ['name', 'subcatchment']])\n",
    "\n",
    "    # plot observed vs forecasted hydrographs\n",
    "    \n",
    "    plot_hydrograph(stn, Qobs.loc[start:end, stn], models, fore_files, thresholds, title=title, freq='2d', fontsize=20,\n",
    "                save=f'{path}{stn:>04}_0_hydrograph_presentation.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f932d13-e36c-43b7-ac63-10128518f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(da, obs, probability, persistence=(1, 1), min_leadtime='all', center=True, w=5, save=None, **kwargs):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    cmap = kwargs.get('cmap', 'magma_r')\n",
    "    norm = kwargs.get('norm', None)\n",
    "    \n",
    "    fig = plt.figure(figsize=kwargs.get('figsize', (16, 6.6)), constrained_layout=True)\n",
    "    height_ratios = [len(da.leadtime)] * 2 + [1] * 3\n",
    "    gs = fig.add_gridspec(nrows=len(height_ratios), height_ratios=height_ratios)\n",
    "    \n",
    "    # total probability\n",
    "    plot_DataArray(da, ytick_step=2, cbar=False, cbar_kws={'label': 'probability'}, title='total probability',\n",
    "                   xticklabels=[], xlabel=None, ylabel='leadtime (h)', cmap=cmap, norm=norm, ax=fig.add_subplot(gs[0]))\n",
    "    \n",
    "    # exceedance over probability threshold\n",
    "    plot_DataArray(da > probability, ytick_step=2, cbar=True, cbar_kws={'label': 'probability'}, title='exceedance', xlabel=None,\n",
    "                   xticklabels=[], ylabel='leadtime (h)', cmap=cmap, norm=norm, ax=fig.add_subplot(gs[1]))\n",
    "    \n",
    "    # predicted events\n",
    "    pred = compute_events(da, probability=probability, persistence=persistence, min_leadtime=min_leadtime)\n",
    "    plot_prediction.pred = pred\n",
    "    plot_DataArray(pred, title='predicted', xticklabels=[], cmap=cmap, norm=norm, cbar=False, ax=fig.add_subplot(gs[2]))\n",
    "    \n",
    "    # buffered, predicted events\n",
    "    buff = buffer_events(pred, center=center, w=w)\n",
    "    plot_prediction.buff = buff\n",
    "    plot_DataArray(buff, title='buffered', xticklabels=[], cmap=cmap, norm=norm, cbar=False, ax=fig.add_subplot(gs[3]))\n",
    "\n",
    "    # observed events\n",
    "    plot_DataArray(obs, xlabel='datetime', xtick_step=4, title='observed', cmap=cmap, norm=norm, cbar=False, ax=fig.add_subplot(gs[4]))\n",
    "    \n",
    "    if 'title' in kwargs:\n",
    "        fig.suptitle(kwargs['title'], fontsize=13);\n",
    "    \n",
    "    if save is not None:\n",
    "        plt.savefig(save, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682221e8-6514-4419-b813-18d824af375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_exceedance_probability(exceedance, obs, models, save=None, **kwargs):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize=kwargs.get('figsize', (16, 10)), constrained_layout=True)\n",
    "    height_ratios = [int(dct['leadtimes'] / 2) for label, dct in models.items()] + [1]\n",
    "    gs = fig.add_gridspec(nrows=len(height_ratios), height_ratios=height_ratios)\n",
    "\n",
    "    # exceedance matrix of every model\n",
    "    for i, (label, dct) in enumerate(models.items()):\n",
    "        ax = fig.add_subplot(gs[i])\n",
    "        ylabel = 'leadtime (h)'\n",
    "        if i == 2:\n",
    "            cbar = True\n",
    "        else:\n",
    "            cbar = False\n",
    "        plot_DataArray(exceedance.sel(model=label).isel(leadtime=slice(0, int(models[label]['leadtimes'] / 2))),\n",
    "                       xtick_step=4, ytick_step=2, cbar=cbar, cbar_kws={'label': 'probability'}, title=label, xticklabels=[], xlabel=None,\n",
    "                       ylabel=ylabel, ax=ax, cmap=cmap_p, norm=norm_p)\n",
    "        \n",
    "    # observed events\n",
    "    plot_DataArray(obs, xlabel='datetime', xtick_step=4, title='observed', cmap=cmap_p, norm=norm_p, cbar=False, ax=fig.add_subplot(gs[-1]))\n",
    "\n",
    "    if 'title' in kwargs:\n",
    "        fig.suptitle(kwargs['title']);\n",
    "\n",
    "    if save is not None:\n",
    "        plt.savefig(save, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c9eed4-137c-424e-8db1-9e5151d8f2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stn in tqdm_notebook(stations.index):\n",
    "    \n",
    "    if (stations.loc[stn, ['TP', 'FN', 'FP']] == 0).all():\n",
    "        continue\n",
    "    \n",
    "    subcatchment = stations.loc[stn, 'subcatchment']\n",
    "    path = f'{path_out}{subcatchment}/'\n",
    "    if os.path.exists(path) is False:\n",
    "        os.makedirs(path)\n",
    "    thresholds = stations.loc[stn, ['rl1.5', 'rl2', 'rl5', 'rl20']].squeeze()\n",
    "    title = '{0} - {1} ({2})'.format(stn, *stations.loc[stn, ['name', 'subcatchment']])\n",
    "\n",
    "    # plot observed vs forecasted hydrographs\n",
    "    \n",
    "    plot_hydrograph(stn, Qobs.loc[start:end, stn], models, fore_files, thresholds, title=title,\n",
    "                save=f'{path}{stn:>04}_0_hydrograph.jpg')\n",
    "    \n",
    "    # observed events\n",
    "    obs = (Qobs[stn] > thresholds.rl5).astype(int).loc[start + timedelta(days=10):end]\n",
    "    # print('no. observed events:\\t{0}'.format((np.diff(obs) == 1).sum()))\n",
    "    obs = xr.DataArray(obs, coords={'datetime': obs.index})\n",
    "\n",
    "    # Exceendance probability\n",
    "\n",
    "    exceedance = xr.open_dataarray(f'{path_in}exceedance/forecast/{stn:>04d}.nc')\n",
    "    exceedance = exceedance.sel(forecast=slice(start, end))\n",
    "    exceedance = reshape_DataArray(exceedance)\n",
    "    exceedance = exceedance.sel(datetime=slice(start + timedelta(days=10), end))\n",
    "\n",
    "    cmap_p, norm_p = create_cmap('magma_r', np.arange(0, 1.01, .05))\n",
    "    plot_exceedance_probability(exceedance, obs, models, cmap=cmap_p, norm=norm_p, title=title,\n",
    "                                save=f'{path}{stn:>04}_1_exceedance_probability.jpg')\n",
    "\n",
    "    # Current: 1 deterministic & 1 probabilistic\n",
    "    \n",
    "    # exceedance according to current criteria\n",
    "    probability, persistence = [best_criteria['current'][key] for key in ['probability', 'persistence']]\n",
    "    deterministic = (exceedance.sel(model=['EUD', 'DWD']) >= probability).any('model')\n",
    "    probabilistic = (exceedance.sel(model=['EUE', 'COS']) >= probability).any('model')\n",
    "    current = (deterministic & probabilistic).sel(leadtime=slice(min_leadtime, None))\n",
    "    plot_prediction(current, obs, probability, persistence, min_leadtime,\n",
    "                    cmap=cmap_p, norm=norm_p, title=f'{title} - Pthreshold = {probability} - persistence = {persistence}',\n",
    "                    save=f'{path}{stn:>04}_2_current.jpg')\n",
    "\n",
    "    # Model mean\n",
    "\n",
    "    # exceedance according to mean over models\n",
    "    probability, persistence = [best_criteria['model_mean'][key] for key in ['probability', 'persistence']]\n",
    "    model_mean = exceedance.mean('model', skipna=True).sel(leadtime=slice(min_leadtime, None))\n",
    "    plot_prediction(model_mean, obs, probability, persistence, min_leadtime,\n",
    "                    cmap=cmap_p, norm=norm_p, title=f'{title} - Pthreshold = {probability} - persistence = {persistence}',\n",
    "                    save=f'{path}{stn:>04}_3_model_mean.jpg')\n",
    "\n",
    "    # Weighted by no. members\n",
    "\n",
    "    # exceedance according to the mean over models weighted by the number of members\n",
    "    probability, persistence = [best_criteria['member_weighted'][key] for key in ['probability', 'persistence']]\n",
    "    member_weighted = exceedance.weighted(weights_member).mean('model', skipna=True).sel(leadtime=slice(min_leadtime, None))\n",
    "    plot_prediction(member_weighted, obs, probability, persistence, min_leadtime,\n",
    "                    cmap=cmap_p, norm=norm_p, title=f'{title} - Pthreshold = {probability} - persistence = {persistence}',\n",
    "                    save=f'{path}{stn:>04}_4_member_weighted.jpg')\n",
    "\n",
    "    # Weighted by performance\n",
    "\n",
    "    # exceedance according to the mean over models weighted by the number of members\n",
    "    probability, persistence = [best_criteria['brier_weighted'][key] for key in ['probability', 'persistence']]\n",
    "    brier_weighted = exceedance.weighted(weights_brier.fillna(0)).mean('model', skipna=True).sel(leadtime=slice(min_leadtime, None))\n",
    "    plot_prediction(brier_weighted, obs, probability, persistence, min_leadtime,\n",
    "                    cmap=cmap_p, norm=norm_p, title=f'{title} - Pthreshold = {probability} - persistence = {persistence}',\n",
    "                    save=f'{path}{stn:>04}_5_brier_weighted.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3179727-10d9-484b-b767-411dafbff02d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e5e514-2514-44e1-b266-3ead764c18de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0f784c-d6d9-4299-a416-468057a8b678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6212d92-0fb0-47e2-ab7a-8b737dd39c12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb4b1e4-6285-4e69-8f5e-e9d8330928ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f72e534-6786-422b-b87a-4f8952ffd00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b198fb2-108a-478b-9ab7-2a2607f21fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from future.utils import listitems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219c936d-2742-4d0c-bc2f-a1a7a25b7bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.variables[value].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5356f06d-bf49-4688-9acb-db5c2eece402",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = 'E:/casadje/GitHub/mekong_usecase/maps/general/'\n",
    "\n",
    "mask = xr.open_dataset(f'{ruta}my_mask.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86c0469-5dd9-4ca7-85a6-8f6b6150b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = xr.open_dataset(file)\n",
    "nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f47216-d089-40ba-a0dc-4164b7b81bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d6c9e-52d8-4c64-8c3e-08b076dbed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629b7efd-a382-43df-a37a-2703bdacdeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131f5a47-c20a-4cd9-b306-cd7383efe84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = 'E:/casadje/GitHub/mekong_usecase/maps/' #land_cover/'\n",
    "ruta = 'E:/casadje/jrcbox/Documents/Lisflood/users/Kraatz/upper_rhine/maps/'\n",
    "for file in glob.glob(f'{ruta}soil_hydraulics/*.nc'):\n",
    "    nc = xr.open_dataset(file)\n",
    "    print(file.split('\\\\')[-1])\n",
    "    print(list(nc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0ef083-0b95-4406-925e-c4f1b3b64cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = 'E:/casadje/GitHub/mekong_usecase/maps/' #land_cover/'\n",
    "ruta = 'E:/casadje/jrcbox/Documents/Lisflood/users/Kraatz/upper_rhine/maps/'\n",
    "for file in glob.glob(f'{ruta}soil_hydraulics/*.nc'):\n",
    "    nc = Dataset(file)\n",
    "    print(file.split('\\\\')[-1])\n",
    "    print([item[0] for item in listitems(nc.variables)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73774c8b-fc22-4533-b5a0-31be3d0b37b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = Dataset(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602c6ee6-1f1e-4050-a1b8-28bd1cc73563",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(nc.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6225d9-022e-4902-9fb6-0e3e784dd76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "listitems(nc.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06351485-b62e-4df9-bcb8-9c8ef88dc6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = listitems(nc.variables)[-1][0]\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952f1a04-5145-4194-b065-6840322487ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc.variables[value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a18e46-a395-4aff-a53a-a58933f58d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_rows, nr_cols =  nc.variables[value].shape\n",
    "nr_rows, nr_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0142154c-d23a-48e5-be23-a9ee6b2c46c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc.variables[value].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a9ec79-0713-4362-9869-aa1df18c9ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a8c5a3-b684-4e6b-9f2f-05d51c7e357c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0dd947-7cb6-49a1-841b-958113841f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44219f3e-2ef9-48d2-aabd-b63e1072b70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = xr.open_dataset('E:/casadje/Downloads/area_FDv4_01min.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb1b6ae-eea0-4686-8a13-7f8264a7ee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = Dataset('E:/casadje/Downloads/area_FDv4_01min.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119eb39b-460f-4ba9-b059-97f14fe01d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.variables['wgs_1984']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44102ba0-d5b9-4952-9647-87bcbb3c3600",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.variables['area'][0:nr_rows, 0:nr_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23de60bf-92a6-48f5-9be1-c6c08dc72ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "exc_o_thr = exceedance >= .3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754e5804-7530-42e8-ad6a-458c6eb22c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap_eot, norm_eot = create_cmap('magma_r', np.arange(0, 1.01, .5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96caf3f9-c6a7-4766-865b-dc25e3b9e200",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 10), constrained_layout=True)\n",
    "height_ratios = [int(dct['leadtimes'] / 2) for label, dct in models.items()]\n",
    "gs = fig.add_gridspec(nrows=len(height_ratios), height_ratios=height_ratios)\n",
    "\n",
    "for i, (label, dct) in enumerate(models.items()):\n",
    "    ax = fig.add_subplot(gs[i])\n",
    "    if i + 1 < len(height_ratios):\n",
    "        xticklabels, xlabel = [], None\n",
    "    else:\n",
    "        xticklabels, xlabel = exceedance.datetime.data, 'datetime'\n",
    "    ylabel = 'leadtime (h)'\n",
    "    if i == 2:\n",
    "        cbar = True\n",
    "    else:\n",
    "        cbar = False\n",
    "    plot_DataArray(exc_o_thr.sel(model=label).isel(leadtime=slice(0, int(models[label]['leadtimes'] / 2))),\n",
    "                   xtick_step=4, ytick_step=2, cbar=cbar, cbar_kws={'label': 'exceedance over threshold'}, title=label, xticklabels=xticklabels, xlabel=xlabel,\n",
    "                   ylabel=ylabel, ax=ax, cmap=cmap_eot, norm=norm_eot)\n",
    "    \n",
    "fig.suptitle('{0} - {1} ({2})'.format(stn, *stations.loc[stn, ['name', 'catchment']]), fontsize=13);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6c1788-de9e-4791-abfb-26ecac52063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exceedance according to current criteria\n",
    "deterministic = (exceedance.sel(model=['EUD', 'DWD']) >= .3).any('model')\n",
    "probabilistic = (exceedance.sel(model=['EUE', 'COS']) >= .3).any('model')\n",
    "current = deterministic & probabilistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8b8e10-8122-487c-aa74-103a88bc10e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, figsize=(16, 10), sharex=True, sharey=True, constrained_layout=True)\n",
    "\n",
    "plot_DataArray(deterministic, ax=ax[0], cmap=cmap_eot, norm=norm_eot, cbar=False, title='deterministic')\n",
    "plot_DataArray(probabilistic, ax=ax[1], cmap=cmap_eot, norm=norm_eot, cbar=True, cbar_kws={'shrink': .25, 'label': 'exceedance over threshold'}, title='probabilistic')\n",
    "plot_DataArray(current, ax=ax[2], cmap=cmap_eot, norm=norm_eot, cbar=False, title='deterministic & probabilistic',\n",
    "               xtick_step=4, ytick_step=2)\n",
    "\n",
    "fig.suptitle('{0} - {1} ({2})'.format(stn, *stations.loc[stn, ['name', 'catchment']]), fontsize=13);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346a305a-79e5-4c91-8da8-559aa58f0701",
   "metadata": {},
   "outputs": [],
   "source": [
    "current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493b766c-4513-4832-bdc2-8c4cbd7f4120",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_leadtime = 60\n",
    "persistence = (3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f588e22-6371-4b2e-b444-ec5b4266877e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2b6df6-e69c-4aa6-9c7d-073dc571d8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_events(da, probability=None, persistence=(1, 1), by_leadtime=False, min_leadtime=None):\n",
    "    \"\"\"It defines predicted events out of a DataArray of exceendances over a probability threshold. \n",
    "    The persistence criterion defines the number of forecast that must predict an exceedance in order to be considered an event.\n",
    "    \n",
    "    Inputs:\n",
    "    -------\n",
    "    da:           xr.DataArray. A matrix of exceedances over probability threshold. It must have a dimension called 'leadtime', over which the function will compute persistence\n",
    "    persistence:  tuple (a, b). Two values that define the number of positive forecasts (a) out of a series of consecutive forecast (b) needed to consider the prediction as an event\n",
    "    resample:     string. \n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    As objetcs:\n",
    "    events:       xr.DataArray. A matrix of predicted events. The dimension 'leadtime' in the input DataArray (length 20 in the usual case) is collapsed to a single value.\n",
    "    As method:\n",
    "    exceedance:   xr.DataArray. Matrix of cells that exceed the 'probability' threshold\n",
    "    \"\"\"\n",
    "    \n",
    "    # invert 'leadtime' order from longer to shorter lead times\n",
    "    da = da.sel(leadtime=slice(min_leadtime, None)).isel(leadtime=slice(None, None, -1))\n",
    "\n",
    "    # compute exceedance over the probability threshold\n",
    "    if probability is None:\n",
    "        exceedance = da\n",
    "    else:\n",
    "        exceedance = (da >= probability).astype(int)\n",
    "    #compute_events.exceedance = exceedance.isel(leadtime=slice(None, None, -1))\n",
    "\n",
    "    # compute persistence (rolling sum over a window exceeds a number of forecast positives)\n",
    "    events = (exceedance.rolling({'leadtime': persistence[1]}, center=False, min_periods=1).sum() >= persistence[0]) & exceedance\n",
    "    events = events.isel(leadtime=slice(None, None, -1))\n",
    "    \n",
    "    if by_leadtime:\n",
    "        events_agg = events.copy()\n",
    "        for lt in events_agg.leadtime.data:\n",
    "            events_agg.loc[dict(leadtime=lt)] = events.sel(leadtime=slice(lt, None)).any('leadtime').astype(int)\n",
    "        return events_agg\n",
    "\n",
    "    # if resample is not None:\n",
    "    #     # convert 'leadtime' from integer hours to timedelta\n",
    "    #     events['leadtime'] = pd.to_timedelta(events.leadtime, 'h')\n",
    "    #     # resample\n",
    "    #     events = events.resample({'leadtime': resample}).any().astype(int)\n",
    "    #     # reconvert 'leadtime' back to intege hours\n",
    "    #     events['leadtime'] = (events.leadtime / np.timedelta64(1, 'h')).astype(int)\n",
    "    #     return events.sel(leadtime=slice(min_leadtime, None))\n",
    "    else:\n",
    "        # check if there's any predicted event\n",
    "        return events.any('leadtime').astype(int)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d48aab-f699-4f47-8483-6c564650596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_events = compute_events(current, persistence=(3, 3), min_leadtime=60, by_leadtime=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9ca3db-c903-44f0-9ec9-491505be9445",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_reanalysis = '../data/exceedance/reanalysis/'\n",
    "\n",
    "# load probability of exceeding the discharge threshold in the REANALYSIS data\n",
    "rean_exc = pd.read_parquet(f'{path_reanalysis}/exceedance_rl5.parquet')\n",
    "rean_exc.columns = rean_exc.columns.astype(int)\n",
    "rean_exc = rean_exc.loc[start:end, stations.index.tolist()]\n",
    "\n",
    "# compute onsets of the flood events\n",
    "rean_onsets = rean_exc.astype(int).diff(axis=0) == 1\n",
    "rean_onsets.iloc[0,:] = rean_exc.iloc[0,:]\n",
    "\n",
    "# create a DataArray with the number of observed events per station\n",
    "n_events_obs = xr.DataArray(rean_onsets.sum(), dims=['id'], coords={'id': rean_onsets.columns.tolist()})\n",
    "print('no. events:\\t\\t\\t{0}'.format(n_events_obs.sum().data))\n",
    "\n",
    "# select stations with events\n",
    "mask_stn = (n_events_obs > 0).to_pandas()\n",
    "print('no. stations with events:\\t{0}'.format(mask_stn.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863d9f9d-6edd-4e63-a496-ad175de52159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataArray with observed threshold exceedance\n",
    "obs = df2da(rean_exc, dims=['id', 'datetime'], plot=False, figsize=(16, 20), title='observed exceendace')\n",
    "obs = obs.sel(id=stn, datetime=slice(datetime(2021, 7, 1), datetime(2021, 7, 31))).astype(int)\n",
    "\n",
    "print(obs.dims)\n",
    "print(obs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae66191-cf9a-4aa3-ad5f-8ad30fbab5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute hits, missses and false alarms\n",
    "hits = compute_hits(obs, pred_events_, center=True, w=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc4afef-2234-401b-b969-cb1652ebbead",
   "metadata": {},
   "outputs": [],
   "source": [
    "das = {'observed events': obs,\n",
    "       'exceedance over threshold': current.sel(leadtime=slice(min_leadtime, None)),\n",
    "       'predicted events': pred_events_,\n",
    "       'buffered prediction': compute_hits.buffer,\n",
    "       'true positives': compute_hits.true_positives}\n",
    "\n",
    "fig = plt.figure(figsize=(16, 6), constrained_layout=True)\n",
    "height_ratios = [len(da.leadtime) if 'leadtime' in da.dims else 1 for key, da in das.items()]\n",
    "gs = fig.add_gridspec(nrows=len(height_ratios), height_ratios=height_ratios)\n",
    "\n",
    "for i, (label, da) in enumerate(das.items()):\n",
    "    ax = fig.add_subplot(gs[i])\n",
    "    if i + 1 < len(height_ratios):\n",
    "        xticklabels, xlabel = [], None\n",
    "    else:\n",
    "        xticklabels, xlabel = da.datetime.data, 'datetime'\n",
    "    if label == 'exceedance':\n",
    "        ylabel = 'leadtime (h)'\n",
    "    else:\n",
    "        ylabel = None\n",
    "    plot_DataArray(da, xtick_step=4, cbar=False, title=label, xticklabels=xticklabels, xlabel=xlabel,\n",
    "                   ylabel=ylabel, ax=ax, cmap='magma_r')\n",
    "    \n",
    "fig.suptitle('{0} - {1} ({2})'.format(stn, *stations.loc[stn, ['name', 'catchment']]), fontsize=13);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190181d4-19e6-4468-95d1-b671ab10ab3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
