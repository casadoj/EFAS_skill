{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a2493eb",
   "metadata": {},
   "source": [
    "# Skill assessment\n",
    "***\n",
    "\n",
    "**Author**: Chus Casado Rodr√≠guez<br>\n",
    "**Date**: 31-05-2023<br>\n",
    "\n",
    "\n",
    "**Introduction**:<br>\n",
    "In this notebook I will analyse the EFAS skill in predicting flood events in general, i.e., looking whether events where predicted at some point in time, regardless of neither the offset nor the duration of the event.\n",
    "\n",
    "**Questions**:<br>\n",
    "\n",
    "* [ ] Take into account the model spread?\n",
    "* [ ] Aggregate results by river/administrative area? EFAS aims at alerting administrations about incoming events in there administrative area, shouldn't that aggregation be included in the results?\n",
    "* [ ] Remove extremely bad performing stations.\n",
    "\n",
    "**Pending tasks**:<br>\n",
    "\n",
    "* [x] Weighting the model average by the Brier score?\n",
    "* [x] Sort stations by catchment area (or other order)?\n",
    "* [x] Persistence\n",
    "* [ ] Analyse only the periods/stations close to an observed event and compute f1 for this extraction. Later on, on the complementary subset of data another metric must be computed to avoid false positives, p.e., false alarm ratio.\n",
    "* [ ] Maps with catchment polygons instead of countries?\n",
    "\n",
    "\n",
    "**Interesting links**<br>\n",
    "[Evaluation metrics for imbalanced classification](https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/)<br>\n",
    "[Cross entropy for machine learning](https://machinelearningmastery.com/cross-entropy-for-machine-learning/)<br>\n",
    "[Probability metrics for imbalanced classification](https://machinelearningmastery.com/probability-metrics-for-imbalanced-classification/)<br>\n",
    "[ROC curves and precision-recall curves for imbalanced classification](https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification/)<br>\n",
    "[Instructions for sending EFAS flood notifications](https://efascom.smhi.se/confluence/display/EDC/Instructions+for+sending%2C+upgrading+and+deactivating+EFAS+Flood+Notifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ee7a0f-f62b-4a8b-8147-c46a2e2471ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import cartopy.crs as ccrs\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm_notebook\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import pickle\n",
    "import yaml\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "\n",
    "path_root = os.getcwd()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.chdir('../py/')\n",
    "from compute import hits2skill, define_area_ranges, hits_by_area\n",
    "from convert import dict2da\n",
    "from optimize import find_best_criterion, find_best_criteria, find_best_criteria_cv\n",
    "from plot.results import lineplot_hits, lineplot_skill, plot_skill_training, plot_hits_by_variable, plot_skill_by_variable\n",
    "from plot.map import create_cmap, map_stations, map_hits, map_skill\n",
    "os.chdir(path_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b0a37e-716a-4a13-b6ec-1a474d080918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the default text font size\n",
    "plt.rc('font', size=15)\n",
    "# Set the axes title font size\n",
    "plt.rc('axes', titlesize=16)\n",
    "# Set the axes labels font size\n",
    "plt.rc('axes', labelsize=15)\n",
    "# Set the font size for x tick labels\n",
    "plt.rc('xtick', labelsize=13)\n",
    "# Set the font size for y tick labels\n",
    "plt.rc('ytick', labelsize=13)\n",
    "# Set the legend font size\n",
    "plt.rc('legend', fontsize=13)\n",
    "# Set the font size of the figure title\n",
    "plt.rc('figure', titlesize=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4e0fda-fb63-48b5-9cc3-679d702d934a",
   "metadata": {},
   "source": [
    "## 1 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b2131f-4cc6-4ab6-9db4-45496ccbfbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coordinate reference system when plotting maps\n",
    "proj = ccrs.LambertAzimuthalEqualArea(central_longitude=10, central_latitude=52, false_easting=4321000, false_northing=3210000, globe=ccrs.Globe(ellipse='GRS80'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d46397-96bd-40b6-859e-f885d2e85db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../conf/config.yml\", \"r\", encoding='utf8') as ymlfile:\n",
    "    cfg = yaml.load(ymlfile, Loader=yaml.FullLoader)\n",
    "\n",
    "# minimum catchment area\n",
    "area_threshold = cfg.get('reporting_points', {}).get('area', 500)\n",
    "\n",
    "# dissagregate the analysis by seasons?\n",
    "seasonality = cfg.get('seasonality', False)\n",
    "\n",
    "# geographic extent of the analysis\n",
    "#domain = 'EFAS'\n",
    "catchments = cfg.get('catchment', None) #['Rhine', 'Meuse / Maas']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e08960-70df-464f-b0f5-5635b080ddf9",
   "metadata": {},
   "source": [
    "### 1.2 Skill analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c245aa78-952b-4696-922a-da691bb8113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed notification criteria\n",
    "min_leadtime = cfg.get('skill_analysis', {}).get('leadtime', 12) \n",
    "min_area = cfg.get('skill_analysis', {}).get('area', 500) \n",
    "\n",
    "# coefficient of the fbeta-score\n",
    "beta = cfg.get('skill_analysis', {}).get('beta', 1) #[.8, 1, 1.2]\n",
    "if isinstance(beta, int):\n",
    "    metric = f'f{beta}'\n",
    "elif isinstance(beta, float):\n",
    "    metric = f'f{beta:.1f}'\n",
    "\n",
    "# optimization parameters\n",
    "kfold = cfg.get('skill_analysis', {}).get('optimization', {}).get('kfold', None)\n",
    "train_size = cfg.get('skill_analysis', {}).get('optimization', {}).get('train_size', .8)\n",
    "tolerance = cfg.get('skill_analysis', {}).get('optimization', {}).get('tolerance', 1e-2)\n",
    "\n",
    "# current operationa criteria\n",
    "current_criteria = cfg.get('skill_analysis', {}).get('current_criteria', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51fed3b-0330-4f9f-837a-e9aba8a55a00",
   "metadata": {},
   "source": [
    "### 1.3 Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2190903b-4d02-4510-9069-68141e962291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path that contains the NetCDFs with hit, misses and false alarms pro\n",
    "path_in = cfg.get('paths', {}).get('output', {}).get('hits', f'../data/hits/')\n",
    "\n",
    "# path where results will be saved\n",
    "#path_out = f'../results/skill/{domain}/'\n",
    "path_out = cfg.get('paths', {}).get('output', {}).get('skill', f'../results/skill/')\n",
    "if os.path.exists(path_out) is False:\n",
    "    os.makedirs(path_out)\n",
    "    \n",
    "# reporting points\n",
    "path_stations = cfg.get('paths', {}).get('output', {}).get('reporting_points', '../results/reporting_points/')\n",
    "file_stations = f'{path_stations}reporting_points_over_{area_threshold}km2.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef9ff02-61a0-4bb5-a436-f64e441f7d5c",
   "metadata": {},
   "source": [
    "## 2 Data\n",
    "\n",
    "### 2.1 Stations\n",
    "\n",
    "I load all the stations that where selected in a previous [notebook](3_0_select_stations.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf123ea-2470-4f7b-90cc-f6ecfebda457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load table of fixed reporting points\n",
    "stations = pd.read_parquet(file_stations)\n",
    "stations[['X', 'Y', 'area']] = stations[['X', 'Y', 'area']].astype(int)\n",
    "\n",
    "# select stations that belong to the selected catchments\n",
    "if isinstance(catchments, list):\n",
    "    stations = stations.loc[stations.catchment.isin(catchments),:]\n",
    "\n",
    "# remove station with erroneous behaviour\n",
    "stations = stations.loc[~(stations.n_events_obs >= 6)]\n",
    "\n",
    "# mask stations with events\n",
    "stations_w_events = (stations.n_events_obs > 0)\n",
    "\n",
    "print('All points')\n",
    "print('----------')\n",
    "print(f'no. reporting points:\\t\\t{stations.shape[0]}')\n",
    "print('no. stations with events:\\t{0}'.format(stations_w_events.sum()))\n",
    "print('no. observed events:\\t\\t{0}'.format(stations.n_events_obs.sum()))\n",
    "\n",
    "# select stations according to catchment area\n",
    "if min_area > area_threshold:\n",
    "    stations_optimize = stations.loc[stations.area >= min_area].index\n",
    "else:\n",
    "    stations_optimize = stations.index\n",
    "\n",
    "print('\\nPoints selected for otimization')\n",
    "print('-------------------------------')\n",
    "print(f'no. reporting points:\\t\\t{len(stations_optimize)}')\n",
    "print('no. stations with events:\\t{0}'.format((stations.loc[stations_optimize, 'n_events_obs'] > 0).sum()))\n",
    "print('no. observed events:\\t\\t{0}'.format(stations.loc[stations_optimize, 'n_events_obs'].sum()))\n",
    "\n",
    "# suffix that will be used when saving plots\n",
    "suffix = f'{min_area}km2_{len(stations_optimize)}points'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5186b23-9639-49fa-9f75-f55cce348029",
   "metadata": {},
   "source": [
    "**Distribution of catchment area**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20f23b5-0454-4943-b7ef-c20fc7c85065",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = area_threshold\n",
    "xmax = 500001#np.ceil(stations.area.max() / 500) * 500\n",
    "bins = np.arange(xmin, xmax, 500).astype(int)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5.5))\n",
    "sns.histplot(stations.area, ax=ax, bins=bins, label='all')\n",
    "sns.histplot(stations[stations_w_events].area, ax=ax, color='firebrick', bins=bins, label='w/ events')\n",
    "ax.axvline(min_area, color='k', ls=':', lw=.75)\n",
    "ax.set(xlabel='area (km¬≤)', ylabel='no. reporting points', xlim=(area_threshold, 50000));\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "ax.legend();\n",
    "\n",
    "plt.savefig(f'{path_out}area_distribution_{suffix}.jpg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb112cb-8c44-4c38-8a13-c30bd57ddb07",
   "metadata": {},
   "source": [
    "> ***Figure 1**. Distribution of the reporting points according to catchment area. The complete set of reporting points is shown in blue, and the subset of reporting points with observed flood events during the study period is shown in red. The balck, dotted line represents the minimum catchment area that will be used for the optimization of the notification criteria.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c9fee9-82e2-4f8c-908c-0f2b2d102011",
   "metadata": {},
   "source": [
    "Two ideas to extract from the previous plot:\n",
    "\n",
    "* When considering all the catchment areas, only **41% of the fixed reporting points had a flood event** during the study period. This figure is very similar (37%) when considering points with a catchment area larger than 2000 km¬≤.\n",
    "\n",
    "* **40% of the fixed reporting points have a catchment area smaller than 2000 km¬≤**, therefore the are excluded from the optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bdbed9-6609-44fa-8229-b68dbc2b6dd9",
   "metadata": {},
   "source": [
    "**Map of number of \"observed\" events**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aba955-541c-4bbc-8716-a498e8223175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colormap used for the maps\n",
    "s = 2\n",
    "alpha = .5\n",
    "max_events = stations.n_events_obs.max()\n",
    "cmap, norm = create_cmap('Oranges', np.arange(max_events + 2), 'no. events', [0, (0, 0, 0, 1)])\n",
    "map_stations(stations.X, stations.Y, stations.n_events_obs, mask=~stations_w_events,\n",
    "                  cmap=cmap, norm=norm, size=s, figsize=(8, 8),alpha=alpha)\n",
    "ticks = np.arange(max_events + 1)\n",
    "cbar = plt.colorbar(map_stations.colorbar, shrink=.33, label='observed events', ticks= ticks + .5)\n",
    "cbar.ax.set_yticklabels(ticks)\n",
    "cbar.ax.tick_params(size=0);\n",
    "\n",
    "plt.savefig(f'{path_out}/map_observed_events_{suffix}.jpg', dpi=300, bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfe35be-0f72-4afc-9952-123342d65c86",
   "metadata": {},
   "source": [
    "> ***Figure 2**. Number of observed flood events during the study period.*\n",
    "\n",
    "The geographical distribution of events is not even. There is a higher proportion of stations with events in Central Europe, British Isles and the Mediterranean catchments than in Estearn and North-Eastern Europe. During the study period there were major events in the Rhine, Meuse and Ebro, which can be seen in the map.\n",
    "\n",
    "The reporting points with more than 5 flood events during the study period were removed, since it is suspicious that the 5-year return period was exceeded so many times in only 2 years of study period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acbef3c-6231-44ad-8e33-c66e1b1a06e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2 Hits, misses and false alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c8bb3b-d731-4cf2-8ee6-3aeae8a1f60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93436796-ab57-49f8-811e-f33a4493af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(f'{path_in}0001.nc')\n",
    "ds['approach'] = ['1_deterministic_+_1_probabilistic' if app == 'current' else app for app in ds.approach.data]\n",
    "ds.close()\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe4182c-7e27-4c48-8f85-0d1c76fda5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_netcdf(f'{path_in}0001.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a83d43-1c21-4141-95c8-0346dea3e9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hits for each station\n",
    "hits_stn = xr.open_mfdataset(f'{path_in}*.nc', combine='nested', concat_dim='id')\n",
    "# reorder persistences\n",
    "hits_stn = hits_stn.sel(persistence=['1/1', '2/4', '2/3', '2/2', '3/4', '3/3', '4/4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e0847a-4ede-4926-80cd-a0c95c3488f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_stn.approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dae9358-36b4-445b-928f-14241312b39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename approaches\n",
    "hits_stn['approach'] = ['1_deterministic_+_1_probabilistic' if app == 'current' else app for app in hits_stn.approach.data]\n",
    "# extract stations\n",
    "hits_stn = hits_stn.sel(id=stations.index.to_list()).compute()\n",
    "# convert to NaN values at long leadtimes for which the persistence criteria is impossible to meet\n",
    "hits_stn = hits_stn.astype(float)\n",
    "for persistence in hits_stn.persistence.data:\n",
    "    last_leadtime = int(persistence.split('/')[0]) - 1\n",
    "    if last_leadtime > 0:\n",
    "        hits_stn.sel(persistence=persistence)[dict(leadtime=slice(-last_leadtime, None))] = np.nan\n",
    "\n",
    "\n",
    "# aggregate over stations\n",
    "hits_lt = hits_stn.sum('id', skipna=False)\n",
    "\n",
    "# # convert 0 into NaN. 0 were caused by the persitence criterion in the longest leadtimes\n",
    "# hits_lt = hits_lt.where(hits_lt != 0, np.nan)\n",
    "\n",
    "# subset of the 'hits' dataset with the stations selected for the optimization\n",
    "hits_opt = hits_stn.sel(id=stations_optimize).sum('id', skipna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d715613-88bb-45e2-a0f6-ec01c693ab7f",
   "metadata": {},
   "source": [
    "### 2.3 Compute skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313de1ab-db62-44ae-b02a-021b6c458628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skill by station\n",
    "skill_stn = hits2skill(hits_stn, beta=beta)\n",
    "\n",
    "# global skill regarding minimum leadtime\n",
    "skill_lt = hits2skill(hits_lt, beta=beta)\n",
    "\n",
    "# skill dataset for optimizing criteria\n",
    "skill_opt = hits2skill(hits_opt, beta=beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c9a1f0-2e0d-475a-9b19-cc35c9ff5b6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3 Assess skill\n",
    "\n",
    "In this section I will compute the skill of the EFAS predictions in different ways. In all the following sections I will work with three metrics: $recall$, $precision$ and the $f_{beta}$ score. The three metrics are based in the contingency table of hits ($TP$ for true positives), false alarms ($FP$ for false positives) and misses ($FN$ for false negatives).\n",
    "\n",
    "$$recall = \\frac{TP}{TP + FN}$$\n",
    "$$precision = \\frac{TP}{TP + FP}$$\n",
    "$$f_{beta} = \\frac{(1 + \\beta^2) \\cdot TP}{(1 + \\beta^2) \\cdot TP + \\beta^2 \\cdot FN + FP}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4720dfcf-35b2-4556-b608-fca8fecfb41a",
   "metadata": {},
   "source": [
    "### 3.1 Analyse overall skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07a4d0f-75f2-4943-b784-f16d35eaf3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to simplify the plot, they will show only the following values of persistence and leadtime\n",
    "persistences = ['1/1', '2/2', '3/3']\n",
    "leadtimes = [12, 36, 60, 84]#, 108, 132]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b47926-3aee-48e1-b96d-faca228d5cb9",
   "metadata": {},
   "source": [
    "#### 3.1.1 Hits, misses and false alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d654d55-e7eb-4f8a-86db-fe05ed344d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lineplot_hits(hits_opt.sel(persistence=persistences, leadtime=leadtimes),\n",
    "              coldim='leadtime', rowdim='persistence', ylim=(0, 2), xticks=skill_lt.probability.data[2::8],\n",
    "              loc_legend=[0.15, -.04, .5, .1],\n",
    "              save=f'{path_out}hits_lineplot_persistenceVSleadtimeVSprobability_{suffix}.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c3c298-6237-41e6-9115-242f3a00fb97",
   "metadata": {},
   "source": [
    "> ***Figure 3**. Evolution of hits, misses and false alarms depending on probability (X axis), persistence (rows), and lead time (columns). The Y axis is normalized by the number of observed events. The black, horizonal line, which represents the number of observed events, is the reference. Blue lines represent the hits (TP) for each of the approaches to combine the meteorological forecasts; the difference between the reference line and these blue lines are the misses (events that were not forecasted). Red lines represent the total number of prediced events; therefore, the difference between them and the blue lines are the false alarms (wrongly predicted events). The vertical, dashed line indicates the probability threshold that maximizes skill, including the skill value.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36f8ccb-73b7-4140-bf55-76218b1cc0cb",
   "metadata": {},
   "source": [
    "The first outcome of this plot is that no matter the combination of criteria, we cannot predict all the observed events. Even for the shortest leadtime, lowest probability threshold and most relaxed persistency, the hit rate ($\\frac{hits}{obs}$) is around 0.80. However, to achieve this hit rate value, the false hit rate ($\\frac{pred-hits}{obs}$) is dramatically large. In fact, since our target skill metric is $f_{beta}$, we want to optimize a combination of those two rates; the result is that we need to allow for a lower hit rate in order not to minimize the amount of false alarms.\n",
    "\n",
    "If we analyse the evolution regarding thre three variables (lead time, persistence and probability), we get the following conclusions:\n",
    "\n",
    "* **Lead time**. As expected, skill improves with shorter leadtimes, as the uncertainty in the prediction dicreases.\n",
    "\n",
    "* **Persistence**. There is a clear tendency to overpredict especially for lower probability thresholds, where the total amount of prediced events go well beyond the number of observed events. The main role of persistency is to limit this overprediction.\n",
    "\n",
    "* **Probability**. It plays a similar role as persistence. By increasing the probability threshold we reduce the number of false alarms. The optimal value of probability is the one that comprimises correctly the number of hits, misses and false alarms. Since probability and persistence play a similar role, there is a trade-off between those two variables. Whenever persistence is more relaxed (or non-existen), the probability threshold is higher; and viceversa. For a fixed persistence, the optimal probability threshold is higher for shorter lead times; since the uncertainty on the prediction is lower, the probability threshold can be higher.\n",
    "\n",
    "* **Approach**. The hit rate is fairly similar regarless of the method used to combine the meteorological forcings. On the contray, the false hit rate is very sensitive to the approach, especially with more relaxed persistence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f414e7f-bc55-4bb0-85db-eafb7ff93c49",
   "metadata": {},
   "source": [
    "#### 3.1.2 Skill: recall, precision and f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1c7e17-b7d0-4888-b26c-0829517f1eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "lineplot_skill(skill_opt.sel(persistence=persistences, leadtime=leadtimes),\n",
    "               metric=metric, coldim='leadtime', xticks=skill_lt.probability.data[2::8],\n",
    "               save=f'{path_out}skill_lineplot_persistenceVSleadtimeVSprobability_{suffix}.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad6c3c7-c21d-45c0-971b-b7d5e43d5bf7",
   "metadata": {},
   "source": [
    "> ***Figure 4**. Evolution of skill depending on probability (X axis), persistence (rows), and lead time (columns). Black lines represents the the target skill metric for each of the approaches to combine the meteorological forecasts, which is a combination of recall (blue lines) and precision (red lines). The dotted lines represent the optimal probability threshold and the associated value of the target metric.*\n",
    "\n",
    "The plot shows the well known interplay between recall and precision. In this case, recall is high for small probability thresholds; when this threshold is low, the system produces more notifications and the number of misses reduces. On the other hand, precision is high for large probability thresholds; notifications are sent only when the certainty of the event is high, so the number of false alarms is minimum.\n",
    "\n",
    "The target metric is a combination of both recall and precision. For that metric, we look for the optimal probability threshold. Fortunately, in the majority of plots we see that the target metric (black lines) has a convex curve, so it is possible to find the optimal value. Only for very short lead time and more relaxed persitence the target metric has a continuously increasing behaviour.\n",
    "\n",
    "The conclusions regarding each of the four variables are similar as before:\n",
    "\n",
    "* **Lead time**. Skill increases with lead time. As said before, lead time also influences the optimal probability threshold, with larger values for shorter lead times.\n",
    "\n",
    "* **Persistence**. Skill reduces with persistence. It also affects the optimal probability threshold, with higher values for more relaxed persistence.\n",
    "\n",
    "* **Probability**. As explained before, in most of the combinations of persistence and leadtime the target skill metric shows a convex behaviour in relation with probability. \n",
    "\n",
    "* **Approach**. The difference among the approaches is noticeable only when persistence is relaxed. For instance, for no persistence (persistence 1/1), the _model mean_ behaves clearly different from the other approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dcf30b-e803-47e5-968d-ddf4e6d7d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skill for a fixed lead time\n",
    "lineplot_skill(skill_opt.sel(persistence=['1/1', '2/2', '3/3'], leadtime=min_leadtime),\n",
    "               metric=metric, coldim=None, xticks=skill_opt.probability.data[2::8], linewidth=1.2, alpha=1,\n",
    "               loc_legend=[1.125, .79, .2, .1],\n",
    "               save=f'{path_out}skill_lineplot_persistenceVSprobability_{suffix}_{min_leadtime}h_comparison_fscores.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a1c31e-1a67-4f49-b6c6-41772a3fca62",
   "metadata": {},
   "source": [
    "> ***Figure 5**. Evolution of skill depending on probability (X axis) and persistence (rows). Each column represents a skill metric. In each plot the solid lines represent the approaches to combine the meteorological forcings. The dotted lines represent probability threshold optimized for the target skill metric and the associated value of the metric.*\n",
    "\n",
    "This plot is similar to the previous, but now the lead time is fixed to 60 h (more than 2 days as it is the current procedure). Each of the skill metrics is represented in a different column and the approaches are distinct by the line colours.\n",
    "\n",
    "* Regardless of the set of criteria (persistence, probability and approach), the maximum values of the target metric are in the order of 0.50. This means that the selection of the optimal set of criteria purely on the skill value would be very uncertain.\n",
    "\n",
    "* In general, the highest skill is achieved with no persistence, except for the _model mean_ approach, which has a clearly distinct behaviour. As already mentioned, the stronger the persistence, the more similar the results among approaches.\n",
    "\n",
    "* The values of precision for the optimal probability threshold are consistently higher than those of recall, as it could be expected since the target metric is $f_{0.8}$, which gives a higher importance to precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cf32c8-5990-4543-958a-9e6ad32967b8",
   "metadata": {},
   "source": [
    "#### 3.1.3 Optimize criteria\n",
    "\n",
    "In this section we will derive a optimal set of notification criteria based on the target skill metric. To avoid overfitting, the sample of reporting points is first divided in a training and a test subset. This division is done in a stratified way after randomly shuflling the points, to keep the proportion of observed events in the subsets and avoid geographic biases, respectively.\n",
    "\n",
    "To increase the robustness of the optimization, cross-validation is applied if the parameter `kfold` is set in the configuration file. In that case, `kfold` subsets of stations are generated, again in a stratified and random manner. The average skill over the subsets will be the data used to find the optimal criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22e95d5-86f0-45f1-9e40-4f3ab640b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide stations in train and test samples\n",
    "X = stations_optimize\n",
    "y = stations.loc[X, 'n_events_obs']\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, train_size=train_size, random_state=0, shuffle=True, stratify=y)\n",
    "\n",
    "# optimize the notification criteria\n",
    "if kfold is not None: # apply a cross-validation approach\n",
    "    skill_train, criteria = find_best_criteria_cv(hits_stn.sel(leadtime=min_leadtime), ytrain,\n",
    "                                                       kfold=kfold, train_size=train_size,\n",
    "                                                       beta=beta, tolerance=tolerance, min_spread=True)\n",
    "else:\n",
    "    # subset of the 'hits' dataset with the training sample\n",
    "    hits_train = hits_stn.sel(id=Xtrain).sum('id', skipna=False)\n",
    "    # skill of the training sample\n",
    "    skill_train = hits2skill(hits_train, beta=beta).sel(leadtime=min_leadtime).drop('leadtime')\n",
    "    # best criteria for each approach\n",
    "    criteria = find_best_criteria(skill_train, metric=metric, tolerance=tolerance, min_spread=True)\n",
    "\n",
    "# create dictionary of best_criteria\n",
    "best_criteria = {app: {par: criteria.sel(approach=app)[par].data for par in ['probability', 'persistence']} for app in criteria.approach.data}\n",
    "for app in best_criteria:\n",
    "    best_criteria[app]['approach'] = app\n",
    "\n",
    "# export best criteria\n",
    "file = f'{path_out}best_criteria_{suffix}_{metric}.pkl'\n",
    "with open (file, 'wb') as f:\n",
    "    pickle.dump(best_criteria, f)\n",
    "\n",
    "# add the current operational criteria to the dictionary\n",
    "if current_criteria is not None:\n",
    "    best_criteria['current'] = current_criteria\n",
    "\n",
    "# performance for every split of the training sample for the best criteria\n",
    "if kfold is not None:\n",
    "    performance_train = {approach: skill_train.sel(criteria) for approach, criteria in best_criteria.items()}\n",
    "    performance_train = dict2da(performance_train, dim='approach')\n",
    "else:\n",
    "    performance_train = {approach: skill_train.sel(criteria) for approach, criteria in best_criteria.items()}\n",
    "    performance_train = dict2da(performance_train, dim='approach')\n",
    "\n",
    "# performance of the test sample for the best criteria\n",
    "hits_test = hits_stn.sel(id=Xtest).sum('id', skipna=False)\n",
    "skill_test = hits2skill(hits_test, beta=beta).sel(leadtime=min_leadtime).drop('leadtime')\n",
    "performance_test = {approach: skill_test.sel(criteria) for approach, criteria in best_criteria.items()}\n",
    "performance_test = dict2da(performance_test, dim='approach')\n",
    "\n",
    "# performance of the complete set of stations\n",
    "hits_all = hits_stn.sel(id=X).sum('id', skipna=False)\n",
    "skill_all = hits2skill(hits_all, beta=beta).sel(leadtime=min_leadtime).drop('leadtime')\n",
    "performance_all = {approach: skill_all.sel(criteria) for approach, criteria in best_criteria.items()}\n",
    "performance_all = dict2da(performance_all, dim='approach')\n",
    "\n",
    "# plot performance\n",
    "plot_skill_training(performance_train, performance_test, performance_all, ylim=(.33, .67),\n",
    "                          save=f'{path_out}skill_training.jpg')\n",
    "\n",
    "# print on screen results\n",
    "for approach, criteria in best_criteria.items():\n",
    "    print(approach.replace('_', ' '))\n",
    "    print('-' * len(approach))\n",
    "    for criterium, value in criteria.items():\n",
    "        if criterium == 'approach':\n",
    "            continue\n",
    "        print(f'{criterium}:\\t{value}')\n",
    "    print('{0}:\\t\\t{1:.3f}\\n'.format(metric, performance_test[metric].sel(approach=approach).data))\n",
    "\n",
    "# approach with the highest skill\n",
    "best_approach = str(performance_test[metric].idxmax('approach').data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e203b81-e92e-4ac4-8eae-a0a55717a36b",
   "metadata": {},
   "source": [
    "> ***Figure 6**. Skill resulting of the otpimization process for each of the methods used to combine the meteorological forcings: 1D+1P, one deterministic and 1 probabilistic; MM, model mean; MW, member weighted; BW, Brier weihted; C, current operational criteria. If cross-validation was applied, the boxplots show the variance in the skill among the kfolds; if not, the black dots represent the skill of the training set. In either case, the orange dot represent the skill of the test set and the blue dots that of the complete set of reporting points.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d053bb3d-2408-4d00-b706-00180448de49",
   "metadata": {},
   "source": [
    "According to the performance on the test set (orange dots), **the optimal criteria is the one that uses the _member weighted_ approach with no persistence and a probability threshold of 40%**. However, for the training set the highest-performing approach was _1 deterministic and 1 probabilistic_, but this approach seems to suffer from overfitting, since it is the second lowest-performing in the test set.\n",
    "\n",
    "Since the target metric benefits precision over recall, the precision values are higher than those of recall. This difference is enhanced for the _member weighted_ (the best-performing) and the _current_ criteria.\n",
    "\n",
    "Persistence is not necessary in two out of four approaches: _1 deterministic and 1 probabilistic_, _member weighted_. The other two approaches have an optimized persistence of $4/4$.</font>\n",
    "\n",
    "In general, the optimized criteria, regarless of the approach, outperform the current operational criteria. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b371fb-3ae7-44f3-8f21-4fca4383fad6",
   "metadata": {},
   "source": [
    "### 3.2 Anaylse skill by reporting points\n",
    "\n",
    "Once we have optimized the notification criteria for each approach, we will have a look to the distribution of the hits/misses/false alarms and the skill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c67621c-ed43-49ca-88f3-727f6b546472",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define colormap for the skill metrics\n",
    "top = cm.get_cmap('Oranges_r', 128)\n",
    "bottom = cm.get_cmap('Blues', 128)\n",
    "newcolors = np.vstack((top(np.linspace(0.2, .8, 128)),\n",
    "                       bottom(np.linspace(0.2, .8, 128))))\n",
    "OrBu = ListedColormap(newcolors, name='OrangeBlue')\n",
    "cmap_f1, norm_f1 = create_cmap(OrBu, np.arange(0, 1.01, 0.05), name='skill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821b3550-b808-4ecb-91e0-dd37d2daa30f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# map hits/misses/false alarmas and performance for each of the total probability approaches\n",
    "s = 2\n",
    "alpha = .5\n",
    "for approach, criteria in best_criteria.items():\n",
    "    \n",
    "    title = '{0}\\nprobability = {1}\\npersistence = {2}'.format(approach.replace('_', ' '), criteria['probability'], criteria['persistence'])\n",
    "    \n",
    "    # extract TP, FN, FP for this approach\n",
    "    hits_stn_best = hits_stn.sel(leadtime=min_leadtime).sel(criteria)\n",
    "    for var, da in hits_stn_best.items():\n",
    "        stations[var] = da.to_pandas()\n",
    "        \n",
    "    # plot maps of TP, FN, FP\n",
    "    map_hits(stations.loc[stations_optimize], cols=['TP', 'FN', 'FP'], mask=stations_w_events, s=s, alpha=alpha,\n",
    "             title=title,\n",
    "             save=f'{path_out}hits_maps_reporting_points_{suffix}_{approach}.jpg')\n",
    "    \n",
    "    # compute metrics\n",
    "    stations['recall'] = stations.TP / (stations.TP + stations.FN)\n",
    "    stations['precision'] = stations.TP / (stations.TP + stations.FP)\n",
    "    stations[metric] = (1 +  beta**2) * stations.TP / ((1 +  beta**2) * stations.TP + beta**2 * stations.FN + stations.FP)\n",
    "\n",
    "    # plot maps of performance\n",
    "    map_skill(stations.loc[stations_optimize], cols=['recall', 'precision', metric], bins=50, cmap=cmap_f1, norm=norm_f1,\n",
    "              s=s, alpha=alpha,\n",
    "              title=title,\n",
    "              save=f'{path_out}skill_maps_reporting_points_{suffix}_{approach}.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfec845-0646-4e38-913e-a636101fa0cc",
   "metadata": {},
   "source": [
    "> ***Figure 7**. Maps of hits, misses and false alarms for the criteria otimized for each approach. The colour scale changes depending on the variable; orange (darker orange) means worse values, whereas blue (darker blue) better values. In the case of hits (TP) and misses (FN) a mask has been applied to remove reporting points with no observed events (gray points), since none of these variables can be computed if there are no observations to predict or miss. The histograms at the bottom show the distributions of hits, misses and false alarms over the whole domain.*\n",
    "\n",
    "> ***Figure 8**. Maps of skill for the criteria otimized for each approach. Orange values represent poor skill, whereas blue values high skill; gray dots represent points for which the metric can not be computed. The histograms at the bottom show the distribution of skill over the whole domain.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf18e14f-1e10-4e5a-8e47-3e63a832b2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_stn_best = hits_stn.sel(leadtime=min_leadtime).sel(best_criteria[best_approach])\n",
    "for var, da in hits_stn_best.items():\n",
    "    stations[var] = da.to_pandas()\n",
    "stations['recall'] = stations.TP / (stations.TP + stations.FN)\n",
    "stations['precision'] = stations.TP / (stations.TP + stations.FP)\n",
    "stations[metric] = (1 +  beta**2) * stations.TP / ((1 +  beta**2) * stations.TP + beta**2 * stations.FN + stations.FP)\n",
    "\n",
    "stations.to_parquet(file_stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524b3971-9fe8-4ffd-bbf2-d96454e27329",
   "metadata": {},
   "source": [
    "### 3.3 Analyse skill by catchment area\n",
    "\n",
    "So far we have analyzed only stations with a catchment area larger or equal than a fixed value (2000 km¬≤). Also, in the optimization of the notification criteria this minimum catchment area was fixed.\n",
    "\n",
    "In this section we will analyze how results change according to the catchment area. First, we will see the evolution of skill over catchment area for the notification criteria optimized for a minimum catchment area. Later, we will derive a new optimization criteria in which the probability threshold varies according to catchment area. This derivation is repeated for every approach, and the persistence criterion is fixed for each approach to the value optimized in the previous sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286b58cf-7135-4b0a-b219-cc5d36eccce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an array of catchment area thresholds\n",
    "area_max = np.ceil(stations.area.max() / 500) * 500\n",
    "areas = define_area_ranges(500, area_max, scale='semilog')\n",
    "\n",
    "# no. stations and events by catchment area threshold\n",
    "stations_area = summarize_by_area(stations.area, stations.n_events_obs, areas)\n",
    "\n",
    "# hits and skill by catchment area\n",
    "hits_area = hits_by_area(hits_stn.sel(leadtime=min_leadtime), stations.area, areas)\n",
    "skill_area = hits2skill(hits_area, beta=beta)\n",
    "skill_area = skill_area.dropna('area', how='all')\n",
    "    \n",
    "# optimize the probability threshold regarding catchment area\n",
    "if kfold is None:\n",
    "\n",
    "    criteria_area = find_best_criteria(skill_area, dims='probability', metric=metric, tolerance=tolerance, min_spread=True)\n",
    "    criteria_area = criteria_area['probability']\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # compute skill on 'kfold' sets of samples\n",
    "    skill_train = {}\n",
    "    cv = StratifiedShuffleSplit(n_splits=kfold, train_size=train_size, random_state=0)\n",
    "    for i, (train, val) in tqdm_notebook(enumerate(cv.split(stations.n_events_obs.index, stations.n_events_obs.values))):\n",
    "        # convert indexes into station ID\n",
    "        train = stations.n_events_obs.index[train]\n",
    "        # compute hits by area in the subset of stations\n",
    "        hits_train = hits_by_area(hits_stn.sel(id=train, leadtime=min_leadtime), stations.loc[train, 'area'], areas)\n",
    "        # compute skill by area in the subset of stations\n",
    "        skill_train[i] = hits2skill(hits_train, beta=beta)\n",
    "    # concatenate the 'skill_cv' dictionary as xarray.DataArray\n",
    "    skill_train = dict2da(skill_train, dim='kfold')\n",
    "    # find the best criteria for the average over station sets\n",
    "    criteria_area = find_best_criteria(skill_train.mean('kfold'), metric=f'f{beta}', dims='probability',\n",
    "                                       tolerance=tolerance, min_spread=True)\n",
    "    criteria_area = criteria_area['probability']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3d66d1-01ec-4ebb-a665-d83dd07bcf41",
   "metadata": {},
   "source": [
    "#### 3.3.1 Stations and events according to catchment area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0767b6d-e939-416a-9eae-8cf00ccc5d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 3\n",
    "lw = 1\n",
    "alpha = .8\n",
    "c1 = 'orange'\n",
    "c2 = 'steelblue'\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(4, 4))\n",
    "\n",
    "ax1.plot(stations_area.index, stations_area.n_stations, alpha=alpha, c=c1, lw=lw, zorder=2)\n",
    "ax1.set_xlabel('area ‚â• (km¬≤)')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_ylabel('no. reporting points', c=c1)\n",
    "ymin1, ymax1 = 0, 3000\n",
    "yticks = np.linspace(ymin1, ymax1, 6).astype(int)\n",
    "ax1.set_yticks(yticks)\n",
    "ax1.set_yticklabels(yticks, c=c1)\n",
    "ax1.set_ylim(ymin1 - ymax1 * .02, ymax1 * 1.02)\n",
    "\n",
    "ax1.axvline(x=min_area, ls=':', lw=.5, color='k', zorder=0)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(stations_area.index, stations_area.n_events_obs, alpha=alpha, c=c2, lw=lw, zorder=1)\n",
    "ax2.set_ylabel('no. observed events', c=c2)\n",
    "ymin2, ymax2 = 0, 1500\n",
    "yticks = np.linspace(ymin2, ymax2, 6).astype(int)\n",
    "ax2.set_yticks(yticks)\n",
    "ax2.set_yticklabels(yticks, c=c2)\n",
    "ax2.set(xlim=(500, area_max), ylim=(ymin2 - ymax2 * .02, ymax2 * 1.02));\n",
    "\n",
    "plt.savefig(f'{path_out}points_observedEvents_vs_area_{suffix}.jpg', dpi=300, bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afbd985-db94-47fb-b32b-61e8c8af1c00",
   "metadata": {},
   "source": [
    "> ***Figure 9**. Number of reporting points (orange) and observed events (blue) by catchment area.*\n",
    "\n",
    "The plot represents both the number of reporting points and the number of observed events over a increasing catchment area threshold. Note that the X axis is in logarithmic scale, and that the primary Y axis (reporting points) has a scale double than the secondary Y axis (events).\n",
    "\n",
    "There is a clear 2:1 relation between the number of reporting points and the number of observed events. Both variables dicrease exponentially with catchment area. However, for small catchments (lower than 2000 km¬≤ approx.) the 2:1 relation disappears; the number of events increases faster than that of reporting points with dicreasing area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ec66fe-8b40-49d0-9246-e7f9455db3e6",
   "metadata": {},
   "source": [
    "#### 3.3.2 Current vs optimized criteria\n",
    "\n",
    "**Hits, misses and false alarms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8d1a09-593e-46aa-9427-095cead404ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hits_by_variable(hits_area, optimal_criteria=best_criteria, variable='area', reference=min_area, \n",
    "                      current_criteria=current_criteria, \n",
    "                      save=f'{path_out}hits_vs_area_{suffix}.jpg',\n",
    "                      xscale='log', xlabel='area ‚â• (km¬≤)', xlim=(criteria_area.area.min(), criteria_area.area.max()),\n",
    "                      loc_legend=[.87, .8, .2, .1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5497b79-6c29-42d0-9606-f4a2f573a380",
   "metadata": {},
   "source": [
    "> ***Figure 10**. Evolution of hits, misses and false alarms with catchment area threshold. Each plot represents a different approach to combine the meteorological forcings. The primary Y axis is normalized by the number of observed events to allow for comparison; the secondary Y axis indicates the probability threshold. The continuous lines are the hits, whereas the shadows are the false alarms; the difference between the reference line ($\\frac{x}{obs}=1$) and the hits are the misses. The dotted lines are the probability thresholds. Black objects represent the current operational criteria and blue ones the criteria optimized for a fixed area threshold (represented by a vertical, solid, black line).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2822e2b9-7b20-48d8-97c0-7c915edeec68",
   "metadata": {},
   "source": [
    "**Skill**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25157721-720f-4b76-b7f4-ead62986bc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_skill_by_variable(skill_area, reference=min_area, variable='area', metric=metric, \n",
    "                       current_criteria=current_criteria, optimal_criteria=best_criteria, optimized_criteria=None,\n",
    "                       xscale='log', xlabel='area ‚â• (km¬≤)', loc_text=4, loc_legend=[.87, .8, .2, .1],\n",
    "                       save=f'{path_out}skill_vs_area_{suffix}.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a44ed8c-552b-48c3-810c-1d42050d5b15",
   "metadata": {},
   "source": [
    "> ***Figure 11**. Evolution of skill with catchment area threshold. Each plot represents a different approach in which the meteorological forcings are combined. The primary Y axis indicates skill, and the secondary Y axis indicates the probability threshold. The continuous lines are the target skill score ($f_{0.8}$), and the shadows represent the difference between $precision$ and $recall$. The dotted lines are the probability thresholds. Black objects represent the current operational criteria and blue ones the criteria optimized for a fixed area threshold (represented by the vertical, solid, black line).*\n",
    "\n",
    "This figure shows both the change in the notification criteria (probability and persistence) and the effects on the skill. \n",
    "\n",
    "In general, the nofitication criteria have shifted towards higher probability thresholds (dotted, blue line), and no persistence. This is the case for all approaches but _model mean_, for which a persistence of $4/4$ and a low probability threshold were the optimal criteria. As explained before, there is a trade-off between persistence and probability, which is seen in this figure; higher probability thresholds require less strict persistence and viceversa.\n",
    "\n",
    "The skill of the system, measured in terms of $f_{0.8}$, improves with catchment area, as it was expected. Very large catchment areas have a skill close to 1. However, the curves are not continuously increasing; in the area range from 30,000 to 70,000 km¬≤ there is a loss of skill that must be analyzed. When moving towards smaller catchments, the loss in skill is not dramatic, which means that the catchment threshold could be lowered.\n",
    "\n",
    "The spread between $precision$ and $recall$ is in general lower with the optimized criteria. Figure 6 showed that the current operational criteria have a much higher $precision$ than $recall$, which is shown here with the wide gray shade. This spread in the current criteria increases towards smaller catchment areas and slightly dicreases toward larger areas. With the optimized criteria the behaviour changes significantly. In general, the spread is low for the fixed area threshold (2000 km¬≤), and it increases towards both sides, larger and smaller areas. Only the _member weighted_ approach, the highest-performing, has a different behaviour, very similar to the current operation criteria.\n",
    "\n",
    "The vertical line at 2000 km¬≤ shows the changes achieved with the optimization (this is the minimum catchment area fixed in the optimizatin). The skill improves for every approach, both in terms of $f_{0.8}$ and the spread between $precision$ and $recall$. The improvement in skill seen at 2000 km¬≤ expands throughout the catchment area values, with enhanced skill for larger catchment areas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552798d2-952c-4d39-9652-a561caaa2f2c",
   "metadata": {},
   "source": [
    "#### 3.3.3 Fixed criteria vs area optimized criteria\n",
    "\n",
    "In the previous section we have analyzed how the skill of the system varies over catchment area for a fixed value of the probability threshold. But, what if we tune the probability threshold according to catchment area? Would it improved the skill of the system?\n",
    "\n",
    "**Hits, misses and false alarms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3942f9-93d4-4bd8-a672-ea0c173537c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hits_by_variable(hits_area, current_criteria=None, optimal_criteria=best_criteria, optimized_criteria=criteria_area,\n",
    "                      reference=min_area, variable='area',\n",
    "                      save=f'{path_out}hits_vs_area_varying_probability_{suffix}.jpg', \n",
    "                      xscale='log', xlabel='area ‚â• (km¬≤)', xlim=(criteria_area.area.min(), criteria_area.area.max()),\n",
    "                      loc_text=1, loc_legend=[.9, .8, .2, .1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dc1999-a808-490d-8743-e83847422e50",
   "metadata": {},
   "source": [
    "> ***Figure 12**. Evolution of hits, misses and false alarms with catchment area threshold. Each plot represents a different approach to combine the meteorological forcings. The primary Y axis is normalized by the number of observed events to allow for comparison; the secondary Y axis indicates the probability threshold. The continuous lines are the hits, the shadows are the false alarms, and the difference between the reference line ($\\frac{x}{obs}=1$) and the hits are the misses. The dotted lines show the probability threshold. Blue objects are the results for the criteria optimized for a fixed area threshold (represented by a vertical, solid, black line), and orange objects those for the criteria optimized for every area threshold.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c5db3-1bd8-47ce-9c8e-ef8c550c4fa3",
   "metadata": {},
   "source": [
    "**Skill**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5945c714-52cf-4b88-b0c1-057f2e5ca2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_skill_by_variable(skill_area, optimal_criteria=best_criteria, variable='area', reference=min_area, metric=metric, \n",
    "                       current_criteria=None, optimized_criteria=criteria_area,\n",
    "                       xscale='log', xlabel='area ‚â• (km¬≤)', loc_text=2, loc_legend=[.9, .8, .2, .1],\n",
    "                       save=f'{path_out}skill_vs_area_varying_probability_{suffix}.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d530bbb-bbf4-4203-b8c3-bedde8aabf54",
   "metadata": {},
   "source": [
    "> ***Figure 13**. Evolution of skill with catchment area threshold. Each plot represents a different approach in which the meteorological forcings are combined. The primary Y axis indicates skill, and the secondary Y axis indicates the probability threshold. The continuous lines are the target skill score ($f_{0.8}$), and the shadows represent the difference between $precision$ and $recall$. The dotted lines show the probability threshold. Blue objects are the results for the criteria optimized for a fixed area threshold (represented by a vertical, solid, black line), and orange objects those for the criteria optimized for every area threshold.*\n",
    "\n",
    "This figure is similar to Figure 11, but the comparison now is between the criteria optimized for a fixed area threshold (2000 km¬≤) and for a varying area threshold. For the area threshold of 2000 km¬≤ (vertical, black line) the values should be the same for the two approaches.\n",
    "\n",
    "* The probability threshold shows a similar behaviour among approaches. It goes towards slighly lower values for catchment areas below the 2000 km¬≤ threshold, it increases from that threshold towards larger areas up to a point from which it dicreases severely, being very low for very large catchments. Only the _member weighted_ approach has a more erratic behaviour.\n",
    "\n",
    "* The skill measured as $f_{0.8}$ is very similar with both approaches. For areas lower than 2000 km¬≤ the skill is practically the same. For larger areas, the main improvement is at the range between 30,000 and 70,000 km¬≤, for which the fixed criteria shows a loss in skill. The biggest improvement is achieved in the _brier weighted_ approach.\n",
    "\n",
    "* The spread between $precision$ and $recall$ do change towards larger spread, especially fot the _1 deterministic and 1 probabilistic_ and the _brier weighted_ approach.\n",
    "\n",
    "The main outcome of this experiment is that the global skill of the system does not improve severely with a varying probability threshold. Therefore, for the sake of simplificity, a fixed probability threshold is advisable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2358e1-7b2e-4b6d-addc-57df1c46c295",
   "metadata": {},
   "source": [
    "### 3.4 Analyse skill by leadtime\n",
    "\n",
    "In the previous section we analyzed how the skill varies with catchment area, in this section we will carry out a similar analysis regarding lead time. First, we will compare the evolution of skill with lead time for the current operational criteria and the criteria optimized for the fixed lead time threshold of 60 h. Later on, we will repeat the optimization of the criteria for varying lead time thresholds, to see if changing the probability threshold for each lead time can enhance the overall skill.\n",
    "\n",
    "#### 3.4.1 Current vs optimized criteria\n",
    "\n",
    "**Hits, misses, false alarms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc71492-23b9-4cb8-811a-665b764b52eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hits_by_variable(hits_lt, optimal_criteria=best_criteria, variable='leadtime', reference=min_leadtime, \n",
    "                      current_criteria=current_criteria, \n",
    "                      save=f'{path_out}hits_vs_leadtime_{suffix}.jpg',\n",
    "                      xlabel='leadtime ‚â• (h)', xticks=4, \n",
    "                      loc_legend=[.87, .8, .2, .1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f553ea36-e39f-45d6-a161-a27b494f1d82",
   "metadata": {},
   "source": [
    "> ***Figure 14**. Evolution of hits, misses and false alarms with lead time threshold. Each plot represents a different approach in which the meteorological forcings are combined. The primary Y axis is normalized by the number of observed events to allow for comparison; the secondary Y axis indicates the probability threshold. The continuous lines are the hits, the shadows are the false alarms, and the difference between the reference line ($\\frac{x}{obs}=1$) and the hits are the misses. The dotted lines are the probability thresholds. Black objects represent the results for the current operational criteria and blue ones those for the criteria optimized for a fixed lead time threshold (represented by a vertical, solid, black line).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8b7f19-ffab-407a-a261-2a58686b8e53",
   "metadata": {},
   "source": [
    "**Skill**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07016861-634c-4afc-9df8-11beef518ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_skill_by_variable(skill_opt, optimal_criteria=best_criteria, variable='leadtime', reference=min_leadtime, metric=metric, \n",
    "                       current_criteria=current_criteria, optimized_criteria=None,\n",
    "                       xlabel='leadtime ‚â• (h)', loc_text=1, xticks=4, loc_legend=[.87, .8, .2, .1],\n",
    "                       save=None)#f'{path_out}skill_vs_leadtime_{suffix}.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fccfbd-7ad1-49ed-a231-0a6c510dbf60",
   "metadata": {},
   "source": [
    "> ***Figure 15**. Evolution of skill with lead time threshold. Each plot represents a different approach in which the meteorological forcings are combined. The primary Y axis indicates skill, and the secondary Y axis indicates the probability threshold. The continuous lines are the target skill score ($f_{0.8}$), and the shadows represent the difference between $precision$ and $recall$. The dotted lines are the probability thresholds. Black objects represent the results for current operational criteria and blue ones the criteria optimized for a fixed lead time threshold (represented by the vertical, solid, black line).*\n",
    "\n",
    "As expected, skill worsens with leadtime in a fairly linearly. Not only $f_{0.8}$ dicreases, but also the spread between $precision$ and $recall$ increases. These facts are true for both criteria: current and the optimized. The fact that EFAS does not provide notifications with less than 2 days notice hinders its skill, since those first 2 days leadtime are the most skillful.\n",
    "\n",
    "When looking at the 60 h leadtime (the fixed threshold in the optimization), the picture is the same as in Figure 11. The optimized criteria show a slightly higher $f_{0.8}$ and a far narrower spread between $precision$ and $recall$. The improvement in $f_{0.8}$ expands over the entire lead time axis, with slighly larger improvements at longer lead times. The $precision$-$recall$ spread, however, increases to both sides of the fixed leadtime threshold (60 h), especially towards long lead times. Nevertheless, the optimized criteria perform better for any lead time threshold.\n",
    "\n",
    "As the optimized criteria does not include persistence (persistence $1/1$) in three of the approaches, the system would be able to send notifications up to the tenth day, whereas in the current approach (persistence $3/3$) notification can only be sent with up to 8.5 days lead time. This is the reason why the results for the current operation criteria are limited to 216 h lead time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690010e4-fef5-4b85-8d8b-21b8c0ae3ff6",
   "metadata": {},
   "source": [
    "#### 3.4.2 Fixed criteria vs leadtime optimized criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c03c9d-238b-40b5-8881-75de61835959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide stations in train and test samples\n",
    "X = stations_optimize\n",
    "y = stations.loc[X, 'n_events_obs']\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, train_size=train_size, random_state=0, shuffle=True, stratify=y)\n",
    "\n",
    "# optimize the notification criteria\n",
    "if kfold is not None: # apply a cross-validation approach\n",
    "    skill_train, bc = find_best_criteria_cv(hits_stn.sel(id=Xtrain), ytrain, dims='probability',\n",
    "                                            kfold=kfold, train_size=train_size,\n",
    "                                            beta=beta, tolerance=tolerance, min_spread=True)\n",
    "else:\n",
    "    # subset of the 'hits' dataset with the training sample\n",
    "    hits_train = hits_stn.sel(id=Xtrain).sum('id', skipna=False)\n",
    "    # skill of the training sample\n",
    "    skill_train = hits2skill(hits_train, beta=beta)\n",
    "    # best criteria for each approach\n",
    "    bc = find_best_criterion(skill_train, dim='probability', metric=metric, tolerance=tolerance, min_spread=True)\n",
    "    \n",
    "criteria_leadtime = bc['probability']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4014d298-f33a-45b8-85fc-588d8e87f0a9",
   "metadata": {},
   "source": [
    "**Hits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30afe0b8-cd5e-4605-8ccc-500051336c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hits_by_variable(hits_lt, optimal_criteria=best_criteria, variable='leadtime', reference=min_leadtime, \n",
    "                      current_criteria=None, optimized_criteria=criteria_leadtime, \n",
    "                      save=f'{path_out}hits_vs_leadtime_varying_probability_{suffix}.jpg',\n",
    "                      xlabel='leadtime ‚â• (h)', xticks=4, \n",
    "                      loc_legend=[.92, .8, .2, .1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13dd094-b33d-42da-a31c-2fd1a7e9671e",
   "metadata": {},
   "source": [
    "> ***Figure 16**. Evolution of hits, misses and false alarms with lead time threshold. Each plot represents a different approach in which the meteorological forcings are combined. The primary Y axis is normalized by the number of observed events to allow for comparison; the secondary Y axis indicates the probability threshold. The continuous lines are the hits, the shadows are the false alarms, and the difference between the reference line ($\\frac{x}{obs}=1$) and the hits are the misses. The dotted lines show the probability threshold. Blue objects are the results for the criteria optimized for a fixed lead time threshold (represented by a vertical, solid, black line), and orange objects those for the criteria optimized for every lead time threshold.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58266f1e-5c85-4fb6-8722-59de6959acb0",
   "metadata": {},
   "source": [
    "**Skill**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d6ded4-fb4c-4ba1-a6d1-2152deaebf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_skill_by_variable(skill_opt, optimal_criteria=best_criteria, variable='leadtime', reference=min_leadtime, metric=metric, \n",
    "                       optimized_criteria=criteria_leadtime,\n",
    "                       xlabel='leadtime ‚â• (h)', loc_text=1, xticks=4, loc_legend=[.92, .8, .2, .1],\n",
    "                       save=f'{path_out}skill_vs_leadtime_varying_probability_{suffix}.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98e01ee-e4c9-4766-898d-670a4daa15f9",
   "metadata": {},
   "source": [
    "> ***Figure 17**. Evolution of skill with lead time threshold. Each plot represents a different approach in which the meteorological forcings are combined. The primary Y axis indicates skill, and the secondary Y axis indicates the probability threshold. The continuous lines are the target skill score ($f_{0.8}$), and the shadows represent the difference between $precision$ and $recall$. The dotted lines are the probability thresholds. Blue objects are the criteria optimized for a fixed lead time threshold (represented by the vertical, solid, black line), and orange ones the criteria optimized for each leadtime.*\n",
    "\n",
    "This figure is similar to Figure 13 with the only difference that the X axis represents lead time instead of area. The results for the two criteria should match for the 60 h lead time (vertical black line).\n",
    "\n",
    "In general, the leadtime-optimized probability threshold dicreases with lead time. For very short lead times the forecast is more certain, so the probability threshold can be as high as 85%; on the contrary, the forecast at 10 days lead time is so uncertain that the probability threshold is as low as 10%. This behaviour applies to all the approaches but model mean; this is most probably caused by the persistence \n",
    " in this approach, which limits the impact of the probability threshold, since most ot the false alarms are filtered out by the very strict persistence.\n",
    "\n",
    "The skill in terms of $f_{0.8}$ improves with the leadtime-optimized criteria for both very short and very long lead times, but for the majority of the lead time range it is fairly similar to that of the fixed criteria. Furthermore, the spread narrows, especially for mid and long lead times.\n",
    "\n",
    "In conclusion, the implementation of a leadtime-varying probability threshold would be of interest to improve the skill in the shorter and longer lead times, and to reduce the amount of misses in the mid and long lead times. The effects on skill obtained by varying the probability threshold with respect to lead time are larger than when varying the criteria with catchment area (previous experiment). It is to be decided if the improvement in skill is worth the increasing complexity in the notification criteria."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
